{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intializing the libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the Datasets\n",
    "Dataset = h5py.File('SVHN_single_grey1.h5','r')\n",
    "Dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set\n",
    "X_train = Dataset['X_val'][:]\n",
    "y_train = Dataset['y_val'][:]\n",
    "\n",
    "# Test Set\n",
    "X_test = Dataset['X_test'][:]\n",
    "y_test = Dataset['y_test'][:]\n",
    "\n",
    "# Validation Set\n",
    "X_val = Dataset['X_train'][:]\n",
    "y_val = Dataset['y_train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 32, 32)\n",
      "(60000, 32, 32)\n",
      "(42000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the data set\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the dataset and labels\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.xlabel('---- {0} ----'.format(y_train[i]))\n",
    "    plt.imshow(X_train[i],cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshapping and Normalizing the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the Inputs from (32,32) 2-dimensional to 1-dimensional.\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "X_val = X_val.reshape(X_val.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero centering the Input space\n",
    "train_means = np.mean(X_train,axis=0)\n",
    "for i in range (X_train.shape[0]):\n",
    "    X_train[i,:] -= train_means\n",
    "    \n",
    "for i in range (X_test.shape[0]):\n",
    "    X_test[i,:] -= train_means\n",
    "\n",
    "for i in range (X_val.shape[0]):\n",
    "    X_val[i,:] -= train_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Input space\n",
    "train_devs = np.std(X_train,axis=0)\n",
    "for i in range (X_train.shape[0]):\n",
    "    X_train[i,:] /= train_devs\n",
    "    \n",
    "for i in range (X_test.shape[0]):\n",
    "    X_test[i,:] /= train_devs\n",
    "\n",
    "for i in range (X_val.shape[0]):\n",
    "    X_val[i,:] /= train_devs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT Encoding the ouput labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val,num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking the complete dataset\n",
    "X = np.vstack((X_train,X_val,X_test)) \n",
    "Y = np.vstack((y_train,y_val,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,x,y_train,y = train_test_split(X,Y,random_state = 7,test_size = 0.4)\n",
    "\n",
    "X_val,X_test,y_val,y_test = train_test_split(x,y,random_state = 7,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Intialzation and Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the Model Architecture hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intializing the NN model function\n",
    "def model_arch(X,Y,loops,learningrate,regularization,hidden_layer_1_neurons,hidden_layer_2_neurons,hidden_layer_3_neurons,\n",
    "               dropout,val = False,x_val = None,y_val = None):\n",
    "    # intializing the model\n",
    "    NN_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hidden_layer_1_neurons),\n",
    "        tf.keras.layers.Dropout(dropout),  # Dropouts are generally used after Activation functions but it can be used before for relu\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dense(hidden_layer_2_neurons),\n",
    "        tf.keras.layers.Dropout(dropout),  # Dropouts are generally used after Activation functions but it can be used before for relu\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dense(hidden_layer_3_neurons),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dense(10,activation = 'softmax',kernel_regularizer = tf.keras.regularizers.l2(regularization))\n",
    "    ])\n",
    "    \n",
    "    # Adam Optimizer\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= learningrate,beta_1 =0.8 ,beta_2=0.8,decay = 1e-4)\n",
    "    \n",
    "    # Compile\n",
    "    NN_model.compile(optimizer= adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 10 , min_delta = 0.01 )\n",
    "    \n",
    "    if val == True:\n",
    "        NN_model.fit(X,Y,epochs=loops,validation_data=(x_val,y_val),batch_size = int(X.shape[0]/21),callbacks=[callback])\n",
    "    else:\n",
    "         NN_model.fit(X,Y,epochs=loops,batch_size = int(X.shape[0]/21))\n",
    "    \n",
    "    return(NN_model)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Loop 1 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 2.3921 - accuracy: 0.1138 - val_loss: 2.7992 - val_accuracy: 0.1337\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.0467 - accuracy: 0.2429 - val_loss: 1.6941 - val_accuracy: 0.4202\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.4404 - accuracy: 0.5058 - val_loss: 1.4902 - val_accuracy: 0.5867\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.1333 - accuracy: 0.6308 - val_loss: 1.3143 - val_accuracy: 0.6421\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.0426 - accuracy: 0.6619 - val_loss: 1.0999 - val_accuracy: 0.6908\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.9424 - accuracy: 0.6972 - val_loss: 0.9940 - val_accuracy: 0.7268\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8885 - accuracy: 0.7169 - val_loss: 0.8532 - val_accuracy: 0.7511\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.8336 - accuracy: 0.7345 - val_loss: 0.8561 - val_accuracy: 0.7368\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7750 - accuracy: 0.7539 - val_loss: 0.7085 - val_accuracy: 0.7880\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7608 - accuracy: 0.7568 - val_loss: 0.6813 - val_accuracy: 0.7914\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7780 - accuracy: 0.7511 - val_loss: 0.6648 - val_accuracy: 0.7915\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6954 - accuracy: 0.7786 - val_loss: 0.6147 - val_accuracy: 0.8072\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6660 - accuracy: 0.7896 - val_loss: 0.6419 - val_accuracy: 0.7980\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6635 - accuracy: 0.7891 - val_loss: 0.5737 - val_accuracy: 0.8186\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6552 - accuracy: 0.7914 - val_loss: 0.6107 - val_accuracy: 0.8050\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6837 - accuracy: 0.7809 - val_loss: 0.5595 - val_accuracy: 0.8239\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6783 - accuracy: 0.7828 - val_loss: 0.5555 - val_accuracy: 0.8240\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6431 - accuracy: 0.7956 - val_loss: 0.5620 - val_accuracy: 0.8230\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6266 - accuracy: 0.8017 - val_loss: 0.5232 - val_accuracy: 0.8342\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5975 - accuracy: 0.8093 - val_loss: 0.4977 - val_accuracy: 0.8431\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5623 - accuracy: 0.8208 - val_loss: 0.4982 - val_accuracy: 0.8428\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5502 - accuracy: 0.8254 - val_loss: 0.5048 - val_accuracy: 0.8412\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5455 - accuracy: 0.8259 - val_loss: 0.4578 - val_accuracy: 0.8550\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5393 - accuracy: 0.8288 - val_loss: 0.5043 - val_accuracy: 0.8438\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5347 - accuracy: 0.8282 - val_loss: 0.5029 - val_accuracy: 0.8422\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5156 - accuracy: 0.8371 - val_loss: 0.4596 - val_accuracy: 0.8558\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4942 - accuracy: 0.8425 - val_loss: 0.4607 - val_accuracy: 0.8540\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5178 - accuracy: 0.8340 - val_loss: 0.4479 - val_accuracy: 0.8587\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5367 - accuracy: 0.8285 - val_loss: 0.4557 - val_accuracy: 0.8573\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4791 - accuracy: 0.8469 - val_loss: 0.4301 - val_accuracy: 0.8650\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5240 - accuracy: 0.8323 - val_loss: 0.4414 - val_accuracy: 0.8622\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4790 - accuracy: 0.8482 - val_loss: 0.4386 - val_accuracy: 0.8637\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.5467 - accuracy: 0.8257 - val_loss: 0.4295 - val_accuracy: 0.8645\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.5143 - accuracy: 0.8359 - val_loss: 0.4202 - val_accuracy: 0.8669\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.5407 - accuracy: 0.8257 - val_loss: 0.4165 - val_accuracy: 0.8700\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.4639 - accuracy: 0.8511 - val_loss: 0.4760 - val_accuracy: 0.8491\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.5289 - accuracy: 0.8308 - val_loss: 0.4141 - val_accuracy: 0.8699\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4621 - accuracy: 0.8523 - val_loss: 0.4349 - val_accuracy: 0.8625\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4594 - accuracy: 0.8524 - val_loss: 0.4171 - val_accuracy: 0.8704\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4430 - accuracy: 0.8568 - val_loss: 0.3925 - val_accuracy: 0.8788\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.4461 - accuracy: 0.8581 - val_loss: 0.3974 - val_accuracy: 0.8753\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4423 - accuracy: 0.8584 - val_loss: 0.3842 - val_accuracy: 0.8820\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4341 - accuracy: 0.8615 - val_loss: 0.3828 - val_accuracy: 0.8810\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.5221 - accuracy: 0.8314 - val_loss: 0.4000 - val_accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.4317 - accuracy: 0.8613 - val_loss: 0.3831 - val_accuracy: 0.8806\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.4246 - accuracy: 0.8639 - val_loss: 0.3930 - val_accuracy: 0.8761\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4218 - accuracy: 0.8639 - val_loss: 0.3722 - val_accuracy: 0.8834\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4139 - accuracy: 0.8667 - val_loss: 0.3669 - val_accuracy: 0.8877\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4151 - accuracy: 0.8676 - val_loss: 0.3925 - val_accuracy: 0.8782\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4483 - accuracy: 0.8557 - val_loss: 0.3751 - val_accuracy: 0.8834\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8834\n",
      "Accuracy on the Validation Data is 0.8833749890327454 and the loss is 0.37509721517562866\n",
      "For Hidden Layer 1 neurons =  619 ,Hidden Layer 2 neurons =  265 & Hidden Layer 3 neurons =  166 ; also Droput of 0.336442211859598\n",
      "\n",
      "\n",
      "--------------------------- Loop 2 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 2.3628 - accuracy: 0.1080 - val_loss: 2.4327 - val_accuracy: 0.1196\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 2.1146 - accuracy: 0.2051 - val_loss: 1.7694 - val_accuracy: 0.3506\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 1.5848 - accuracy: 0.4368 - val_loss: 1.6196 - val_accuracy: 0.4700\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 1.2866 - accuracy: 0.5714 - val_loss: 1.3316 - val_accuracy: 0.6231\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 1.0667 - accuracy: 0.6554 - val_loss: 1.1898 - val_accuracy: 0.6664\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 1.0109 - accuracy: 0.6745 - val_loss: 1.0345 - val_accuracy: 0.7003\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.9095 - accuracy: 0.7089 - val_loss: 0.9882 - val_accuracy: 0.7063\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.8717 - accuracy: 0.7237 - val_loss: 0.7862 - val_accuracy: 0.7758\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.8412 - accuracy: 0.7313 - val_loss: 0.7614 - val_accuracy: 0.7705\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.8211 - accuracy: 0.7389 - val_loss: 0.7009 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.7964 - accuracy: 0.7466 - val_loss: 0.7524 - val_accuracy: 0.7614\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.7856 - accuracy: 0.7512 - val_loss: 0.6493 - val_accuracy: 0.7953\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.7409 - accuracy: 0.7661 - val_loss: 0.6669 - val_accuracy: 0.7876\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7350 - accuracy: 0.7657 - val_loss: 0.6331 - val_accuracy: 0.8006\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7263 - accuracy: 0.7690 - val_loss: 0.5742 - val_accuracy: 0.8202\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.7518 - accuracy: 0.7605 - val_loss: 0.5921 - val_accuracy: 0.8138\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.6843 - accuracy: 0.7828 - val_loss: 0.5878 - val_accuracy: 0.8127\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.7080 - accuracy: 0.7748 - val_loss: 0.5380 - val_accuracy: 0.8302\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.6522 - accuracy: 0.7959 - val_loss: 0.5357 - val_accuracy: 0.8313\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6288 - accuracy: 0.8022 - val_loss: 0.5197 - val_accuracy: 0.8372\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6163 - accuracy: 0.8048 - val_loss: 0.5092 - val_accuracy: 0.8401\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6224 - accuracy: 0.8031 - val_loss: 0.5023 - val_accuracy: 0.8422\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.6085 - accuracy: 0.8073 - val_loss: 0.4811 - val_accuracy: 0.8492\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6013 - accuracy: 0.8093 - val_loss: 0.5062 - val_accuracy: 0.8426\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.5985 - accuracy: 0.8093 - val_loss: 0.4731 - val_accuracy: 0.8519\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.6072 - accuracy: 0.8084 - val_loss: 0.4789 - val_accuracy: 0.8494\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5832 - accuracy: 0.8145 - val_loss: 0.4675 - val_accuracy: 0.8536\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5758 - accuracy: 0.8185 - val_loss: 0.4814 - val_accuracy: 0.8474\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5599 - accuracy: 0.8221 - val_loss: 0.4646 - val_accuracy: 0.8553\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5788 - accuracy: 0.8146 - val_loss: 0.4759 - val_accuracy: 0.8538\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5565 - accuracy: 0.8245 - val_loss: 0.4656 - val_accuracy: 0.8524\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.5811 - accuracy: 0.8154 - val_loss: 0.4559 - val_accuracy: 0.8583\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5324 - accuracy: 0.8318 - val_loss: 0.4554 - val_accuracy: 0.8578\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.5246 - accuracy: 0.8341 - val_loss: 0.4321 - val_accuracy: 0.8656\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.5286 - accuracy: 0.8330 - val_loss: 0.4332 - val_accuracy: 0.8642\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5055 - accuracy: 0.8387 - val_loss: 0.4333 - val_accuracy: 0.8648\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5652 - accuracy: 0.8196 - val_loss: 0.4426 - val_accuracy: 0.8642\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5114 - accuracy: 0.8372 - val_loss: 0.4276 - val_accuracy: 0.8665\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.5220 - accuracy: 0.8338 - val_loss: 0.4227 - val_accuracy: 0.8679\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4980 - accuracy: 0.8412 - val_loss: 0.4110 - val_accuracy: 0.8729\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.5033 - accuracy: 0.8395 - val_loss: 0.4252 - val_accuracy: 0.8670\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4947 - accuracy: 0.8431 - val_loss: 0.4001 - val_accuracy: 0.8775\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4826 - accuracy: 0.8464 - val_loss: 0.4017 - val_accuracy: 0.8765\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4911 - accuracy: 0.8436 - val_loss: 0.4031 - val_accuracy: 0.8761\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5244 - accuracy: 0.8311 - val_loss: 0.3984 - val_accuracy: 0.8777\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.4825 - accuracy: 0.8453 - val_loss: 0.3922 - val_accuracy: 0.8801\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4943 - accuracy: 0.8438 - val_loss: 0.3909 - val_accuracy: 0.8788\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4703 - accuracy: 0.8510 - val_loss: 0.3919 - val_accuracy: 0.8772\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4893 - accuracy: 0.8456 - val_loss: 0.4112 - val_accuracy: 0.8728\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4625 - accuracy: 0.8537 - val_loss: 0.4032 - val_accuracy: 0.8733\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.4651 - accuracy: 0.8519 - val_loss: 0.3838 - val_accuracy: 0.8812\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4501 - accuracy: 0.8579 - val_loss: 0.3877 - val_accuracy: 0.8800\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3877 - accuracy: 0.8800\n",
      "Accuracy on the Validation Data is 0.8799583315849304 and the loss is 0.38765430450439453\n",
      "For Hidden Layer 1 neurons =  933 ,Hidden Layer 2 neurons =  331 & Hidden Layer 3 neurons =  82 ; also Droput of 0.4491941792773088\n",
      "\n",
      "\n",
      "--------------------------- Loop 3 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 2.4116 - accuracy: 0.1016 - val_loss: 2.5704 - val_accuracy: 0.1112\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 2.2560 - accuracy: 0.1487 - val_loss: 1.9101 - val_accuracy: 0.3198\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 114ms/step - loss: 1.6964 - accuracy: 0.3891 - val_loss: 1.6162 - val_accuracy: 0.4820\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.3459 - accuracy: 0.5418 - val_loss: 1.4050 - val_accuracy: 0.6006\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 1.2147 - accuracy: 0.5975 - val_loss: 1.2175 - val_accuracy: 0.6432\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 1.0861 - accuracy: 0.6452 - val_loss: 1.0882 - val_accuracy: 0.6776\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 114ms/step - loss: 1.0327 - accuracy: 0.6654 - val_loss: 0.9196 - val_accuracy: 0.7444\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.9431 - accuracy: 0.6990 - val_loss: 0.8303 - val_accuracy: 0.7549\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.9131 - accuracy: 0.7100 - val_loss: 0.7772 - val_accuracy: 0.7703\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.8941 - accuracy: 0.7139 - val_loss: 0.7938 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.8725 - accuracy: 0.7204 - val_loss: 0.6764 - val_accuracy: 0.7908\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.8688 - accuracy: 0.7238 - val_loss: 0.6708 - val_accuracy: 0.7893\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.8231 - accuracy: 0.7388 - val_loss: 0.7455 - val_accuracy: 0.7615\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.8174 - accuracy: 0.7418 - val_loss: 0.6792 - val_accuracy: 0.7840\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.7792 - accuracy: 0.7524 - val_loss: 0.6096 - val_accuracy: 0.8076\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.7617 - accuracy: 0.7591 - val_loss: 0.5790 - val_accuracy: 0.8185\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.7594 - accuracy: 0.7591 - val_loss: 0.5831 - val_accuracy: 0.8174\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.7864 - accuracy: 0.7512 - val_loss: 0.5561 - val_accuracy: 0.8249\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7100 - accuracy: 0.7750 - val_loss: 0.5723 - val_accuracy: 0.8222\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6979 - accuracy: 0.7793 - val_loss: 0.5691 - val_accuracy: 0.8212\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.7294 - accuracy: 0.7682 - val_loss: 0.5490 - val_accuracy: 0.8241\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6935 - accuracy: 0.7796 - val_loss: 0.5361 - val_accuracy: 0.8284\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.6982 - accuracy: 0.7763 - val_loss: 0.5464 - val_accuracy: 0.8282\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6724 - accuracy: 0.7867 - val_loss: 0.5576 - val_accuracy: 0.8261\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.6558 - accuracy: 0.7928 - val_loss: 0.5340 - val_accuracy: 0.8349\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6610 - accuracy: 0.7900 - val_loss: 0.5189 - val_accuracy: 0.8377\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.6364 - accuracy: 0.7980 - val_loss: 0.5041 - val_accuracy: 0.8430\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6234 - accuracy: 0.8029 - val_loss: 0.5151 - val_accuracy: 0.8392\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6461 - accuracy: 0.7936 - val_loss: 0.5055 - val_accuracy: 0.8410\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.6303 - accuracy: 0.8008 - val_loss: 0.4920 - val_accuracy: 0.8475\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.6108 - accuracy: 0.8066 - val_loss: 0.4700 - val_accuracy: 0.8533\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5962 - accuracy: 0.8103 - val_loss: 0.4765 - val_accuracy: 0.8495\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6009 - accuracy: 0.8099 - val_loss: 0.4644 - val_accuracy: 0.8543\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6081 - accuracy: 0.8057 - val_loss: 0.4564 - val_accuracy: 0.8577\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5901 - accuracy: 0.8128 - val_loss: 0.4513 - val_accuracy: 0.8587\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.5673 - accuracy: 0.8212 - val_loss: 0.4842 - val_accuracy: 0.8482\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5640 - accuracy: 0.8228 - val_loss: 0.4396 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.5618 - accuracy: 0.8242 - val_loss: 0.4863 - val_accuracy: 0.8474\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6207 - accuracy: 0.8023 - val_loss: 0.4459 - val_accuracy: 0.8614\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6242 - accuracy: 0.8014 - val_loss: 0.4424 - val_accuracy: 0.8625\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.6357 - accuracy: 0.7983 - val_loss: 0.4513 - val_accuracy: 0.8602\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5691 - accuracy: 0.8191 - val_loss: 0.4596 - val_accuracy: 0.8562\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.5731 - accuracy: 0.8174 - val_loss: 0.4365 - val_accuracy: 0.8618\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.5495 - accuracy: 0.8251 - val_loss: 0.4329 - val_accuracy: 0.8660\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.4329 - accuracy: 0.8660\n",
      "Accuracy on the Validation Data is 0.8659999966621399 and the loss is 0.4328823387622833\n",
      "For Hidden Layer 1 neurons =  938 ,Hidden Layer 2 neurons =  239 & Hidden Layer 3 neurons =  156 ; also Droput of 0.4946640269339935\n",
      "\n",
      "\n",
      "--------------------------- Loop 4 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 2.4175 - accuracy: 0.1096 - val_loss: 2.7883 - val_accuracy: 0.1183\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 2.0762 - accuracy: 0.2249 - val_loss: 1.8357 - val_accuracy: 0.3417\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 1.4689 - accuracy: 0.4882 - val_loss: 1.5629 - val_accuracy: 0.5052\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 1.1236 - accuracy: 0.6316 - val_loss: 1.3137 - val_accuracy: 0.6616\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.9837 - accuracy: 0.6817 - val_loss: 1.2222 - val_accuracy: 0.6409\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.9392 - accuracy: 0.6981 - val_loss: 1.0017 - val_accuracy: 0.7197\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.8747 - accuracy: 0.7186 - val_loss: 0.9613 - val_accuracy: 0.7183\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.8845 - accuracy: 0.7144 - val_loss: 0.8165 - val_accuracy: 0.7514\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.7572 - accuracy: 0.7601 - val_loss: 0.7630 - val_accuracy: 0.7666\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.7148 - accuracy: 0.7730 - val_loss: 0.7113 - val_accuracy: 0.7807\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.7008 - accuracy: 0.7768 - val_loss: 0.6309 - val_accuracy: 0.8026\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.6193 - accuracy: 0.8039 - val_loss: 0.6351 - val_accuracy: 0.8001\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.6756 - accuracy: 0.7842 - val_loss: 0.6203 - val_accuracy: 0.8037\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.6082 - accuracy: 0.8057 - val_loss: 0.5896 - val_accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.5971 - accuracy: 0.8088 - val_loss: 0.6727 - val_accuracy: 0.7957\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.5892 - accuracy: 0.8107 - val_loss: 0.5598 - val_accuracy: 0.8211\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.5467 - accuracy: 0.8254 - val_loss: 0.6163 - val_accuracy: 0.8099\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 4s 198ms/step - loss: 0.5891 - accuracy: 0.8117 - val_loss: 0.5797 - val_accuracy: 0.8205\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.5797 - accuracy: 0.8152 - val_loss: 0.5524 - val_accuracy: 0.8260\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.5433 - accuracy: 0.8274 - val_loss: 0.5175 - val_accuracy: 0.8377\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.5260 - accuracy: 0.8307 - val_loss: 0.4956 - val_accuracy: 0.8467\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.5266 - accuracy: 0.8323 - val_loss: 0.4889 - val_accuracy: 0.8460\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.4799 - accuracy: 0.8471 - val_loss: 0.4952 - val_accuracy: 0.8465\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4559 - accuracy: 0.8541 - val_loss: 0.5025 - val_accuracy: 0.8438\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4305 - accuracy: 0.8619 - val_loss: 0.4887 - val_accuracy: 0.8502\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.4424 - accuracy: 0.8586 - val_loss: 0.4774 - val_accuracy: 0.8512\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.4907 - accuracy: 0.8405 - val_loss: 0.4646 - val_accuracy: 0.8549\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.4697 - accuracy: 0.8499 - val_loss: 0.4530 - val_accuracy: 0.8626\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4751 - accuracy: 0.8460 - val_loss: 0.4279 - val_accuracy: 0.8680\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.3917 - accuracy: 0.8743 - val_loss: 0.4692 - val_accuracy: 0.8564\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.3883 - accuracy: 0.8768 - val_loss: 0.5379 - val_accuracy: 0.8394\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.4346 - accuracy: 0.8593 - val_loss: 0.4277 - val_accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.3979 - accuracy: 0.8721 - val_loss: 0.4199 - val_accuracy: 0.8685\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.4341 - accuracy: 0.8594 - val_loss: 0.4832 - val_accuracy: 0.8546\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.4097 - accuracy: 0.8683 - val_loss: 0.3933 - val_accuracy: 0.8798\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.3930 - accuracy: 0.8722 - val_loss: 0.3799 - val_accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.3640 - accuracy: 0.8831 - val_loss: 0.4036 - val_accuracy: 0.8774\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.3497 - accuracy: 0.8880 - val_loss: 0.4350 - val_accuracy: 0.8689\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.3521 - accuracy: 0.8856 - val_loss: 0.3926 - val_accuracy: 0.8801\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.3480 - accuracy: 0.8870 - val_loss: 0.3728 - val_accuracy: 0.8860\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.3437 - accuracy: 0.8883 - val_loss: 0.3687 - val_accuracy: 0.8864\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.3585 - accuracy: 0.8833 - val_loss: 0.4230 - val_accuracy: 0.8764\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3414 - accuracy: 0.8883 - val_loss: 0.3727 - val_accuracy: 0.8865\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3454 - accuracy: 0.8865 - val_loss: 0.3728 - val_accuracy: 0.8870\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3102 - accuracy: 0.8992 - val_loss: 0.3613 - val_accuracy: 0.8937\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3553 - accuracy: 0.8848 - val_loss: 0.3860 - val_accuracy: 0.8847\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.3456 - accuracy: 0.8881 - val_loss: 0.3592 - val_accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.3198 - accuracy: 0.8962 - val_loss: 0.3549 - val_accuracy: 0.8946\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.3219 - accuracy: 0.8944 - val_loss: 0.3676 - val_accuracy: 0.8907\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.3282 - accuracy: 0.8928 - val_loss: 0.3633 - val_accuracy: 0.8930\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.3465 - accuracy: 0.8883 - val_loss: 0.3779 - val_accuracy: 0.8884\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.3399 - accuracy: 0.8889 - val_loss: 0.3499 - val_accuracy: 0.8967\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3032 - accuracy: 0.9020 - val_loss: 0.3540 - val_accuracy: 0.8941\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.3031 - accuracy: 0.9019 - val_loss: 0.3487 - val_accuracy: 0.8978\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.3233 - accuracy: 0.8953 - val_loss: 0.3457 - val_accuracy: 0.8989\n",
      "  1/750 [..............................] - ETA: 0s - loss: 0.0917 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8989\n",
      "Accuracy on the Validation Data is 0.8989166617393494 and the loss is 0.34574654698371887\n",
      "For Hidden Layer 1 neurons =  869 ,Hidden Layer 2 neurons =  295 & Hidden Layer 3 neurons =  189 ; also Droput of 0.22461609656250223\n",
      "\n",
      "\n",
      "--------------------------- Loop 5 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 2.3815 - accuracy: 0.1048 - val_loss: 2.5419 - val_accuracy: 0.1042\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 2.1834 - accuracy: 0.1805 - val_loss: 1.8555 - val_accuracy: 0.3754\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 1.5771 - accuracy: 0.4445 - val_loss: 1.4942 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 1.2563 - accuracy: 0.5812 - val_loss: 1.2974 - val_accuracy: 0.6407\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 1.0806 - accuracy: 0.6497 - val_loss: 1.1123 - val_accuracy: 0.6936\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.0049 - accuracy: 0.6762 - val_loss: 0.9590 - val_accuracy: 0.7435\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.9196 - accuracy: 0.7060 - val_loss: 0.9187 - val_accuracy: 0.7347\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8685 - accuracy: 0.7236 - val_loss: 0.7810 - val_accuracy: 0.7718\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8468 - accuracy: 0.7298 - val_loss: 0.7515 - val_accuracy: 0.7733\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.8247 - accuracy: 0.7382 - val_loss: 0.6807 - val_accuracy: 0.7918\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7702 - accuracy: 0.7546 - val_loss: 0.6676 - val_accuracy: 0.7902\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7874 - accuracy: 0.7493 - val_loss: 0.6302 - val_accuracy: 0.8028\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.7574 - accuracy: 0.7580 - val_loss: 0.5962 - val_accuracy: 0.8145\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.6993 - accuracy: 0.7791 - val_loss: 0.5759 - val_accuracy: 0.8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.6858 - accuracy: 0.7810 - val_loss: 0.5445 - val_accuracy: 0.8312\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.7108 - accuracy: 0.7739 - val_loss: 0.5782 - val_accuracy: 0.8207\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.6860 - accuracy: 0.7814 - val_loss: 0.5488 - val_accuracy: 0.8284\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.6763 - accuracy: 0.7855 - val_loss: 0.5491 - val_accuracy: 0.8258\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6705 - accuracy: 0.7869 - val_loss: 0.5305 - val_accuracy: 0.8337\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6688 - accuracy: 0.7854 - val_loss: 0.5352 - val_accuracy: 0.8295\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6375 - accuracy: 0.7968 - val_loss: 0.5087 - val_accuracy: 0.8395\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6263 - accuracy: 0.8003 - val_loss: 0.5260 - val_accuracy: 0.8331\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6633 - accuracy: 0.7886 - val_loss: 0.5025 - val_accuracy: 0.8433\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6221 - accuracy: 0.8021 - val_loss: 0.4980 - val_accuracy: 0.8444\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5818 - accuracy: 0.8141 - val_loss: 0.4783 - val_accuracy: 0.8504\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5869 - accuracy: 0.8138 - val_loss: 0.4627 - val_accuracy: 0.8536\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5919 - accuracy: 0.8123 - val_loss: 0.4610 - val_accuracy: 0.8549\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.5631 - accuracy: 0.8223 - val_loss: 0.4559 - val_accuracy: 0.8568\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5680 - accuracy: 0.8204 - val_loss: 0.4624 - val_accuracy: 0.8544\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.6480 - accuracy: 0.7922 - val_loss: 0.4597 - val_accuracy: 0.8562\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5536 - accuracy: 0.8243 - val_loss: 0.4524 - val_accuracy: 0.8564\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.6030 - accuracy: 0.8072 - val_loss: 0.4475 - val_accuracy: 0.8613\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5589 - accuracy: 0.8221 - val_loss: 0.4409 - val_accuracy: 0.8617\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5322 - accuracy: 0.8314 - val_loss: 0.4350 - val_accuracy: 0.8642\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5488 - accuracy: 0.8252 - val_loss: 0.4379 - val_accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5533 - accuracy: 0.8241 - val_loss: 0.4356 - val_accuracy: 0.8642\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5374 - accuracy: 0.8298 - val_loss: 0.4454 - val_accuracy: 0.8591\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5569 - accuracy: 0.8230 - val_loss: 0.4289 - val_accuracy: 0.8644\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5382 - accuracy: 0.8287 - val_loss: 0.4143 - val_accuracy: 0.8705\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5146 - accuracy: 0.8358 - val_loss: 0.4263 - val_accuracy: 0.8664\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5156 - accuracy: 0.8367 - val_loss: 0.4268 - val_accuracy: 0.8651\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5373 - accuracy: 0.8286 - val_loss: 0.4201 - val_accuracy: 0.8680\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.4990 - accuracy: 0.8416 - val_loss: 0.4086 - val_accuracy: 0.8723\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.5070 - accuracy: 0.8396 - val_loss: 0.4055 - val_accuracy: 0.8730\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4055 - accuracy: 0.8730\n",
      "Accuracy on the Validation Data is 0.8730416893959045 and the loss is 0.40551915764808655\n",
      "For Hidden Layer 1 neurons =  516 ,Hidden Layer 2 neurons =  346 & Hidden Layer 3 neurons =  80 ; also Droput of 0.4294073452355189\n",
      "\n",
      "\n",
      "--------------------------- Loop 6 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 2.3891 - accuracy: 0.1051 - val_loss: 2.8131 - val_accuracy: 0.1157\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.1626 - accuracy: 0.1849 - val_loss: 1.8789 - val_accuracy: 0.3339\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.6332 - accuracy: 0.4191 - val_loss: 1.6499 - val_accuracy: 0.5180\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.3147 - accuracy: 0.5598 - val_loss: 1.3991 - val_accuracy: 0.6463\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.1243 - accuracy: 0.6372 - val_loss: 1.2350 - val_accuracy: 0.6839\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.0249 - accuracy: 0.6702 - val_loss: 1.0764 - val_accuracy: 0.7183\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.9540 - accuracy: 0.6948 - val_loss: 0.9705 - val_accuracy: 0.7434\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.9181 - accuracy: 0.7084 - val_loss: 0.8859 - val_accuracy: 0.7622\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.9227 - accuracy: 0.7054 - val_loss: 0.8035 - val_accuracy: 0.7589\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.9103 - accuracy: 0.7092 - val_loss: 0.7615 - val_accuracy: 0.7720\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.8629 - accuracy: 0.7252 - val_loss: 0.7095 - val_accuracy: 0.7826\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.8612 - accuracy: 0.7251 - val_loss: 0.6802 - val_accuracy: 0.7887\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.8303 - accuracy: 0.7348 - val_loss: 0.6484 - val_accuracy: 0.7966\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.7855 - accuracy: 0.7498 - val_loss: 0.6171 - val_accuracy: 0.8053\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.7903 - accuracy: 0.7473 - val_loss: 0.5988 - val_accuracy: 0.8094\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8012 - accuracy: 0.7437 - val_loss: 0.6010 - val_accuracy: 0.8099\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.7694 - accuracy: 0.7549 - val_loss: 0.5894 - val_accuracy: 0.8131\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.7431 - accuracy: 0.7653 - val_loss: 0.5628 - val_accuracy: 0.8225\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7162 - accuracy: 0.7741 - val_loss: 0.5651 - val_accuracy: 0.8235\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.7259 - accuracy: 0.7707 - val_loss: 0.5461 - val_accuracy: 0.8277\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.6965 - accuracy: 0.7807 - val_loss: 0.5549 - val_accuracy: 0.8260\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6873 - accuracy: 0.7826 - val_loss: 0.5343 - val_accuracy: 0.8337\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6670 - accuracy: 0.7895 - val_loss: 0.5064 - val_accuracy: 0.8413\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6687 - accuracy: 0.7876 - val_loss: 0.5161 - val_accuracy: 0.8393\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6922 - accuracy: 0.7798 - val_loss: 0.5259 - val_accuracy: 0.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6738 - accuracy: 0.7853 - val_loss: 0.4998 - val_accuracy: 0.8440\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.6402 - accuracy: 0.7980 - val_loss: 0.4992 - val_accuracy: 0.8459\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6505 - accuracy: 0.7938 - val_loss: 0.4977 - val_accuracy: 0.8458\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6108 - accuracy: 0.8072 - val_loss: 0.4894 - val_accuracy: 0.8475\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6623 - accuracy: 0.7873 - val_loss: 0.4790 - val_accuracy: 0.8503\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.6075 - accuracy: 0.8077 - val_loss: 0.4987 - val_accuracy: 0.8451\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6350 - accuracy: 0.7981 - val_loss: 0.4645 - val_accuracy: 0.8562\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5979 - accuracy: 0.8106 - val_loss: 0.4673 - val_accuracy: 0.8552\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6458 - accuracy: 0.7955 - val_loss: 0.4603 - val_accuracy: 0.8576\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6296 - accuracy: 0.7995 - val_loss: 0.4769 - val_accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.5982 - accuracy: 0.8108 - val_loss: 0.4741 - val_accuracy: 0.8524\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.6062 - accuracy: 0.8074 - val_loss: 0.4525 - val_accuracy: 0.8589\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5812 - accuracy: 0.8155 - val_loss: 0.4620 - val_accuracy: 0.8569\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5923 - accuracy: 0.8132 - val_loss: 0.4723 - val_accuracy: 0.8537\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.5823 - accuracy: 0.8155 - val_loss: 0.4435 - val_accuracy: 0.8618\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5868 - accuracy: 0.8136 - val_loss: 0.4337 - val_accuracy: 0.8650\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5611 - accuracy: 0.8214 - val_loss: 0.4429 - val_accuracy: 0.8618\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4429 - accuracy: 0.8618\n",
      "Accuracy on the Validation Data is 0.8617500066757202 and the loss is 0.4428771436214447\n",
      "For Hidden Layer 1 neurons =  539 ,Hidden Layer 2 neurons =  297 & Hidden Layer 3 neurons =  154 ; also Droput of 0.4811091380135907\n",
      "\n",
      "\n",
      "--------------------------- Loop 7 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 2.4108 - accuracy: 0.1037 - val_loss: 2.5755 - val_accuracy: 0.1069\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 2.1452 - accuracy: 0.1957 - val_loss: 1.8440 - val_accuracy: 0.3453\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 1.5929 - accuracy: 0.4350 - val_loss: 1.6644 - val_accuracy: 0.4489\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 140ms/step - loss: 1.2416 - accuracy: 0.5852 - val_loss: 1.4471 - val_accuracy: 0.6023\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 1.0275 - accuracy: 0.6674 - val_loss: 1.2994 - val_accuracy: 0.6527\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 0.9283 - accuracy: 0.7029 - val_loss: 1.1418 - val_accuracy: 0.6941\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.8572 - accuracy: 0.7256 - val_loss: 1.0386 - val_accuracy: 0.7234\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.7991 - accuracy: 0.7454 - val_loss: 0.9023 - val_accuracy: 0.7540\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.7915 - accuracy: 0.7475 - val_loss: 0.7753 - val_accuracy: 0.7823\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.7456 - accuracy: 0.7619 - val_loss: 0.7079 - val_accuracy: 0.7953\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.7127 - accuracy: 0.7717 - val_loss: 0.7481 - val_accuracy: 0.7750\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.7313 - accuracy: 0.7660 - val_loss: 0.6970 - val_accuracy: 0.7839\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.6578 - accuracy: 0.7909 - val_loss: 0.5596 - val_accuracy: 0.8250\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.6044 - accuracy: 0.8095 - val_loss: 0.6008 - val_accuracy: 0.8126\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.5969 - accuracy: 0.8097 - val_loss: 0.5333 - val_accuracy: 0.8331\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.5745 - accuracy: 0.8179 - val_loss: 0.5449 - val_accuracy: 0.8302\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.5822 - accuracy: 0.8146 - val_loss: 0.5037 - val_accuracy: 0.8406\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 4s 192ms/step - loss: 0.5592 - accuracy: 0.8216 - val_loss: 0.5407 - val_accuracy: 0.8315\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.5672 - accuracy: 0.8198 - val_loss: 0.5031 - val_accuracy: 0.8395\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 0.5524 - accuracy: 0.8234 - val_loss: 0.5154 - val_accuracy: 0.8375\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.5388 - accuracy: 0.8274 - val_loss: 0.4749 - val_accuracy: 0.8525\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.5003 - accuracy: 0.8413 - val_loss: 0.5115 - val_accuracy: 0.8420\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.5573 - accuracy: 0.8206 - val_loss: 0.4806 - val_accuracy: 0.8515\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 0.4951 - accuracy: 0.8415 - val_loss: 0.4348 - val_accuracy: 0.8651\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.5059 - accuracy: 0.8377 - val_loss: 0.4545 - val_accuracy: 0.8570\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.4732 - accuracy: 0.8498 - val_loss: 0.4421 - val_accuracy: 0.8633\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.5344 - accuracy: 0.8277 - val_loss: 0.4346 - val_accuracy: 0.8677\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.4683 - accuracy: 0.8506 - val_loss: 0.4380 - val_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.4985 - accuracy: 0.8410 - val_loss: 0.4340 - val_accuracy: 0.8646\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.5196 - accuracy: 0.8328 - val_loss: 0.4293 - val_accuracy: 0.8660\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.4671 - accuracy: 0.8512 - val_loss: 0.4213 - val_accuracy: 0.8705\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 4s 191ms/step - loss: 0.4521 - accuracy: 0.8553 - val_loss: 0.4197 - val_accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.4392 - accuracy: 0.8591 - val_loss: 0.4058 - val_accuracy: 0.8765\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.4620 - accuracy: 0.8506 - val_loss: 0.4195 - val_accuracy: 0.8701\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.4266 - accuracy: 0.8645 - val_loss: 0.3987 - val_accuracy: 0.8763\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.4190 - accuracy: 0.8655 - val_loss: 0.3835 - val_accuracy: 0.8816\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3909 - accuracy: 0.8742 - val_loss: 0.3988 - val_accuracy: 0.8773\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.3992 - accuracy: 0.8738 - val_loss: 0.3901 - val_accuracy: 0.8781\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3856 - accuracy: 0.8754 - val_loss: 0.3943 - val_accuracy: 0.8788\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.3855 - accuracy: 0.8755 - val_loss: 0.3625 - val_accuracy: 0.8890\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3720 - accuracy: 0.8812 - val_loss: 0.3805 - val_accuracy: 0.8829\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.3887 - accuracy: 0.8737 - val_loss: 0.3681 - val_accuracy: 0.8865\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.4064 - accuracy: 0.8681 - val_loss: 0.3918 - val_accuracy: 0.8782\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.4072 - accuracy: 0.8682 - val_loss: 0.3590 - val_accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.3879 - accuracy: 0.8741 - val_loss: 0.3777 - val_accuracy: 0.8836\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 0.3824 - accuracy: 0.8765 - val_loss: 0.3572 - val_accuracy: 0.8906\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3772 - accuracy: 0.8770 - val_loss: 0.3609 - val_accuracy: 0.8895\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.4182 - accuracy: 0.8647 - val_loss: 0.3852 - val_accuracy: 0.8837\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3733 - accuracy: 0.8787 - val_loss: 0.3508 - val_accuracy: 0.8922\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3811 - accuracy: 0.8753 - val_loss: 0.3642 - val_accuracy: 0.8890\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3642 - accuracy: 0.8890\n",
      "Accuracy on the Validation Data is 0.8890416622161865 and the loss is 0.3642300069332123\n",
      "For Hidden Layer 1 neurons =  968 ,Hidden Layer 2 neurons =  431 & Hidden Layer 3 neurons =  121 ; also Droput of 0.33645146775170587\n",
      "\n",
      "\n",
      "--------------------------- Loop 8 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 2.3631 - accuracy: 0.1182 - val_loss: 2.4942 - val_accuracy: 0.1190\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.9545 - accuracy: 0.2864 - val_loss: 1.6107 - val_accuracy: 0.4114\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 1.3635 - accuracy: 0.5374 - val_loss: 1.3193 - val_accuracy: 0.6079\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.1164 - accuracy: 0.6362 - val_loss: 1.1511 - val_accuracy: 0.6859\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.0466 - accuracy: 0.6606 - val_loss: 0.9599 - val_accuracy: 0.7106\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.9056 - accuracy: 0.7097 - val_loss: 0.8626 - val_accuracy: 0.7442\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.8373 - accuracy: 0.7319 - val_loss: 0.8367 - val_accuracy: 0.7390\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.7944 - accuracy: 0.7472 - val_loss: 0.7409 - val_accuracy: 0.7660\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.7953 - accuracy: 0.7453 - val_loss: 0.6623 - val_accuracy: 0.7980\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7352 - accuracy: 0.7657 - val_loss: 0.6570 - val_accuracy: 0.7932\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7449 - accuracy: 0.7629 - val_loss: 0.6463 - val_accuracy: 0.7971\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6719 - accuracy: 0.7864 - val_loss: 0.5796 - val_accuracy: 0.8183\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.6541 - accuracy: 0.7930 - val_loss: 0.5578 - val_accuracy: 0.8227\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6648 - accuracy: 0.7889 - val_loss: 0.5736 - val_accuracy: 0.8196\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.6417 - accuracy: 0.7959 - val_loss: 0.5381 - val_accuracy: 0.8297\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6378 - accuracy: 0.7954 - val_loss: 0.5337 - val_accuracy: 0.8336\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.6238 - accuracy: 0.8013 - val_loss: 0.5331 - val_accuracy: 0.8318\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5808 - accuracy: 0.8158 - val_loss: 0.5301 - val_accuracy: 0.8337\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6312 - accuracy: 0.7971 - val_loss: 0.5262 - val_accuracy: 0.8372\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5710 - accuracy: 0.8183 - val_loss: 0.5160 - val_accuracy: 0.8385\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5685 - accuracy: 0.8181 - val_loss: 0.4647 - val_accuracy: 0.8545\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5713 - accuracy: 0.8179 - val_loss: 0.4561 - val_accuracy: 0.8592\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5287 - accuracy: 0.8318 - val_loss: 0.4696 - val_accuracy: 0.8529\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5357 - accuracy: 0.8301 - val_loss: 0.4578 - val_accuracy: 0.8565\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5152 - accuracy: 0.8365 - val_loss: 0.4451 - val_accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5541 - accuracy: 0.8208 - val_loss: 0.4457 - val_accuracy: 0.8617\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.5464 - accuracy: 0.8256 - val_loss: 0.4400 - val_accuracy: 0.8632\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.5106 - accuracy: 0.8360 - val_loss: 0.4426 - val_accuracy: 0.8622\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5240 - accuracy: 0.8329 - val_loss: 0.4303 - val_accuracy: 0.8678\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.5035 - accuracy: 0.8383 - val_loss: 0.4128 - val_accuracy: 0.8712\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4786 - accuracy: 0.8474 - val_loss: 0.4209 - val_accuracy: 0.8698\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.4905 - accuracy: 0.8432 - val_loss: 0.4242 - val_accuracy: 0.8687\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.4596 - accuracy: 0.8534 - val_loss: 0.4139 - val_accuracy: 0.8715\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.4921 - accuracy: 0.8425 - val_loss: 0.4267 - val_accuracy: 0.8668\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5093 - accuracy: 0.8356 - val_loss: 0.4099 - val_accuracy: 0.8712\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4873 - accuracy: 0.8434 - val_loss: 0.4056 - val_accuracy: 0.8737\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.4413 - accuracy: 0.8589 - val_loss: 0.4027 - val_accuracy: 0.8753\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4603 - accuracy: 0.8526 - val_loss: 0.3981 - val_accuracy: 0.8763\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4663 - accuracy: 0.8493 - val_loss: 0.3988 - val_accuracy: 0.8758\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8758: 0s - loss: 0.397\n",
      "Accuracy on the Validation Data is 0.8757916688919067 and the loss is 0.3987632095813751\n",
      "For Hidden Layer 1 neurons =  500 ,Hidden Layer 2 neurons =  434 & Hidden Layer 3 neurons =  93 ; also Droput of 0.36502077782502557\n",
      "\n",
      "\n",
      "--------------------------- Loop 9 ---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 2.3917 - accuracy: 0.1065 - val_loss: 2.6814 - val_accuracy: 0.1066\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 2.1042 - accuracy: 0.2126 - val_loss: 1.7858 - val_accuracy: 0.3422\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 1.5442 - accuracy: 0.4561 - val_loss: 1.4415 - val_accuracy: 0.5572\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.2038 - accuracy: 0.6008 - val_loss: 1.1943 - val_accuracy: 0.6464\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 1.0535 - accuracy: 0.6603 - val_loss: 1.0882 - val_accuracy: 0.6734\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.0257 - accuracy: 0.6691 - val_loss: 0.8762 - val_accuracy: 0.7440\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.9299 - accuracy: 0.7015 - val_loss: 0.8099 - val_accuracy: 0.7563\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.9118 - accuracy: 0.7093 - val_loss: 0.7665 - val_accuracy: 0.7639\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.8597 - accuracy: 0.7272 - val_loss: 0.6923 - val_accuracy: 0.7856\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.8869 - accuracy: 0.7165 - val_loss: 0.6837 - val_accuracy: 0.7849\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.8256 - accuracy: 0.7374 - val_loss: 0.6695 - val_accuracy: 0.7892\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7940 - accuracy: 0.7479 - val_loss: 0.6369 - val_accuracy: 0.8002\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.7722 - accuracy: 0.7550 - val_loss: 0.6079 - val_accuracy: 0.8080\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.7771 - accuracy: 0.7516 - val_loss: 0.5975 - val_accuracy: 0.8133\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.7612 - accuracy: 0.7578 - val_loss: 0.6001 - val_accuracy: 0.8127\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7165 - accuracy: 0.7729 - val_loss: 0.5697 - val_accuracy: 0.8208\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6963 - accuracy: 0.7776 - val_loss: 0.5935 - val_accuracy: 0.8122\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.6963 - accuracy: 0.7798 - val_loss: 0.5534 - val_accuracy: 0.8255\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.7072 - accuracy: 0.7748 - val_loss: 0.5456 - val_accuracy: 0.8288\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6874 - accuracy: 0.7799 - val_loss: 0.5491 - val_accuracy: 0.8293\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6626 - accuracy: 0.7878 - val_loss: 0.5284 - val_accuracy: 0.8362\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6676 - accuracy: 0.7890 - val_loss: 0.5074 - val_accuracy: 0.8432\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.6242 - accuracy: 0.8036 - val_loss: 0.4982 - val_accuracy: 0.8455\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6428 - accuracy: 0.7965 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.6159 - accuracy: 0.8058 - val_loss: 0.4919 - val_accuracy: 0.8450\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6319 - accuracy: 0.7998 - val_loss: 0.4775 - val_accuracy: 0.8519\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.5955 - accuracy: 0.8121 - val_loss: 0.4756 - val_accuracy: 0.8519\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5747 - accuracy: 0.8179 - val_loss: 0.4690 - val_accuracy: 0.8547\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.5938 - accuracy: 0.8124 - val_loss: 0.4808 - val_accuracy: 0.8490\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.5730 - accuracy: 0.8179 - val_loss: 0.4622 - val_accuracy: 0.8569\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.5579 - accuracy: 0.8231 - val_loss: 0.4571 - val_accuracy: 0.8578\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5955 - accuracy: 0.8112 - val_loss: 0.4641 - val_accuracy: 0.8558\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5542 - accuracy: 0.8239 - val_loss: 0.4455 - val_accuracy: 0.8618\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5584 - accuracy: 0.8233 - val_loss: 0.4282 - val_accuracy: 0.8685\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5444 - accuracy: 0.8269 - val_loss: 0.4402 - val_accuracy: 0.8637\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.5849 - accuracy: 0.8126 - val_loss: 0.4439 - val_accuracy: 0.8626\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5333 - accuracy: 0.8313 - val_loss: 0.4380 - val_accuracy: 0.8639\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.5592 - accuracy: 0.8224 - val_loss: 0.4224 - val_accuracy: 0.8695\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5487 - accuracy: 0.8254 - val_loss: 0.4232 - val_accuracy: 0.8677\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5320 - accuracy: 0.8305 - val_loss: 0.4510 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.5931 - accuracy: 0.8101 - val_loss: 0.4221 - val_accuracy: 0.8690\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5389 - accuracy: 0.8288 - val_loss: 0.4213 - val_accuracy: 0.8687\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5153 - accuracy: 0.8353 - val_loss: 0.4230 - val_accuracy: 0.8665\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.5424 - accuracy: 0.8265 - val_loss: 0.4077 - val_accuracy: 0.8733\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8733\n",
      "Accuracy on the Validation Data is 0.8733333349227905 and the loss is 0.40773847699165344\n",
      "For Hidden Layer 1 neurons =  796 ,Hidden Layer 2 neurons =  305 & Hidden Layer 3 neurons =  153 ; also Droput of 0.47153204400438764\n",
      "\n",
      "\n",
      "--------------------------- Loop 10 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 2.4292 - accuracy: 0.1036 - val_loss: 2.8694 - val_accuracy: 0.1018\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 2.2453 - accuracy: 0.1526 - val_loss: 1.9952 - val_accuracy: 0.2541\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 1.6288 - accuracy: 0.4217 - val_loss: 1.7533 - val_accuracy: 0.4329\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 1.2035 - accuracy: 0.5994 - val_loss: 1.6523 - val_accuracy: 0.5216\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 1.0391 - accuracy: 0.6651 - val_loss: 1.4614 - val_accuracy: 0.6064\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.8927 - accuracy: 0.7144 - val_loss: 1.3018 - val_accuracy: 0.6568\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.8234 - accuracy: 0.7361 - val_loss: 1.1982 - val_accuracy: 0.6797\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.8156 - accuracy: 0.7377 - val_loss: 1.0091 - val_accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.7388 - accuracy: 0.7642 - val_loss: 0.9065 - val_accuracy: 0.7754\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.6591 - accuracy: 0.7901 - val_loss: 0.8664 - val_accuracy: 0.7581\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.6542 - accuracy: 0.7928 - val_loss: 0.7839 - val_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.6310 - accuracy: 0.7993 - val_loss: 0.7179 - val_accuracy: 0.7856\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6238 - accuracy: 0.8019 - val_loss: 0.6355 - val_accuracy: 0.8062\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.5774 - accuracy: 0.8153 - val_loss: 0.6308 - val_accuracy: 0.8051\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.5556 - accuracy: 0.8229 - val_loss: 0.5509 - val_accuracy: 0.8310\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.5280 - accuracy: 0.8323 - val_loss: 0.5985 - val_accuracy: 0.8100\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.5071 - accuracy: 0.8383 - val_loss: 0.5495 - val_accuracy: 0.8271\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4835 - accuracy: 0.8446 - val_loss: 0.5899 - val_accuracy: 0.8180\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.5014 - accuracy: 0.8391 - val_loss: 0.4967 - val_accuracy: 0.8436\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.4689 - accuracy: 0.8505 - val_loss: 0.4705 - val_accuracy: 0.8524\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.4477 - accuracy: 0.8569 - val_loss: 0.4869 - val_accuracy: 0.8512\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.4387 - accuracy: 0.8590 - val_loss: 0.4707 - val_accuracy: 0.8531\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.4147 - accuracy: 0.8674 - val_loss: 0.4782 - val_accuracy: 0.8543\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.4202 - accuracy: 0.8661 - val_loss: 0.4957 - val_accuracy: 0.8455\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.4482 - accuracy: 0.8562 - val_loss: 0.4715 - val_accuracy: 0.8549\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4447 - accuracy: 0.8566 - val_loss: 0.4185 - val_accuracy: 0.8725\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3767 - accuracy: 0.8776 - val_loss: 0.4411 - val_accuracy: 0.8639\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.3873 - accuracy: 0.8745 - val_loss: 0.4432 - val_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4344 - accuracy: 0.8595 - val_loss: 0.4751 - val_accuracy: 0.8583\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4732 - accuracy: 0.8461 - val_loss: 0.4560 - val_accuracy: 0.8615\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3909 - accuracy: 0.8747 - val_loss: 0.3969 - val_accuracy: 0.8777\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.3678 - accuracy: 0.8808 - val_loss: 0.4178 - val_accuracy: 0.8733\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3543 - accuracy: 0.8848 - val_loss: 0.4319 - val_accuracy: 0.8700\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.3556 - accuracy: 0.8847 - val_loss: 0.3815 - val_accuracy: 0.8835\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.3869 - accuracy: 0.8744 - val_loss: 0.3961 - val_accuracy: 0.8810\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.3557 - accuracy: 0.8843 - val_loss: 0.3843 - val_accuracy: 0.8855\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3407 - accuracy: 0.8897 - val_loss: 0.3981 - val_accuracy: 0.8805\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3311 - accuracy: 0.8920 - val_loss: 0.3743 - val_accuracy: 0.8884\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3396 - accuracy: 0.8889 - val_loss: 0.3637 - val_accuracy: 0.8915\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3233 - accuracy: 0.8949 - val_loss: 0.3576 - val_accuracy: 0.8939\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.2991 - accuracy: 0.9032 - val_loss: 0.3725 - val_accuracy: 0.8912\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3236 - accuracy: 0.8952 - val_loss: 0.3466 - val_accuracy: 0.8977\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.2939 - accuracy: 0.9044 - val_loss: 0.3450 - val_accuracy: 0.8971\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3171 - accuracy: 0.8967 - val_loss: 0.3404 - val_accuracy: 0.8993\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.2737 - accuracy: 0.9106 - val_loss: 0.3541 - val_accuracy: 0.8956\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3174 - accuracy: 0.8961 - val_loss: 0.3615 - val_accuracy: 0.8957\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.2844 - accuracy: 0.9080 - val_loss: 0.3563 - val_accuracy: 0.8980\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.2593 - accuracy: 0.9144 - val_loss: 0.3652 - val_accuracy: 0.8953\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.3149 - accuracy: 0.8973 - val_loss: 0.3394 - val_accuracy: 0.9012\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.2580 - accuracy: 0.9154 - val_loss: 0.3723 - val_accuracy: 0.8911\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3723 - accuracy: 0.8911\n",
      "Accuracy on the Validation Data is 0.8911250233650208 and the loss is 0.37228742241859436\n",
      "For Hidden Layer 1 neurons =  894 ,Hidden Layer 2 neurons =  471 & Hidden Layer 3 neurons =  150 ; also Droput of 0.21117976758873822\n",
      "\n",
      "\n",
      "--------------------------- Loop 11 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 2.3851 - accuracy: 0.1038 - val_loss: 2.4517 - val_accuracy: 0.1059\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 2.2720 - accuracy: 0.1356 - val_loss: 2.1554 - val_accuracy: 0.1945\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 1.8303 - accuracy: 0.3302 - val_loss: 1.8383 - val_accuracy: 0.3522\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 1.3735 - accuracy: 0.5308 - val_loss: 1.6638 - val_accuracy: 0.4660\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 1.1022 - accuracy: 0.6391 - val_loss: 1.5185 - val_accuracy: 0.5577\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.0278 - accuracy: 0.6669 - val_loss: 1.3926 - val_accuracy: 0.5837\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.9058 - accuracy: 0.7104 - val_loss: 1.2913 - val_accuracy: 0.6580\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.9010 - accuracy: 0.7124 - val_loss: 1.1329 - val_accuracy: 0.7022\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.8114 - accuracy: 0.7413 - val_loss: 1.0357 - val_accuracy: 0.7150\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.8147 - accuracy: 0.7402 - val_loss: 0.8969 - val_accuracy: 0.7464\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.7559 - accuracy: 0.7598 - val_loss: 0.7889 - val_accuracy: 0.7836\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.7059 - accuracy: 0.7766 - val_loss: 0.7133 - val_accuracy: 0.7999\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.6644 - accuracy: 0.7902 - val_loss: 0.6637 - val_accuracy: 0.8078\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.6505 - accuracy: 0.7943 - val_loss: 0.7521 - val_accuracy: 0.7617\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 109ms/step - loss: 0.7008 - accuracy: 0.7759 - val_loss: 0.6903 - val_accuracy: 0.7818\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.6616 - accuracy: 0.7916 - val_loss: 0.5885 - val_accuracy: 0.8171\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.6375 - accuracy: 0.7969 - val_loss: 0.6060 - val_accuracy: 0.8103\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.5900 - accuracy: 0.8129 - val_loss: 0.5415 - val_accuracy: 0.8307\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.5805 - accuracy: 0.8164 - val_loss: 0.5075 - val_accuracy: 0.8433\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5394 - accuracy: 0.8292 - val_loss: 0.5731 - val_accuracy: 0.8206\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5713 - accuracy: 0.8173 - val_loss: 0.6135 - val_accuracy: 0.8068\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.5466 - accuracy: 0.8258 - val_loss: 0.5107 - val_accuracy: 0.8407\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5263 - accuracy: 0.8333 - val_loss: 0.4910 - val_accuracy: 0.8477\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.5760 - accuracy: 0.8172 - val_loss: 0.5128 - val_accuracy: 0.8389\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5373 - accuracy: 0.8292 - val_loss: 0.5026 - val_accuracy: 0.8416\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.5285 - accuracy: 0.8328 - val_loss: 0.4627 - val_accuracy: 0.8544\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5453 - accuracy: 0.8248 - val_loss: 0.5024 - val_accuracy: 0.8424\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5470 - accuracy: 0.8253 - val_loss: 0.4572 - val_accuracy: 0.8567\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.4897 - accuracy: 0.8436 - val_loss: 0.4960 - val_accuracy: 0.8466\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.5358 - accuracy: 0.8270 - val_loss: 0.4495 - val_accuracy: 0.8599\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4771 - accuracy: 0.8487 - val_loss: 0.4941 - val_accuracy: 0.8484\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4725 - accuracy: 0.8493 - val_loss: 0.5108 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.4916 - accuracy: 0.8425 - val_loss: 0.4520 - val_accuracy: 0.8592\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.4424 - accuracy: 0.8590 - val_loss: 0.4490 - val_accuracy: 0.8605\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4631 - accuracy: 0.8515 - val_loss: 0.4504 - val_accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4196 - accuracy: 0.8663 - val_loss: 0.4300 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4625 - accuracy: 0.8516 - val_loss: 0.4603 - val_accuracy: 0.8568\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.4350 - accuracy: 0.8613 - val_loss: 0.4391 - val_accuracy: 0.8642\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.4531 - accuracy: 0.8544 - val_loss: 0.4180 - val_accuracy: 0.8694\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4765 - accuracy: 0.8464 - val_loss: 0.4049 - val_accuracy: 0.8747\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4381 - accuracy: 0.8604 - val_loss: 0.4002 - val_accuracy: 0.8751\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4153 - accuracy: 0.8667 - val_loss: 0.4156 - val_accuracy: 0.8732\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.4207 - accuracy: 0.8663 - val_loss: 0.4217 - val_accuracy: 0.8721\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.4692 - accuracy: 0.8502 - val_loss: 0.3911 - val_accuracy: 0.8808\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4244 - accuracy: 0.8646 - val_loss: 0.4133 - val_accuracy: 0.8740\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.4343 - accuracy: 0.8608 - val_loss: 0.3976 - val_accuracy: 0.8759\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.4485 - accuracy: 0.8555 - val_loss: 0.4598 - val_accuracy: 0.8572\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.4264 - accuracy: 0.8634 - val_loss: 0.4465 - val_accuracy: 0.8629\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.4403 - accuracy: 0.8578 - val_loss: 0.3859 - val_accuracy: 0.8823\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.3863 - accuracy: 0.8767 - val_loss: 0.3735 - val_accuracy: 0.8859\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.3753 - accuracy: 0.8796 - val_loss: 0.3791 - val_accuracy: 0.8836\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3816 - accuracy: 0.8766 - val_loss: 0.3934 - val_accuracy: 0.8789\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.4463 - accuracy: 0.8561 - val_loss: 0.3737 - val_accuracy: 0.8855\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.3989 - accuracy: 0.8712 - val_loss: 0.3796 - val_accuracy: 0.8822\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.8822\n",
      "Accuracy on the Validation Data is 0.8822083473205566 and the loss is 0.37957707047462463\n",
      "For Hidden Layer 1 neurons =  855 ,Hidden Layer 2 neurons =  218 & Hidden Layer 3 neurons =  88 ; also Droput of 0.2583115475793326\n",
      "\n",
      "\n",
      "--------------------------- Loop 12 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 2.3772 - accuracy: 0.1075 - val_loss: 2.4985 - val_accuracy: 0.1038\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 2.1711 - accuracy: 0.1810 - val_loss: 1.9502 - val_accuracy: 0.3278\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 1.5486 - accuracy: 0.4631 - val_loss: 1.7015 - val_accuracy: 0.4609\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 1.1677 - accuracy: 0.6161 - val_loss: 1.5531 - val_accuracy: 0.5552\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.9629 - accuracy: 0.6909 - val_loss: 1.4144 - val_accuracy: 0.6073\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.9357 - accuracy: 0.6982 - val_loss: 1.2572 - val_accuracy: 0.6596\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.8848 - accuracy: 0.7155 - val_loss: 1.1354 - val_accuracy: 0.6835\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.8477 - accuracy: 0.7278 - val_loss: 0.9418 - val_accuracy: 0.7518\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.7771 - accuracy: 0.7527 - val_loss: 0.8007 - val_accuracy: 0.7803\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.7312 - accuracy: 0.7677 - val_loss: 0.7878 - val_accuracy: 0.7659\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.6841 - accuracy: 0.7838 - val_loss: 0.6813 - val_accuracy: 0.7981\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6700 - accuracy: 0.7869 - val_loss: 0.7905 - val_accuracy: 0.7625\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.7000 - accuracy: 0.7782 - val_loss: 0.6489 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6086 - accuracy: 0.8069 - val_loss: 0.5793 - val_accuracy: 0.8188\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.6085 - accuracy: 0.8060 - val_loss: 0.5976 - val_accuracy: 0.8152\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.5772 - accuracy: 0.8173 - val_loss: 0.5518 - val_accuracy: 0.8267\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.5389 - accuracy: 0.8287 - val_loss: 0.6226 - val_accuracy: 0.8097\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5344 - accuracy: 0.8307 - val_loss: 0.5227 - val_accuracy: 0.8337\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.5385 - accuracy: 0.8277 - val_loss: 0.5004 - val_accuracy: 0.8440\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.4855 - accuracy: 0.8446 - val_loss: 0.4885 - val_accuracy: 0.8480\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4872 - accuracy: 0.8442 - val_loss: 0.5401 - val_accuracy: 0.8334\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.4737 - accuracy: 0.8490 - val_loss: 0.4885 - val_accuracy: 0.8475\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.5030 - accuracy: 0.8383 - val_loss: 0.5290 - val_accuracy: 0.8393\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.5006 - accuracy: 0.8388 - val_loss: 0.4807 - val_accuracy: 0.8521\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.4662 - accuracy: 0.8525 - val_loss: 0.5313 - val_accuracy: 0.8378\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.4537 - accuracy: 0.8555 - val_loss: 0.4359 - val_accuracy: 0.8648\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.4982 - accuracy: 0.8408 - val_loss: 0.4425 - val_accuracy: 0.8617\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.4640 - accuracy: 0.8521 - val_loss: 0.4488 - val_accuracy: 0.8603\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4499 - accuracy: 0.8566 - val_loss: 0.4407 - val_accuracy: 0.8627\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.4237 - accuracy: 0.8634 - val_loss: 0.4182 - val_accuracy: 0.8724\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.4117 - accuracy: 0.8682 - val_loss: 0.4211 - val_accuracy: 0.8695\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.4835 - accuracy: 0.8432 - val_loss: 0.4326 - val_accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.4392 - accuracy: 0.8591 - val_loss: 0.4004 - val_accuracy: 0.8766\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.3944 - accuracy: 0.8742 - val_loss: 0.4182 - val_accuracy: 0.8742\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.3890 - accuracy: 0.8751 - val_loss: 0.4031 - val_accuracy: 0.8764\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.3924 - accuracy: 0.8732 - val_loss: 0.4040 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.4128 - accuracy: 0.8675 - val_loss: 0.4282 - val_accuracy: 0.8680\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.4370 - accuracy: 0.8578 - val_loss: 0.4188 - val_accuracy: 0.8728\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.4239 - accuracy: 0.8636 - val_loss: 0.3898 - val_accuracy: 0.8815\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.3565 - accuracy: 0.8856 - val_loss: 0.3937 - val_accuracy: 0.8794\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.3532 - accuracy: 0.8862 - val_loss: 0.3742 - val_accuracy: 0.8846\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.3705 - accuracy: 0.8800 - val_loss: 0.3985 - val_accuracy: 0.8818\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.3636 - accuracy: 0.8823 - val_loss: 0.4108 - val_accuracy: 0.8770\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.8770\n",
      "Accuracy on the Validation Data is 0.8769583106040955 and the loss is 0.410762220621109\n",
      "For Hidden Layer 1 neurons =  906 ,Hidden Layer 2 neurons =  319 & Hidden Layer 3 neurons =  82 ; also Droput of 0.24011416412070552\n",
      "\n",
      "\n",
      "--------------------------- Loop 13 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 2.3905 - accuracy: 0.1066 - val_loss: 2.4954 - val_accuracy: 0.1132\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 2.1231 - accuracy: 0.2027 - val_loss: 1.8356 - val_accuracy: 0.3517\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 1.5423 - accuracy: 0.4603 - val_loss: 1.5832 - val_accuracy: 0.5244\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 1.2001 - accuracy: 0.6048 - val_loss: 1.3649 - val_accuracy: 0.6510\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 1.1185 - accuracy: 0.6360 - val_loss: 1.1749 - val_accuracy: 0.6971\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.9797 - accuracy: 0.6855 - val_loss: 1.0480 - val_accuracy: 0.7096\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.9580 - accuracy: 0.6933 - val_loss: 0.9016 - val_accuracy: 0.7524\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.8851 - accuracy: 0.7172 - val_loss: 0.8458 - val_accuracy: 0.7530\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.8279 - accuracy: 0.7363 - val_loss: 0.8052 - val_accuracy: 0.7548\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.8266 - accuracy: 0.7367 - val_loss: 0.7365 - val_accuracy: 0.7737\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.8102 - accuracy: 0.7413 - val_loss: 0.6589 - val_accuracy: 0.7984\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.7770 - accuracy: 0.7533 - val_loss: 0.7125 - val_accuracy: 0.7784\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7750 - accuracy: 0.7529 - val_loss: 0.6624 - val_accuracy: 0.7887\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.7485 - accuracy: 0.7623 - val_loss: 0.6076 - val_accuracy: 0.8095\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.7247 - accuracy: 0.7717 - val_loss: 0.5836 - val_accuracy: 0.8163\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7107 - accuracy: 0.7751 - val_loss: 0.5934 - val_accuracy: 0.8133\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.7218 - accuracy: 0.7704 - val_loss: 0.5476 - val_accuracy: 0.8312\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6807 - accuracy: 0.7841 - val_loss: 0.5310 - val_accuracy: 0.8350\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6689 - accuracy: 0.7880 - val_loss: 0.5261 - val_accuracy: 0.8357\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6310 - accuracy: 0.8022 - val_loss: 0.5453 - val_accuracy: 0.8303\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.6690 - accuracy: 0.7885 - val_loss: 0.5188 - val_accuracy: 0.8366\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6085 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.8439\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6401 - accuracy: 0.7985 - val_loss: 0.5183 - val_accuracy: 0.8378\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.5915 - accuracy: 0.8127 - val_loss: 0.4921 - val_accuracy: 0.8443\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5792 - accuracy: 0.8152 - val_loss: 0.4686 - val_accuracy: 0.8539\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5782 - accuracy: 0.8161 - val_loss: 0.4794 - val_accuracy: 0.8489\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.5673 - accuracy: 0.8209 - val_loss: 0.4543 - val_accuracy: 0.8588\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.5683 - accuracy: 0.8204 - val_loss: 0.4518 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.5751 - accuracy: 0.8181 - val_loss: 0.4752 - val_accuracy: 0.8521\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5926 - accuracy: 0.8113 - val_loss: 0.4660 - val_accuracy: 0.8530\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.5906 - accuracy: 0.8105 - val_loss: 0.4720 - val_accuracy: 0.8533\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.5833 - accuracy: 0.8133 - val_loss: 0.4489 - val_accuracy: 0.8602\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5843 - accuracy: 0.8130 - val_loss: 0.4381 - val_accuracy: 0.8648\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.5363 - accuracy: 0.8291 - val_loss: 0.4327 - val_accuracy: 0.8643\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.5622 - accuracy: 0.8209 - val_loss: 0.4344 - val_accuracy: 0.8647\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.5247 - accuracy: 0.8325 - val_loss: 0.4490 - val_accuracy: 0.8605\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.5252 - accuracy: 0.8343 - val_loss: 0.4343 - val_accuracy: 0.8653\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.4343 - accuracy: 0.8653\n",
      "Accuracy on the Validation Data is 0.8652916550636292 and the loss is 0.43425387144088745\n",
      "For Hidden Layer 1 neurons =  813 ,Hidden Layer 2 neurons =  386 & Hidden Layer 3 neurons =  129 ; also Droput of 0.4709148066529542\n",
      "\n",
      "\n",
      "--------------------------- Loop 14 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 2.3494 - accuracy: 0.1249 - val_loss: 2.4713 - val_accuracy: 0.1603\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.8141 - accuracy: 0.3422 - val_loss: 1.5620 - val_accuracy: 0.4613\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 1.3015 - accuracy: 0.5645 - val_loss: 1.2632 - val_accuracy: 0.6319\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 1.0704 - accuracy: 0.6522 - val_loss: 1.1816 - val_accuracy: 0.6462\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 1.0065 - accuracy: 0.6748 - val_loss: 0.9895 - val_accuracy: 0.7072\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8927 - accuracy: 0.7138 - val_loss: 0.8456 - val_accuracy: 0.7423\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.8196 - accuracy: 0.7393 - val_loss: 0.7637 - val_accuracy: 0.7674\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.7847 - accuracy: 0.7494 - val_loss: 0.7707 - val_accuracy: 0.7633\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.7926 - accuracy: 0.7460 - val_loss: 0.6670 - val_accuracy: 0.7904\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.7042 - accuracy: 0.7767 - val_loss: 0.7261 - val_accuracy: 0.7717\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.6980 - accuracy: 0.7793 - val_loss: 0.5917 - val_accuracy: 0.8139\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.6528 - accuracy: 0.7930 - val_loss: 0.6142 - val_accuracy: 0.8067\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.6660 - accuracy: 0.7870 - val_loss: 0.5647 - val_accuracy: 0.8227\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.6319 - accuracy: 0.7992 - val_loss: 0.5915 - val_accuracy: 0.8123\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.6236 - accuracy: 0.8014 - val_loss: 0.5331 - val_accuracy: 0.8316\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5899 - accuracy: 0.8132 - val_loss: 0.6029 - val_accuracy: 0.8114\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5951 - accuracy: 0.8098 - val_loss: 0.5048 - val_accuracy: 0.8409\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5607 - accuracy: 0.8211 - val_loss: 0.4987 - val_accuracy: 0.8425\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5406 - accuracy: 0.8279 - val_loss: 0.5126 - val_accuracy: 0.8395\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 78ms/step - loss: 0.5608 - accuracy: 0.8206 - val_loss: 0.4961 - val_accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5311 - accuracy: 0.8304 - val_loss: 0.5020 - val_accuracy: 0.8442\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5436 - accuracy: 0.8265 - val_loss: 0.5107 - val_accuracy: 0.8396\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5253 - accuracy: 0.8326 - val_loss: 0.4612 - val_accuracy: 0.8556\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.5265 - accuracy: 0.8307 - val_loss: 0.4603 - val_accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.5013 - accuracy: 0.8401 - val_loss: 0.4621 - val_accuracy: 0.8560\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5096 - accuracy: 0.8363 - val_loss: 0.4727 - val_accuracy: 0.8548\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.4884 - accuracy: 0.8436 - val_loss: 0.4671 - val_accuracy: 0.8579\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4823 - accuracy: 0.8453 - val_loss: 0.4496 - val_accuracy: 0.8588\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4704 - accuracy: 0.8493 - val_loss: 0.4305 - val_accuracy: 0.8658\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.4586 - accuracy: 0.8520 - val_loss: 0.4289 - val_accuracy: 0.8655\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.4612 - accuracy: 0.8504 - val_loss: 0.4221 - val_accuracy: 0.8684\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4630 - accuracy: 0.8515 - val_loss: 0.3931 - val_accuracy: 0.8788\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5090 - accuracy: 0.8336 - val_loss: 0.4088 - val_accuracy: 0.8731\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4248 - accuracy: 0.8642 - val_loss: 0.4251 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4395 - accuracy: 0.8588 - val_loss: 0.4037 - val_accuracy: 0.8770\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.4238 - accuracy: 0.8632 - val_loss: 0.4065 - val_accuracy: 0.8732\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4271 - accuracy: 0.8626 - val_loss: 0.3945 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4905 - accuracy: 0.8418 - val_loss: 0.4021 - val_accuracy: 0.8759\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.4247 - accuracy: 0.8647 - val_loss: 0.3897 - val_accuracy: 0.8796\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.4044 - accuracy: 0.8693 - val_loss: 0.3823 - val_accuracy: 0.8813\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.4047 - accuracy: 0.8687 - val_loss: 0.3838 - val_accuracy: 0.8819\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4208 - accuracy: 0.8646 - val_loss: 0.3760 - val_accuracy: 0.8828\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3760 - accuracy: 0.8828\n",
      "Accuracy on the Validation Data is 0.8827916383743286 and the loss is 0.3759689927101135\n",
      "For Hidden Layer 1 neurons =  510 ,Hidden Layer 2 neurons =  283 & Hidden Layer 3 neurons =  164 ; also Droput of 0.2845867367924245\n",
      "\n",
      "\n",
      "--------------------------- Loop 15 ---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.3909 - accuracy: 0.1081 - val_loss: 2.7318 - val_accuracy: 0.1109\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 2.0926 - accuracy: 0.2142 - val_loss: 1.7763 - val_accuracy: 0.3815\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.4937 - accuracy: 0.4810 - val_loss: 1.3714 - val_accuracy: 0.6087\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.1648 - accuracy: 0.6161 - val_loss: 1.1976 - val_accuracy: 0.6611\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.0901 - accuracy: 0.6453 - val_loss: 1.0432 - val_accuracy: 0.6952\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 1.0252 - accuracy: 0.6691 - val_loss: 0.9300 - val_accuracy: 0.7170\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.9315 - accuracy: 0.7005 - val_loss: 0.9377 - val_accuracy: 0.7088\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.9117 - accuracy: 0.7093 - val_loss: 0.8067 - val_accuracy: 0.7471\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.8458 - accuracy: 0.7295 - val_loss: 0.6983 - val_accuracy: 0.7821\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7928 - accuracy: 0.7484 - val_loss: 0.6795 - val_accuracy: 0.7879\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.8047 - accuracy: 0.7430 - val_loss: 0.6423 - val_accuracy: 0.7975\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7493 - accuracy: 0.7631 - val_loss: 0.6636 - val_accuracy: 0.7881\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7289 - accuracy: 0.7680 - val_loss: 0.6099 - val_accuracy: 0.8072\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.7539 - accuracy: 0.7587 - val_loss: 0.6099 - val_accuracy: 0.8055\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.7101 - accuracy: 0.7740 - val_loss: 0.5961 - val_accuracy: 0.8121\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.6950 - accuracy: 0.7807 - val_loss: 0.5597 - val_accuracy: 0.8263\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6499 - accuracy: 0.7949 - val_loss: 0.5407 - val_accuracy: 0.8301\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.6519 - accuracy: 0.7924 - val_loss: 0.5541 - val_accuracy: 0.8246\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.6669 - accuracy: 0.7872 - val_loss: 0.5208 - val_accuracy: 0.8385\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.6416 - accuracy: 0.7978 - val_loss: 0.5404 - val_accuracy: 0.8304\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.6398 - accuracy: 0.7966 - val_loss: 0.5028 - val_accuracy: 0.8403\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.5956 - accuracy: 0.8113 - val_loss: 0.5030 - val_accuracy: 0.8431\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.6261 - accuracy: 0.8020 - val_loss: 0.5076 - val_accuracy: 0.8416\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.5799 - accuracy: 0.8164 - val_loss: 0.5025 - val_accuracy: 0.8405\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5873 - accuracy: 0.8127 - val_loss: 0.4939 - val_accuracy: 0.8460\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5524 - accuracy: 0.8251 - val_loss: 0.5261 - val_accuracy: 0.8332\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5720 - accuracy: 0.8171 - val_loss: 0.4638 - val_accuracy: 0.8530\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5751 - accuracy: 0.8169 - val_loss: 0.4849 - val_accuracy: 0.8463\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5836 - accuracy: 0.8132 - val_loss: 0.4608 - val_accuracy: 0.8560\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5478 - accuracy: 0.8278 - val_loss: 0.4651 - val_accuracy: 0.8531\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5599 - accuracy: 0.8220 - val_loss: 0.4436 - val_accuracy: 0.8613\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5456 - accuracy: 0.8272 - val_loss: 0.4422 - val_accuracy: 0.8639\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5438 - accuracy: 0.8268 - val_loss: 0.4501 - val_accuracy: 0.8608\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.5341 - accuracy: 0.8297 - val_loss: 0.4354 - val_accuracy: 0.8624\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5162 - accuracy: 0.8354 - val_loss: 0.4335 - val_accuracy: 0.8618\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5218 - accuracy: 0.8330 - val_loss: 0.4252 - val_accuracy: 0.8673\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4890 - accuracy: 0.8447 - val_loss: 0.4235 - val_accuracy: 0.8685\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4915 - accuracy: 0.8430 - val_loss: 0.4207 - val_accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4975 - accuracy: 0.8413 - val_loss: 0.4074 - val_accuracy: 0.8725\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4995 - accuracy: 0.8408 - val_loss: 0.4153 - val_accuracy: 0.8699\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4910 - accuracy: 0.8422 - val_loss: 0.4112 - val_accuracy: 0.8737\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4914 - accuracy: 0.8425 - val_loss: 0.4288 - val_accuracy: 0.8652\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4288 - accuracy: 0.8652\n",
      "Accuracy on the Validation Data is 0.8652499914169312 and the loss is 0.4287968873977661\n",
      "For Hidden Layer 1 neurons =  639 ,Hidden Layer 2 neurons =  255 & Hidden Layer 3 neurons =  119 ; also Droput of 0.3778386480847995\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intializing empty lists\n",
    "Layer_1_neurons=[]\n",
    "Layer_2_neurons = []\n",
    "Layer_3_neurons = []\n",
    "Dropout = []\n",
    "Loss = []\n",
    "Accuracy = []\n",
    "\n",
    "# Tuning\n",
    "for i in range(15):\n",
    "    print('--------------------------- Loop {0} ---------------------------'.format(i+1))\n",
    "    layer_1 = np.random.randint(500,1000)\n",
    "    layer_2 = np.random.randint(200,500)\n",
    "    layer_3 = np.random.randint(75,200)\n",
    "    drop = np.random.uniform(0.2,0.5)\n",
    "    mod = model_arch(X_train,y_train,loops = 100,hidden_layer_1_neurons= layer_1,hidden_layer_2_neurons= layer_2,hidden_layer_3_neurons= layer_3,\n",
    "                     dropout=drop,learningrate = 0.01, regularization = 0,val=True,x_val=X_val,y_val=y_val)\n",
    "    # Performance of model\n",
    "    loss,accuracy = mod.evaluate(X_val,y_val)\n",
    "    print('Accuracy on the Validation Data is {0} and the loss is {1}'.format(accuracy,loss))\n",
    "    print('For Hidden Layer 1 neurons =  {0} ,Hidden Layer 2 neurons =  {1} & Hidden Layer 3 neurons =  {2} ; also Droput of {3}'.format(layer_1,layer_2,layer_3,drop))\n",
    "    print('\\n')\n",
    "    Layer_1_neurons.append(layer_1)\n",
    "    Layer_2_neurons.append(layer_2)\n",
    "    Layer_3_neurons.append(layer_3)\n",
    "    Dropout.append(drop)\n",
    "    Loss.append(loss)\n",
    "    Accuracy.append(accuracy)\n",
    "    \n",
    "# Visualizng the Results\n",
    "data = pd.DataFrame(Layer_1_neurons,columns=['Layer 1 neurons'])\n",
    "data['Layer 2 neurons'] = Layer_2_neurons\n",
    "data['Layer 3 neurons'] = Layer_3_neurons\n",
    "data['Dropout'] = Dropout\n",
    "data['Loss'] = Loss\n",
    "data['Accuracy'] = Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 neurons</th>\n",
       "      <th>Layer 2 neurons</th>\n",
       "      <th>Layer 3 neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>265</td>\n",
       "      <td>166</td>\n",
       "      <td>0.336442</td>\n",
       "      <td>0.375097</td>\n",
       "      <td>0.883375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>933</td>\n",
       "      <td>331</td>\n",
       "      <td>82</td>\n",
       "      <td>0.449194</td>\n",
       "      <td>0.387654</td>\n",
       "      <td>0.879958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>938</td>\n",
       "      <td>239</td>\n",
       "      <td>156</td>\n",
       "      <td>0.494664</td>\n",
       "      <td>0.432882</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>869</td>\n",
       "      <td>295</td>\n",
       "      <td>189</td>\n",
       "      <td>0.224616</td>\n",
       "      <td>0.345747</td>\n",
       "      <td>0.898917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>346</td>\n",
       "      <td>80</td>\n",
       "      <td>0.429407</td>\n",
       "      <td>0.405519</td>\n",
       "      <td>0.873042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>539</td>\n",
       "      <td>297</td>\n",
       "      <td>154</td>\n",
       "      <td>0.481109</td>\n",
       "      <td>0.442877</td>\n",
       "      <td>0.861750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>968</td>\n",
       "      <td>431</td>\n",
       "      <td>121</td>\n",
       "      <td>0.336451</td>\n",
       "      <td>0.364230</td>\n",
       "      <td>0.889042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>434</td>\n",
       "      <td>93</td>\n",
       "      <td>0.365021</td>\n",
       "      <td>0.398763</td>\n",
       "      <td>0.875792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>796</td>\n",
       "      <td>305</td>\n",
       "      <td>153</td>\n",
       "      <td>0.471532</td>\n",
       "      <td>0.407738</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>894</td>\n",
       "      <td>471</td>\n",
       "      <td>150</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.372287</td>\n",
       "      <td>0.891125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>855</td>\n",
       "      <td>218</td>\n",
       "      <td>88</td>\n",
       "      <td>0.258312</td>\n",
       "      <td>0.379577</td>\n",
       "      <td>0.882208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>906</td>\n",
       "      <td>319</td>\n",
       "      <td>82</td>\n",
       "      <td>0.240114</td>\n",
       "      <td>0.410762</td>\n",
       "      <td>0.876958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>813</td>\n",
       "      <td>386</td>\n",
       "      <td>129</td>\n",
       "      <td>0.470915</td>\n",
       "      <td>0.434254</td>\n",
       "      <td>0.865292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>510</td>\n",
       "      <td>283</td>\n",
       "      <td>164</td>\n",
       "      <td>0.284587</td>\n",
       "      <td>0.375969</td>\n",
       "      <td>0.882792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>639</td>\n",
       "      <td>255</td>\n",
       "      <td>119</td>\n",
       "      <td>0.377839</td>\n",
       "      <td>0.428797</td>\n",
       "      <td>0.865250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 neurons  Layer 2 neurons  Layer 3 neurons   Dropout      Loss  \\\n",
       "0               619              265              166  0.336442  0.375097   \n",
       "1               933              331               82  0.449194  0.387654   \n",
       "2               938              239              156  0.494664  0.432882   \n",
       "3               869              295              189  0.224616  0.345747   \n",
       "4               516              346               80  0.429407  0.405519   \n",
       "5               539              297              154  0.481109  0.442877   \n",
       "6               968              431              121  0.336451  0.364230   \n",
       "7               500              434               93  0.365021  0.398763   \n",
       "8               796              305              153  0.471532  0.407738   \n",
       "9               894              471              150  0.211180  0.372287   \n",
       "10              855              218               88  0.258312  0.379577   \n",
       "11              906              319               82  0.240114  0.410762   \n",
       "12              813              386              129  0.470915  0.434254   \n",
       "13              510              283              164  0.284587  0.375969   \n",
       "14              639              255              119  0.377839  0.428797   \n",
       "\n",
       "    Accuracy  \n",
       "0   0.883375  \n",
       "1   0.879958  \n",
       "2   0.866000  \n",
       "3   0.898917  \n",
       "4   0.873042  \n",
       "5   0.861750  \n",
       "6   0.889042  \n",
       "7   0.875792  \n",
       "8   0.873333  \n",
       "9   0.891125  \n",
       "10  0.882208  \n",
       "11  0.876958  \n",
       "12  0.865292  \n",
       "13  0.882792  \n",
       "14  0.865250  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will narrow our input parameters as\n",
    "\n",
    "Layer_1_neurons : 500 - 700\n",
    "\n",
    "Layer_2_neurons : 350 - 500\n",
    "\n",
    "Layer_3_neurons : 75 - 150 \n",
    "\n",
    "Dropout : 0.2 - 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Loop 1 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 2.3984 - accuracy: 0.1097 - val_loss: 3.0607 - val_accuracy: 0.1085\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 2.0806 - accuracy: 0.2309 - val_loss: 1.8125 - val_accuracy: 0.3283\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.4574 - accuracy: 0.4907 - val_loss: 1.5566 - val_accuracy: 0.5281\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.1487 - accuracy: 0.6233 - val_loss: 1.3795 - val_accuracy: 0.6365\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9595 - accuracy: 0.69 - 2s 92ms/step - loss: 0.9595 - accuracy: 0.6910 - val_loss: 1.2362 - val_accuracy: 0.6850\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.9155 - accuracy: 0.7058 - val_loss: 1.0523 - val_accuracy: 0.7312\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.8025 - accuracy: 0.7434 - val_loss: 0.9401 - val_accuracy: 0.7433\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.7482 - accuracy: 0.7595 - val_loss: 0.8866 - val_accuracy: 0.7397\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.7202 - accuracy: 0.7713 - val_loss: 0.7610 - val_accuracy: 0.7803\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6688 - accuracy: 0.7869 - val_loss: 0.6903 - val_accuracy: 0.7943\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6717 - accuracy: 0.7861 - val_loss: 0.6405 - val_accuracy: 0.8027\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6894 - accuracy: 0.7787 - val_loss: 0.6345 - val_accuracy: 0.8007\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6323 - accuracy: 0.7974 - val_loss: 0.6139 - val_accuracy: 0.8076\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6253 - accuracy: 0.7999 - val_loss: 0.5778 - val_accuracy: 0.8194\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5922 - accuracy: 0.8107 - val_loss: 0.5810 - val_accuracy: 0.8160\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5710 - accuracy: 0.8186 - val_loss: 0.5262 - val_accuracy: 0.8356\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4983 - accuracy: 0.8423 - val_loss: 0.4914 - val_accuracy: 0.8448\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4942 - accuracy: 0.8431 - val_loss: 0.4700 - val_accuracy: 0.8525\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4944 - accuracy: 0.8428 - val_loss: 0.4822 - val_accuracy: 0.8501\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4527 - accuracy: 0.8553 - val_loss: 0.4605 - val_accuracy: 0.8555\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5152 - accuracy: 0.8338 - val_loss: 0.4570 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4401 - accuracy: 0.8589 - val_loss: 0.4837 - val_accuracy: 0.8475\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4872 - accuracy: 0.8446 - val_loss: 0.4586 - val_accuracy: 0.8578\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4074 - accuracy: 0.8699 - val_loss: 0.4267 - val_accuracy: 0.8696\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4264 - accuracy: 0.8633 - val_loss: 0.4401 - val_accuracy: 0.8663\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4244 - accuracy: 0.8639 - val_loss: 0.4600 - val_accuracy: 0.8563\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4155 - accuracy: 0.8658 - val_loss: 0.4440 - val_accuracy: 0.8607\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4152 - accuracy: 0.8656 - val_loss: 0.4093 - val_accuracy: 0.8738\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.3707 - accuracy: 0.8808 - val_loss: 0.4232 - val_accuracy: 0.8674\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4705 - accuracy: 0.8472 - val_loss: 0.3987 - val_accuracy: 0.8758\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.3769 - accuracy: 0.8772 - val_loss: 0.4048 - val_accuracy: 0.8763\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4178 - accuracy: 0.8642 - val_loss: 0.3999 - val_accuracy: 0.8790\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.3785 - accuracy: 0.8779 - val_loss: 0.4036 - val_accuracy: 0.8790\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.3945 - accuracy: 0.8718 - val_loss: 0.3924 - val_accuracy: 0.8812\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3599 - accuracy: 0.8841 - val_loss: 0.3936 - val_accuracy: 0.8814\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.3295 - accuracy: 0.8926 - val_loss: 0.3718 - val_accuracy: 0.8880\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3345 - accuracy: 0.8910 - val_loss: 0.3895 - val_accuracy: 0.8821\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.3802 - accuracy: 0.8763 - val_loss: 0.3618 - val_accuracy: 0.8911\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3310 - accuracy: 0.8920 - val_loss: 0.3665 - val_accuracy: 0.8907\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3856 - accuracy: 0.8741 - val_loss: 0.3695 - val_accuracy: 0.8871\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3294 - accuracy: 0.8933 - val_loss: 0.3836 - val_accuracy: 0.8860\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3415 - accuracy: 0.8893 - val_loss: 0.3584 - val_accuracy: 0.8926\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3388 - accuracy: 0.8887 - val_loss: 0.3503 - val_accuracy: 0.8965\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3068 - accuracy: 0.8995 - val_loss: 0.3375 - val_accuracy: 0.8997\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.2953 - accuracy: 0.9037 - val_loss: 0.3470 - val_accuracy: 0.8970\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3154 - accuracy: 0.8968 - val_loss: 0.3402 - val_accuracy: 0.8984\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3126 - accuracy: 0.8976 - val_loss: 0.3348 - val_accuracy: 0.8993\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3019 - accuracy: 0.9005 - val_loss: 0.3614 - val_accuracy: 0.8938\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3176 - accuracy: 0.8963 - val_loss: 0.3527 - val_accuracy: 0.8960\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3069 - accuracy: 0.8990 - val_loss: 0.3214 - val_accuracy: 0.9053\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3155 - accuracy: 0.8957 - val_loss: 0.3306 - val_accuracy: 0.9036\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3106 - accuracy: 0.8989 - val_loss: 0.3227 - val_accuracy: 0.9068\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.2827 - accuracy: 0.9066 - val_loss: 0.3190 - val_accuracy: 0.9078\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.2792 - accuracy: 0.9088 - val_loss: 0.3278 - val_accuracy: 0.9053\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.2832 - accuracy: 0.9069 - val_loss: 0.3309 - val_accuracy: 0.9057\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.2994 - accuracy: 0.9015 - val_loss: 0.3242 - val_accuracy: 0.9067\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2769 - accuracy: 0.9091 - val_loss: 0.3432 - val_accuracy: 0.9018\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.2890 - accuracy: 0.9053 - val_loss: 0.3271 - val_accuracy: 0.9072\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3061 - accuracy: 0.9000 - val_loss: 0.3276 - val_accuracy: 0.9055\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2752 - accuracy: 0.9094 - val_loss: 0.3238 - val_accuracy: 0.9059\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3238 - accuracy: 0.9059\n",
      "Accuracy on the Validation Data is 0.905875027179718 and the loss is 0.32380411028862\n",
      "For Hidden Layer 1 neurons =  519 ,Hidden Layer 2 neurons =  424 & Hidden Layer 3 neurons =  142 ; also Droput of 0.22220258720476307\n",
      "\n",
      "\n",
      "--------------------------- Loop 2 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 2.3677 - accuracy: 0.1202 - val_loss: 2.5003 - val_accuracy: 0.1272\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 1.9984 - accuracy: 0.2501 - val_loss: 1.8114 - val_accuracy: 0.3578\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 1.4265 - accuracy: 0.5102 - val_loss: 1.5840 - val_accuracy: 0.5156\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 1.1077 - accuracy: 0.6385 - val_loss: 1.3993 - val_accuracy: 0.6075\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.9694 - accuracy: 0.6894 - val_loss: 1.2436 - val_accuracy: 0.6537\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.8337 - accuracy: 0.7331 - val_loss: 1.1676 - val_accuracy: 0.6660\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.8009 - accuracy: 0.7442 - val_loss: 0.9710 - val_accuracy: 0.7244\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.7744 - accuracy: 0.7525 - val_loss: 0.8565 - val_accuracy: 0.7653\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.7304 - accuracy: 0.7666 - val_loss: 0.7909 - val_accuracy: 0.7669\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6618 - accuracy: 0.7883 - val_loss: 0.7225 - val_accuracy: 0.7829\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.6061 - accuracy: 0.8071 - val_loss: 0.6114 - val_accuracy: 0.8160\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5897 - accuracy: 0.8119 - val_loss: 0.5961 - val_accuracy: 0.8166\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.6212 - accuracy: 0.8019 - val_loss: 0.6365 - val_accuracy: 0.7976\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5534 - accuracy: 0.8240 - val_loss: 0.6084 - val_accuracy: 0.8068\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.5368 - accuracy: 0.8296 - val_loss: 0.5352 - val_accuracy: 0.8339\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5156 - accuracy: 0.8354 - val_loss: 0.5371 - val_accuracy: 0.8283\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.5353 - accuracy: 0.8272 - val_loss: 0.5226 - val_accuracy: 0.8325\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.5071 - accuracy: 0.8365 - val_loss: 0.5191 - val_accuracy: 0.8376\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5020 - accuracy: 0.8389 - val_loss: 0.4755 - val_accuracy: 0.8553\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4680 - accuracy: 0.8493 - val_loss: 0.5079 - val_accuracy: 0.8458\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.4752 - accuracy: 0.8464 - val_loss: 0.4766 - val_accuracy: 0.8503\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.4535 - accuracy: 0.8537 - val_loss: 0.4398 - val_accuracy: 0.8624\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4620 - accuracy: 0.8501 - val_loss: 0.4260 - val_accuracy: 0.8678\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.4436 - accuracy: 0.8560 - val_loss: 0.4602 - val_accuracy: 0.8590\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4502 - accuracy: 0.8547 - val_loss: 0.4399 - val_accuracy: 0.8638\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4435 - accuracy: 0.8564 - val_loss: 0.4252 - val_accuracy: 0.8695\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4337 - accuracy: 0.8593 - val_loss: 0.4303 - val_accuracy: 0.8652\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4164 - accuracy: 0.8658 - val_loss: 0.4284 - val_accuracy: 0.8692\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3957 - accuracy: 0.8712 - val_loss: 0.3877 - val_accuracy: 0.8823\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3699 - accuracy: 0.8794 - val_loss: 0.4011 - val_accuracy: 0.8781\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3672 - accuracy: 0.8810 - val_loss: 0.4064 - val_accuracy: 0.8776\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3675 - accuracy: 0.8808 - val_loss: 0.3845 - val_accuracy: 0.8813\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3435 - accuracy: 0.8887 - val_loss: 0.4289 - val_accuracy: 0.8697\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3494 - accuracy: 0.8869 - val_loss: 0.4115 - val_accuracy: 0.8742\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3808 - accuracy: 0.8759 - val_loss: 0.3779 - val_accuracy: 0.8857\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3585 - accuracy: 0.8836 - val_loss: 0.4216 - val_accuracy: 0.8746\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3960 - accuracy: 0.8710 - val_loss: 0.3752 - val_accuracy: 0.8862\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3341 - accuracy: 0.8923 - val_loss: 0.3876 - val_accuracy: 0.8863\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3709 - accuracy: 0.8792 - val_loss: 0.3806 - val_accuracy: 0.8842\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8842\n",
      "Accuracy on the Validation Data is 0.8842499852180481 and the loss is 0.3805549740791321\n",
      "For Hidden Layer 1 neurons =  573 ,Hidden Layer 2 neurons =  483 & Hidden Layer 3 neurons =  102 ; also Droput of 0.2087207076007534\n",
      "\n",
      "\n",
      "--------------------------- Loop 3 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.4155 - accuracy: 0.1026 - val_loss: 2.5051 - val_accuracy: 0.1035\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 2.2555 - accuracy: 0.1454 - val_loss: 2.0803 - val_accuracy: 0.2432\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.6801 - accuracy: 0.4004 - val_loss: 1.7683 - val_accuracy: 0.4526\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1963 - accuracy: 0.6040 - val_loss: 1.6570 - val_accuracy: 0.5430\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.9953 - accuracy: 0.6780 - val_loss: 1.5678 - val_accuracy: 0.5499\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.9152 - accuracy: 0.7041 - val_loss: 1.3452 - val_accuracy: 0.6761\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.8368 - accuracy: 0.7329 - val_loss: 1.2620 - val_accuracy: 0.6893\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.8635 - accuracy: 0.7223 - val_loss: 1.0826 - val_accuracy: 0.7275\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.7804 - accuracy: 0.7522 - val_loss: 0.9826 - val_accuracy: 0.7420\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6826 - accuracy: 0.7837 - val_loss: 0.8762 - val_accuracy: 0.7653\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6887 - accuracy: 0.7807 - val_loss: 0.8094 - val_accuracy: 0.7757\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6542 - accuracy: 0.7931 - val_loss: 0.7128 - val_accuracy: 0.7917\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6398 - accuracy: 0.7966 - val_loss: 0.6509 - val_accuracy: 0.8117\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6182 - accuracy: 0.8029 - val_loss: 0.6624 - val_accuracy: 0.7953\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5658 - accuracy: 0.8199 - val_loss: 0.6102 - val_accuracy: 0.8053\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6155 - accuracy: 0.8016 - val_loss: 0.5872 - val_accuracy: 0.8169\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5408 - accuracy: 0.8277 - val_loss: 0.5699 - val_accuracy: 0.8238\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5187 - accuracy: 0.8350 - val_loss: 0.5200 - val_accuracy: 0.8372\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5428 - accuracy: 0.8267 - val_loss: 0.4922 - val_accuracy: 0.8457\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4864 - accuracy: 0.8438 - val_loss: 0.5267 - val_accuracy: 0.8335\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4892 - accuracy: 0.8449 - val_loss: 0.4689 - val_accuracy: 0.8520\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4768 - accuracy: 0.8460 - val_loss: 0.5383 - val_accuracy: 0.8323\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5146 - accuracy: 0.8366 - val_loss: 0.5032 - val_accuracy: 0.8434\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4471 - accuracy: 0.8566 - val_loss: 0.4950 - val_accuracy: 0.8489\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4407 - accuracy: 0.8586 - val_loss: 0.4492 - val_accuracy: 0.8629\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4377 - accuracy: 0.8603 - val_loss: 0.4322 - val_accuracy: 0.8675\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4358 - accuracy: 0.8606 - val_loss: 0.4436 - val_accuracy: 0.8626\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4075 - accuracy: 0.8700 - val_loss: 0.4631 - val_accuracy: 0.8578\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4605 - accuracy: 0.8517 - val_loss: 0.4251 - val_accuracy: 0.8687\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4456 - accuracy: 0.8556 - val_loss: 0.4411 - val_accuracy: 0.8637\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4688 - accuracy: 0.8503 - val_loss: 0.4327 - val_accuracy: 0.8670\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4092 - accuracy: 0.8678 - val_loss: 0.4176 - val_accuracy: 0.8740\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4102 - accuracy: 0.8682 - val_loss: 0.4135 - val_accuracy: 0.8729\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3828 - accuracy: 0.8768 - val_loss: 0.4155 - val_accuracy: 0.8720\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3746 - accuracy: 0.8792 - val_loss: 0.4132 - val_accuracy: 0.8722\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3545 - accuracy: 0.8862 - val_loss: 0.3782 - val_accuracy: 0.8841\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3789 - accuracy: 0.8777 - val_loss: 0.3929 - val_accuracy: 0.8823\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3670 - accuracy: 0.8808 - val_loss: 0.4139 - val_accuracy: 0.8740\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4449 - accuracy: 0.8563 - val_loss: 0.3986 - val_accuracy: 0.8795\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4042 - accuracy: 0.8688 - val_loss: 0.3920 - val_accuracy: 0.8819\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3586 - accuracy: 0.8832 - val_loss: 0.3989 - val_accuracy: 0.8792\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3358 - accuracy: 0.8907 - val_loss: 0.3602 - val_accuracy: 0.8920\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3339 - accuracy: 0.8926 - val_loss: 0.3851 - val_accuracy: 0.8849\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3273 - accuracy: 0.8951 - val_loss: 0.3509 - val_accuracy: 0.8963\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3016 - accuracy: 0.9017 - val_loss: 0.3628 - val_accuracy: 0.8915\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3295 - accuracy: 0.8930 - val_loss: 0.3569 - val_accuracy: 0.8924\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2926 - accuracy: 0.9051 - val_loss: 0.3535 - val_accuracy: 0.8959\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3095 - accuracy: 0.8998 - val_loss: 0.3407 - val_accuracy: 0.8993\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2944 - accuracy: 0.9040 - val_loss: 0.3576 - val_accuracy: 0.8943\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.2945 - accuracy: 0.9036 - val_loss: 0.3287 - val_accuracy: 0.9039\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3032 - accuracy: 0.9004 - val_loss: 0.3480 - val_accuracy: 0.8989\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3472 - accuracy: 0.8865 - val_loss: 0.3517 - val_accuracy: 0.8969\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3329 - accuracy: 0.8912 - val_loss: 0.3440 - val_accuracy: 0.9017\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2747 - accuracy: 0.9110 - val_loss: 0.3340 - val_accuracy: 0.9023\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.9023\n",
      "Accuracy on the Validation Data is 0.9022916555404663 and the loss is 0.33398154377937317\n",
      "For Hidden Layer 1 neurons =  581 ,Hidden Layer 2 neurons =  391 & Hidden Layer 3 neurons =  106 ; also Droput of 0.21364952329756765\n",
      "\n",
      "\n",
      "--------------------------- Loop 4 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 2.4525 - accuracy: 0.1018 - val_loss: 2.6215 - val_accuracy: 0.1010\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 2.3096 - accuracy: 0.1123 - val_loss: 2.3893 - val_accuracy: 0.1153\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 1.9096 - accuracy: 0.2952 - val_loss: 1.8811 - val_accuracy: 0.3530\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.3449 - accuracy: 0.5423 - val_loss: 1.7695 - val_accuracy: 0.4707\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 1.0784 - accuracy: 0.6464 - val_loss: 1.6962 - val_accuracy: 0.4728\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.9569 - accuracy: 0.6906 - val_loss: 1.5416 - val_accuracy: 0.6174\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8904 - accuracy: 0.7137 - val_loss: 1.3668 - val_accuracy: 0.6746\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.8220 - accuracy: 0.7376 - val_loss: 1.2437 - val_accuracy: 0.7169\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7855 - accuracy: 0.7484 - val_loss: 1.1793 - val_accuracy: 0.7078\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7252 - accuracy: 0.7683 - val_loss: 1.0478 - val_accuracy: 0.7353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.7043 - accuracy: 0.7753 - val_loss: 0.9305 - val_accuracy: 0.7605\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6547 - accuracy: 0.7892 - val_loss: 0.8045 - val_accuracy: 0.7853\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.6027 - accuracy: 0.8083 - val_loss: 0.7196 - val_accuracy: 0.8111\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5790 - accuracy: 0.8143 - val_loss: 0.7018 - val_accuracy: 0.8031\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5657 - accuracy: 0.8203 - val_loss: 0.6260 - val_accuracy: 0.8091\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5422 - accuracy: 0.8279 - val_loss: 0.6276 - val_accuracy: 0.8046\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5937 - accuracy: 0.8089 - val_loss: 0.5511 - val_accuracy: 0.8313\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5356 - accuracy: 0.8289 - val_loss: 0.5182 - val_accuracy: 0.8408\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5126 - accuracy: 0.8359 - val_loss: 0.5143 - val_accuracy: 0.8407\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4989 - accuracy: 0.8398 - val_loss: 0.4718 - val_accuracy: 0.8527\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4728 - accuracy: 0.8469 - val_loss: 0.4641 - val_accuracy: 0.8533\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4538 - accuracy: 0.8541 - val_loss: 0.4732 - val_accuracy: 0.8536\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4660 - accuracy: 0.8494 - val_loss: 0.4800 - val_accuracy: 0.8503\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4433 - accuracy: 0.8581 - val_loss: 0.4491 - val_accuracy: 0.8591\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4617 - accuracy: 0.8507 - val_loss: 0.4368 - val_accuracy: 0.8642\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4479 - accuracy: 0.8567 - val_loss: 0.4214 - val_accuracy: 0.8703\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4250 - accuracy: 0.8624 - val_loss: 0.4277 - val_accuracy: 0.8679\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4368 - accuracy: 0.8575 - val_loss: 0.4421 - val_accuracy: 0.8649\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3853 - accuracy: 0.8749 - val_loss: 0.4502 - val_accuracy: 0.8606\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4071 - accuracy: 0.8675 - val_loss: 0.4111 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3681 - accuracy: 0.8801 - val_loss: 0.4172 - val_accuracy: 0.8725\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.4101 - accuracy: 0.8677 - val_loss: 0.3962 - val_accuracy: 0.8790\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3965 - accuracy: 0.8714 - val_loss: 0.4037 - val_accuracy: 0.8777\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3791 - accuracy: 0.8770 - val_loss: 0.3911 - val_accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3540 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.8830\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3860 - accuracy: 0.8756 - val_loss: 0.3952 - val_accuracy: 0.8810\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3814 - accuracy: 0.8763 - val_loss: 0.3762 - val_accuracy: 0.8841\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3424 - accuracy: 0.8882 - val_loss: 0.3953 - val_accuracy: 0.8818\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3987 - accuracy: 0.8707 - val_loss: 0.3965 - val_accuracy: 0.8815\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3760 - accuracy: 0.8781 - val_loss: 0.3805 - val_accuracy: 0.8856\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3517 - accuracy: 0.8859 - val_loss: 0.3745 - val_accuracy: 0.8877\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3097 - accuracy: 0.8991 - val_loss: 0.3651 - val_accuracy: 0.8904\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3078 - accuracy: 0.8992 - val_loss: 0.3933 - val_accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3358 - accuracy: 0.8913 - val_loss: 0.3498 - val_accuracy: 0.8948\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2993 - accuracy: 0.9016 - val_loss: 0.3528 - val_accuracy: 0.8953\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.3374 - accuracy: 0.8902 - val_loss: 0.3400 - val_accuracy: 0.8999\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2786 - accuracy: 0.9091 - val_loss: 0.3534 - val_accuracy: 0.8965\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.2964 - accuracy: 0.9033 - val_loss: 0.3497 - val_accuracy: 0.8968\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2787 - accuracy: 0.9083 - val_loss: 0.3484 - val_accuracy: 0.8982\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.3322 - accuracy: 0.8914 - val_loss: 0.3381 - val_accuracy: 0.9018\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.2973 - accuracy: 0.9018 - val_loss: 0.3368 - val_accuracy: 0.9031\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2964 - accuracy: 0.9025 - val_loss: 0.3478 - val_accuracy: 0.8990\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2817 - accuracy: 0.9093 - val_loss: 0.3254 - val_accuracy: 0.9070\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2645 - accuracy: 0.9135 - val_loss: 0.3288 - val_accuracy: 0.9045ss: 0.2644 - accuracy: 0.91\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.2966 - accuracy: 0.9029 - val_loss: 0.3275 - val_accuracy: 0.9075\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.2632 - accuracy: 0.9136 - val_loss: 0.3424 - val_accuracy: 0.9023\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.3022 - accuracy: 0.8998 - val_loss: 0.3350 - val_accuracy: 0.9066\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.3102 - accuracy: 0.8980 - val_loss: 0.3297 - val_accuracy: 0.9035\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2423 - accuracy: 0.9213 - val_loss: 0.3142 - val_accuracy: 0.9106\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.2741 - accuracy: 0.9086 - val_loss: 0.3354 - val_accuracy: 0.9053\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3354 - accuracy: 0.9053\n",
      "Accuracy on the Validation Data is 0.9052500128746033 and the loss is 0.33539968729019165\n",
      "For Hidden Layer 1 neurons =  512 ,Hidden Layer 2 neurons =  405 & Hidden Layer 3 neurons =  145 ; also Droput of 0.20382194028671216\n",
      "\n",
      "\n",
      "--------------------------- Loop 5 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 2.3679 - accuracy: 0.1105 - val_loss: 2.4856 - val_accuracy: 0.1169\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 2.0354 - accuracy: 0.2496 - val_loss: 1.7326 - val_accuracy: 0.3788\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 1.4018 - accuracy: 0.5212 - val_loss: 1.5081 - val_accuracy: 0.5085\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 1.1615 - accuracy: 0.6143 - val_loss: 1.2911 - val_accuracy: 0.6189\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 1.0106 - accuracy: 0.6738 - val_loss: 1.0905 - val_accuracy: 0.6916\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.8641 - accuracy: 0.7225 - val_loss: 1.0436 - val_accuracy: 0.6824\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.8574 - accuracy: 0.7250 - val_loss: 0.9349 - val_accuracy: 0.7118\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.8275 - accuracy: 0.7345 - val_loss: 0.7851 - val_accuracy: 0.7592\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.7382 - accuracy: 0.7638 - val_loss: 0.7550 - val_accuracy: 0.7627\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.7403 - accuracy: 0.7626 - val_loss: 0.7562 - val_accuracy: 0.7662\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.6825 - accuracy: 0.7828 - val_loss: 0.6872 - val_accuracy: 0.7832\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.6432 - accuracy: 0.7946 - val_loss: 0.7010 - val_accuracy: 0.7819\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.6543 - accuracy: 0.7917 - val_loss: 0.6577 - val_accuracy: 0.7928\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.6283 - accuracy: 0.7993 - val_loss: 0.5943 - val_accuracy: 0.8153\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.6004 - accuracy: 0.8073 - val_loss: 0.5941 - val_accuracy: 0.8132\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.5454 - accuracy: 0.8268 - val_loss: 0.5548 - val_accuracy: 0.8252\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5331 - accuracy: 0.8289 - val_loss: 0.5291 - val_accuracy: 0.8312\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5020 - accuracy: 0.8395 - val_loss: 0.5184 - val_accuracy: 0.8364\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.5254 - accuracy: 0.8311 - val_loss: 0.5477 - val_accuracy: 0.8256\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.5476 - accuracy: 0.8252 - val_loss: 0.4892 - val_accuracy: 0.8464\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.5222 - accuracy: 0.8326 - val_loss: 0.4796 - val_accuracy: 0.8512\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4592 - accuracy: 0.8527 - val_loss: 0.4407 - val_accuracy: 0.8617\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.4594 - accuracy: 0.8532 - val_loss: 0.4746 - val_accuracy: 0.8541\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.4772 - accuracy: 0.8469 - val_loss: 0.4711 - val_accuracy: 0.8535\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4641 - accuracy: 0.8512 - val_loss: 0.4705 - val_accuracy: 0.8509\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.4666 - accuracy: 0.8498 - val_loss: 0.4357 - val_accuracy: 0.8637\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.4971 - accuracy: 0.8389 - val_loss: 0.4443 - val_accuracy: 0.8591\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.4493 - accuracy: 0.8556 - val_loss: 0.4106 - val_accuracy: 0.8732\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4417 - accuracy: 0.8574 - val_loss: 0.4638 - val_accuracy: 0.8568\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4131 - accuracy: 0.8667 - val_loss: 0.4082 - val_accuracy: 0.8755\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4174 - accuracy: 0.8643 - val_loss: 0.3899 - val_accuracy: 0.8786\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.3855 - accuracy: 0.8749 - val_loss: 0.3840 - val_accuracy: 0.8830\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.3932 - accuracy: 0.8724 - val_loss: 0.3968 - val_accuracy: 0.8776\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.4230 - accuracy: 0.8631 - val_loss: 0.3878 - val_accuracy: 0.8799\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3943 - accuracy: 0.8722 - val_loss: 0.3952 - val_accuracy: 0.8764\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 114ms/step - loss: 0.3697 - accuracy: 0.8805 - val_loss: 0.3723 - val_accuracy: 0.8880\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3864 - accuracy: 0.8751 - val_loss: 0.4095 - val_accuracy: 0.8761\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4321 - accuracy: 0.8584 - val_loss: 0.4186 - val_accuracy: 0.8727\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3796 - accuracy: 0.8763 - val_loss: 0.3608 - val_accuracy: 0.8903\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.3460 - accuracy: 0.8885 - val_loss: 0.3774 - val_accuracy: 0.8879\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.3884 - accuracy: 0.8736 - val_loss: 0.3667 - val_accuracy: 0.8877\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4342 - accuracy: 0.8585 - val_loss: 0.3992 - val_accuracy: 0.8788\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4049 - accuracy: 0.8689 - val_loss: 0.3723 - val_accuracy: 0.8892\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3777 - accuracy: 0.8770 - val_loss: 0.3800 - val_accuracy: 0.8852\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.3829 - accuracy: 0.8760 - val_loss: 0.3762 - val_accuracy: 0.8848\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.3628 - accuracy: 0.8822 - val_loss: 0.3504 - val_accuracy: 0.8942\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8942\n",
      "Accuracy on the Validation Data is 0.8942499756813049 and the loss is 0.35043999552726746\n",
      "For Hidden Layer 1 neurons =  657 ,Hidden Layer 2 neurons =  465 & Hidden Layer 3 neurons =  95 ; also Droput of 0.2738050202876039\n",
      "\n",
      "\n",
      "--------------------------- Loop 6 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 2.4128 - accuracy: 0.1040 - val_loss: 2.6989 - val_accuracy: 0.1061\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 2.1600 - accuracy: 0.1929 - val_loss: 1.8948 - val_accuracy: 0.3174\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.5836 - accuracy: 0.4415 - val_loss: 1.6563 - val_accuracy: 0.5035\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 1.1418 - accuracy: 0.6261 - val_loss: 1.5073 - val_accuracy: 0.6010\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.9912 - accuracy: 0.6806 - val_loss: 1.3327 - val_accuracy: 0.6706\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.8786 - accuracy: 0.7182 - val_loss: 1.2300 - val_accuracy: 0.6825\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.8899 - accuracy: 0.7156 - val_loss: 1.0606 - val_accuracy: 0.7237\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.7857 - accuracy: 0.7490 - val_loss: 1.0080 - val_accuracy: 0.7097\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.7213 - accuracy: 0.7712 - val_loss: 0.8014 - val_accuracy: 0.7929\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.6686 - accuracy: 0.7874 - val_loss: 0.7382 - val_accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.6613 - accuracy: 0.7874 - val_loss: 0.6944 - val_accuracy: 0.7913\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.6588 - accuracy: 0.7887 - val_loss: 0.6587 - val_accuracy: 0.8001\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5960 - accuracy: 0.8098 - val_loss: 0.5668 - val_accuracy: 0.8288\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.6108 - accuracy: 0.8039 - val_loss: 0.5925 - val_accuracy: 0.8162\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5832 - accuracy: 0.8140 - val_loss: 0.5681 - val_accuracy: 0.8210\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.5411 - accuracy: 0.8266 - val_loss: 0.5399 - val_accuracy: 0.8292\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.5843 - accuracy: 0.8123 - val_loss: 0.5146 - val_accuracy: 0.8378\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.5580 - accuracy: 0.8208 - val_loss: 0.5031 - val_accuracy: 0.8460\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.5130 - accuracy: 0.8368 - val_loss: 0.4823 - val_accuracy: 0.8505\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4890 - accuracy: 0.8437 - val_loss: 0.4808 - val_accuracy: 0.8484\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.4979 - accuracy: 0.8402 - val_loss: 0.4918 - val_accuracy: 0.8476\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.5217 - accuracy: 0.8320 - val_loss: 0.5355 - val_accuracy: 0.8376\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5232 - accuracy: 0.8317 - val_loss: 0.4432 - val_accuracy: 0.8616\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.5063 - accuracy: 0.8361 - val_loss: 0.4524 - val_accuracy: 0.8578\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4760 - accuracy: 0.8478 - val_loss: 0.4603 - val_accuracy: 0.8549\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4829 - accuracy: 0.8440 - val_loss: 0.4404 - val_accuracy: 0.8635\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.4523 - accuracy: 0.8545 - val_loss: 0.4482 - val_accuracy: 0.8624\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.4834 - accuracy: 0.8438 - val_loss: 0.4331 - val_accuracy: 0.8641\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4357 - accuracy: 0.8597 - val_loss: 0.4333 - val_accuracy: 0.8650\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.4016 - accuracy: 0.8716 - val_loss: 0.4344 - val_accuracy: 0.8648\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.4527 - accuracy: 0.8530 - val_loss: 0.4172 - val_accuracy: 0.8735\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.4165 - accuracy: 0.8655 - val_loss: 0.4025 - val_accuracy: 0.8749\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.4030 - accuracy: 0.8709 - val_loss: 0.3947 - val_accuracy: 0.8788\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.4186 - accuracy: 0.8644 - val_loss: 0.4070 - val_accuracy: 0.8737\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.4316 - accuracy: 0.8592 - val_loss: 0.3994 - val_accuracy: 0.8770\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.3931 - accuracy: 0.8730 - val_loss: 0.3924 - val_accuracy: 0.8808\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.3670 - accuracy: 0.8802 - val_loss: 0.4130 - val_accuracy: 0.8736\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3873 - accuracy: 0.8769 - val_loss: 0.3756 - val_accuracy: 0.8866\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.3625 - accuracy: 0.8827 - val_loss: 0.3976 - val_accuracy: 0.8789\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3540 - accuracy: 0.8852 - val_loss: 0.3752 - val_accuracy: 0.8876\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3617 - accuracy: 0.8823 - val_loss: 0.3735 - val_accuracy: 0.8846\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3913 - accuracy: 0.8723 - val_loss: 0.3604 - val_accuracy: 0.8905\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.3779 - accuracy: 0.8775 - val_loss: 0.3511 - val_accuracy: 0.8936\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.3823 - accuracy: 0.8749 - val_loss: 0.3639 - val_accuracy: 0.8895\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.3397 - accuracy: 0.8898 - val_loss: 0.3700 - val_accuracy: 0.8871\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.3254 - accuracy: 0.8948 - val_loss: 0.3430 - val_accuracy: 0.8964\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.3381 - accuracy: 0.8905 - val_loss: 0.3583 - val_accuracy: 0.8916\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.3414 - accuracy: 0.8883 - val_loss: 0.3398 - val_accuracy: 0.8972\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.3209 - accuracy: 0.8959 - val_loss: 0.3495 - val_accuracy: 0.8954\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.3407 - accuracy: 0.8882 - val_loss: 0.3417 - val_accuracy: 0.8963\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3808 - accuracy: 0.8761 - val_loss: 0.3512 - val_accuracy: 0.8965\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.3699 - accuracy: 0.8791 - val_loss: 0.3418 - val_accuracy: 0.8980\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.3243 - accuracy: 0.8943 - val_loss: 0.3317 - val_accuracy: 0.9012\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3012 - accuracy: 0.9030 - val_loss: 0.3382 - val_accuracy: 0.8991\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3144 - accuracy: 0.8976 - val_loss: 0.3319 - val_accuracy: 0.9035\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.3481 - accuracy: 0.8867 - val_loss: 0.3263 - val_accuracy: 0.9033\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.3334 - accuracy: 0.8909 - val_loss: 0.3303 - val_accuracy: 0.9002\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.2997 - accuracy: 0.9014 - val_loss: 0.3241 - val_accuracy: 0.9015\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.9015\n",
      "Accuracy on the Validation Data is 0.9014583230018616 and the loss is 0.32406020164489746\n",
      "For Hidden Layer 1 neurons =  659 ,Hidden Layer 2 neurons =  372 & Hidden Layer 3 neurons =  146 ; also Droput of 0.2727253713957791\n",
      "\n",
      "\n",
      "--------------------------- Loop 7 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 2.4028 - accuracy: 0.1082 - val_loss: 2.6256 - val_accuracy: 0.1040\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 2.0948 - accuracy: 0.2265 - val_loss: 1.8032 - val_accuracy: 0.3603\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.4435 - accuracy: 0.5026 - val_loss: 1.5104 - val_accuracy: 0.5127\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.1772 - accuracy: 0.6145 - val_loss: 1.3599 - val_accuracy: 0.5992\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.0027 - accuracy: 0.6789 - val_loss: 1.1995 - val_accuracy: 0.6646\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.9057 - accuracy: 0.7093 - val_loss: 1.0745 - val_accuracy: 0.6884\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.8522 - accuracy: 0.7284 - val_loss: 0.9329 - val_accuracy: 0.7295\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.8380 - accuracy: 0.7299 - val_loss: 0.8182 - val_accuracy: 0.7630\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.7845 - accuracy: 0.7499 - val_loss: 0.7652 - val_accuracy: 0.7677\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.7126 - accuracy: 0.7737 - val_loss: 0.6984 - val_accuracy: 0.7831\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.6716 - accuracy: 0.7871 - val_loss: 0.6888 - val_accuracy: 0.7845\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6796 - accuracy: 0.7838 - val_loss: 0.6337 - val_accuracy: 0.8025\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6003 - accuracy: 0.8088 - val_loss: 0.6161 - val_accuracy: 0.8059\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5732 - accuracy: 0.8177 - val_loss: 0.5783 - val_accuracy: 0.8222\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5764 - accuracy: 0.8190 - val_loss: 0.6019 - val_accuracy: 0.8119\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5916 - accuracy: 0.8124 - val_loss: 0.5413 - val_accuracy: 0.8323\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5918 - accuracy: 0.8113 - val_loss: 0.5479 - val_accuracy: 0.8279\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.5431 - accuracy: 0.8257 - val_loss: 0.5104 - val_accuracy: 0.8418\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5561 - accuracy: 0.8223 - val_loss: 0.5118 - val_accuracy: 0.8416\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5452 - accuracy: 0.8258 - val_loss: 0.5184 - val_accuracy: 0.8375\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.5158 - accuracy: 0.8347 - val_loss: 0.5349 - val_accuracy: 0.8324\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4934 - accuracy: 0.8427 - val_loss: 0.5194 - val_accuracy: 0.8395\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4768 - accuracy: 0.8478 - val_loss: 0.4612 - val_accuracy: 0.8568\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4521 - accuracy: 0.8555 - val_loss: 0.4843 - val_accuracy: 0.8518\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4705 - accuracy: 0.8500 - val_loss: 0.4482 - val_accuracy: 0.8612\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4500 - accuracy: 0.8554 - val_loss: 0.4460 - val_accuracy: 0.8625\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4301 - accuracy: 0.8622 - val_loss: 0.4417 - val_accuracy: 0.8624\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4126 - accuracy: 0.8684 - val_loss: 0.4101 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.4080 - accuracy: 0.8702 - val_loss: 0.4219 - val_accuracy: 0.8681\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4228 - accuracy: 0.8651 - val_loss: 0.4000 - val_accuracy: 0.8789\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3967 - accuracy: 0.8723 - val_loss: 0.4545 - val_accuracy: 0.8640\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4881 - accuracy: 0.8432 - val_loss: 0.4143 - val_accuracy: 0.8735\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4473 - accuracy: 0.8543 - val_loss: 0.4530 - val_accuracy: 0.8637\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4631 - accuracy: 0.8502 - val_loss: 0.4072 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.3994 - accuracy: 0.8708 - val_loss: 0.4185 - val_accuracy: 0.8698\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4314 - accuracy: 0.8606 - val_loss: 0.3955 - val_accuracy: 0.8786\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.3592 - accuracy: 0.8848 - val_loss: 0.4029 - val_accuracy: 0.8757\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4047 - accuracy: 0.8699 - val_loss: 0.3845 - val_accuracy: 0.8835\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3845 - accuracy: 0.8835\n",
      "Accuracy on the Validation Data is 0.8835416436195374 and the loss is 0.38447973132133484\n",
      "For Hidden Layer 1 neurons =  558 ,Hidden Layer 2 neurons =  360 & Hidden Layer 3 neurons =  98 ; also Droput of 0.21304143969699385\n",
      "\n",
      "\n",
      "--------------------------- Loop 8 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 2.4135 - accuracy: 0.1058 - val_loss: 2.6148 - val_accuracy: 0.1183\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 2.1313 - accuracy: 0.2047 - val_loss: 1.8943 - val_accuracy: 0.3173\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.4674 - accuracy: 0.4942 - val_loss: 1.6621 - val_accuracy: 0.5052\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 1.1203 - accuracy: 0.6354 - val_loss: 1.4969 - val_accuracy: 0.5996\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.9884 - accuracy: 0.6821 - val_loss: 1.2784 - val_accuracy: 0.6864\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.9123 - accuracy: 0.7072 - val_loss: 1.1445 - val_accuracy: 0.7014\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.8613 - accuracy: 0.7231 - val_loss: 1.0178 - val_accuracy: 0.7325\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.7774 - accuracy: 0.7535 - val_loss: 0.8784 - val_accuracy: 0.7571\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.7319 - accuracy: 0.7667 - val_loss: 0.8157 - val_accuracy: 0.7601\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.7059 - accuracy: 0.7741 - val_loss: 0.9308 - val_accuracy: 0.7201\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.6783 - accuracy: 0.7848 - val_loss: 0.6412 - val_accuracy: 0.8012\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.6042 - accuracy: 0.8088 - val_loss: 0.6536 - val_accuracy: 0.7991\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.6693 - accuracy: 0.7841 - val_loss: 0.5819 - val_accuracy: 0.8192\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.6295 - accuracy: 0.7992 - val_loss: 0.5469 - val_accuracy: 0.8311\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.5448 - accuracy: 0.8254 - val_loss: 0.5597 - val_accuracy: 0.8229\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.5452 - accuracy: 0.8272 - val_loss: 0.5362 - val_accuracy: 0.8295\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5439 - accuracy: 0.8272 - val_loss: 0.5503 - val_accuracy: 0.8247\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.5207 - accuracy: 0.8335 - val_loss: 0.4775 - val_accuracy: 0.8522\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.5420 - accuracy: 0.8266 - val_loss: 0.4933 - val_accuracy: 0.8472\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5229 - accuracy: 0.8340 - val_loss: 0.4902 - val_accuracy: 0.8470\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.4744 - accuracy: 0.8490 - val_loss: 0.4736 - val_accuracy: 0.8527\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4648 - accuracy: 0.8507 - val_loss: 0.5011 - val_accuracy: 0.8466\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5056 - accuracy: 0.8378 - val_loss: 0.4570 - val_accuracy: 0.8590\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4467 - accuracy: 0.8581 - val_loss: 0.4515 - val_accuracy: 0.8590\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4455 - accuracy: 0.8571 - val_loss: 0.4221 - val_accuracy: 0.8684\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.4398 - accuracy: 0.8583 - val_loss: 0.4244 - val_accuracy: 0.8699\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4725 - accuracy: 0.8479 - val_loss: 0.4277 - val_accuracy: 0.8662\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.4148 - accuracy: 0.8665 - val_loss: 0.4164 - val_accuracy: 0.8707\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.4017 - accuracy: 0.8714 - val_loss: 0.4154 - val_accuracy: 0.8723\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.3905 - accuracy: 0.8749 - val_loss: 0.4153 - val_accuracy: 0.8716\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4551 - accuracy: 0.8538 - val_loss: 0.3949 - val_accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.4211 - accuracy: 0.8637 - val_loss: 0.4214 - val_accuracy: 0.8702\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.4014 - accuracy: 0.8704 - val_loss: 0.3937 - val_accuracy: 0.8795\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.3833 - accuracy: 0.8767 - val_loss: 0.3839 - val_accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3790 - accuracy: 0.8788 - val_loss: 0.3658 - val_accuracy: 0.8861\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.3980 - accuracy: 0.8717 - val_loss: 0.3953 - val_accuracy: 0.8783\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.4152 - accuracy: 0.8660 - val_loss: 0.3691 - val_accuracy: 0.8871\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3634 - accuracy: 0.8836 - val_loss: 0.3828 - val_accuracy: 0.8817\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3558 - accuracy: 0.8840 - val_loss: 0.3667 - val_accuracy: 0.8856\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.3720 - accuracy: 0.8790 - val_loss: 0.3606 - val_accuracy: 0.8910\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.3705 - accuracy: 0.8795 - val_loss: 0.3474 - val_accuracy: 0.8946\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.3442 - accuracy: 0.8892 - val_loss: 0.3650 - val_accuracy: 0.8902\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3493 - accuracy: 0.8868 - val_loss: 0.3546 - val_accuracy: 0.8923\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.3496 - accuracy: 0.8868 - val_loss: 0.3452 - val_accuracy: 0.8976\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3422 - accuracy: 0.8879 - val_loss: 0.3532 - val_accuracy: 0.8944\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3473 - accuracy: 0.8874 - val_loss: 0.3530 - val_accuracy: 0.8944\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3306 - accuracy: 0.8926 - val_loss: 0.3473 - val_accuracy: 0.8957\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3131 - accuracy: 0.8982 - val_loss: 0.3399 - val_accuracy: 0.9003\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3095 - accuracy: 0.8983 - val_loss: 0.3445 - val_accuracy: 0.8974\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3526 - accuracy: 0.8846 - val_loss: 0.3361 - val_accuracy: 0.8989\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3361 - accuracy: 0.8989\n",
      "Accuracy on the Validation Data is 0.8988749980926514 and the loss is 0.33614885807037354\n",
      "For Hidden Layer 1 neurons =  602 ,Hidden Layer 2 neurons =  465 & Hidden Layer 3 neurons =  98 ; also Droput of 0.2601690270663655\n",
      "\n",
      "\n",
      "--------------------------- Loop 9 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 2.3740 - accuracy: 0.1069 - val_loss: 2.7259 - val_accuracy: 0.1068\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.1448 - accuracy: 0.1969 - val_loss: 1.8853 - val_accuracy: 0.3743\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.4684 - accuracy: 0.4926 - val_loss: 1.6799 - val_accuracy: 0.5292\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.1391 - accuracy: 0.6299 - val_loss: 1.5099 - val_accuracy: 0.6229\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.9742 - accuracy: 0.6865 - val_loss: 1.4270 - val_accuracy: 0.6532\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.8885 - accuracy: 0.7168 - val_loss: 1.2625 - val_accuracy: 0.6730\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.8775 - accuracy: 0.7190 - val_loss: 1.0781 - val_accuracy: 0.7270\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.7680 - accuracy: 0.7556 - val_loss: 1.0176 - val_accuracy: 0.7399\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.7546 - accuracy: 0.7577 - val_loss: 0.9268 - val_accuracy: 0.7387\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.6850 - accuracy: 0.7825 - val_loss: 0.8343 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.6353 - accuracy: 0.7978 - val_loss: 0.8084 - val_accuracy: 0.7613\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.6881 - accuracy: 0.7791 - val_loss: 0.7025 - val_accuracy: 0.7855\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.6056 - accuracy: 0.8061 - val_loss: 0.6049 - val_accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.6329 - accuracy: 0.7998 - val_loss: 0.6554 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.6313 - accuracy: 0.7994 - val_loss: 0.6297 - val_accuracy: 0.8044\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5717 - accuracy: 0.8182 - val_loss: 0.5861 - val_accuracy: 0.8156\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5550 - accuracy: 0.8230 - val_loss: 0.6434 - val_accuracy: 0.8005\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5754 - accuracy: 0.8176 - val_loss: 0.5343 - val_accuracy: 0.8336\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5084 - accuracy: 0.8389 - val_loss: 0.5467 - val_accuracy: 0.8295\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5163 - accuracy: 0.8359 - val_loss: 0.4695 - val_accuracy: 0.8529\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5142 - accuracy: 0.8346 - val_loss: 0.5137 - val_accuracy: 0.8385\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4855 - accuracy: 0.8445 - val_loss: 0.5156 - val_accuracy: 0.8425\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.4704 - accuracy: 0.8486 - val_loss: 0.4757 - val_accuracy: 0.8504\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4680 - accuracy: 0.8503 - val_loss: 0.4590 - val_accuracy: 0.8585\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5031 - accuracy: 0.8393 - val_loss: 0.5073 - val_accuracy: 0.8430\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4908 - accuracy: 0.8417 - val_loss: 0.4503 - val_accuracy: 0.8616\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.4352 - accuracy: 0.8603 - val_loss: 0.4522 - val_accuracy: 0.8605\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4351 - accuracy: 0.8610 - val_loss: 0.4402 - val_accuracy: 0.8627\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.4238 - accuracy: 0.8651 - val_loss: 0.4406 - val_accuracy: 0.8631\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.4390 - accuracy: 0.8588 - val_loss: 0.4245 - val_accuracy: 0.8677\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.4110 - accuracy: 0.8676 - val_loss: 0.4003 - val_accuracy: 0.8768\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3755 - accuracy: 0.8802 - val_loss: 0.4067 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3878 - accuracy: 0.8749 - val_loss: 0.4075 - val_accuracy: 0.8747\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3922 - accuracy: 0.8729 - val_loss: 0.4284 - val_accuracy: 0.8683\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.3896 - accuracy: 0.8736 - val_loss: 0.3999 - val_accuracy: 0.8764\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.3769 - accuracy: 0.8794 - val_loss: 0.4111 - val_accuracy: 0.8743\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3597 - accuracy: 0.8846 - val_loss: 0.4000 - val_accuracy: 0.8782\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3632 - accuracy: 0.8828 - val_loss: 0.3812 - val_accuracy: 0.8834\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3358 - accuracy: 0.8925 - val_loss: 0.4330 - val_accuracy: 0.8698\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.3828 - accuracy: 0.8761 - val_loss: 0.4192 - val_accuracy: 0.8741\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3942 - accuracy: 0.8715 - val_loss: 0.3656 - val_accuracy: 0.8909\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3687 - accuracy: 0.8813 - val_loss: 0.3735 - val_accuracy: 0.8883\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3311 - accuracy: 0.8926 - val_loss: 0.3832 - val_accuracy: 0.8837\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3242 - accuracy: 0.8954 - val_loss: 0.3866 - val_accuracy: 0.8866\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3423 - accuracy: 0.8899 - val_loss: 0.3527 - val_accuracy: 0.8965\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3051 - accuracy: 0.9005 - val_loss: 0.3912 - val_accuracy: 0.8830\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3913 - accuracy: 0.8721 - val_loss: 0.3658 - val_accuracy: 0.8894\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.3236 - accuracy: 0.8948 - val_loss: 0.3876 - val_accuracy: 0.8870\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3232 - accuracy: 0.8953 - val_loss: 0.3839 - val_accuracy: 0.8872\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.3043 - accuracy: 0.8997 - val_loss: 0.3381 - val_accuracy: 0.9003\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.3169 - accuracy: 0.8963 - val_loss: 0.3620 - val_accuracy: 0.8929\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8929\n",
      "Accuracy on the Validation Data is 0.8928750157356262 and the loss is 0.362037718296051\n",
      "For Hidden Layer 1 neurons =  684 ,Hidden Layer 2 neurons =  364 & Hidden Layer 3 neurons =  108 ; also Droput of 0.21970453770771473\n",
      "\n",
      "\n",
      "--------------------------- Loop 10 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 2.4014 - accuracy: 0.1037 - val_loss: 2.8800 - val_accuracy: 0.1057\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 2.2484 - accuracy: 0.1526 - val_loss: 1.9953 - val_accuracy: 0.2989\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 1.6244 - accuracy: 0.4240 - val_loss: 1.7614 - val_accuracy: 0.4358\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 1.2103 - accuracy: 0.5981 - val_loss: 1.7113 - val_accuracy: 0.5130\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 1.0070 - accuracy: 0.6771 - val_loss: 1.5686 - val_accuracy: 0.6082\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.9071 - accuracy: 0.7078 - val_loss: 1.4590 - val_accuracy: 0.6376\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.8168 - accuracy: 0.7366 - val_loss: 1.3351 - val_accuracy: 0.6841\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.7888 - accuracy: 0.7475 - val_loss: 1.2347 - val_accuracy: 0.6992\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.7808 - accuracy: 0.7503 - val_loss: 1.0151 - val_accuracy: 0.7517\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.6967 - accuracy: 0.7769 - val_loss: 0.9247 - val_accuracy: 0.7685\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.6527 - accuracy: 0.7914 - val_loss: 0.8353 - val_accuracy: 0.7860\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.6547 - accuracy: 0.7913 - val_loss: 0.7955 - val_accuracy: 0.7819\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.6399 - accuracy: 0.7956 - val_loss: 0.6906 - val_accuracy: 0.7929\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.5728 - accuracy: 0.8174 - val_loss: 0.6221 - val_accuracy: 0.8143\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.5463 - accuracy: 0.8243 - val_loss: 0.5840 - val_accuracy: 0.8187\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.5418 - accuracy: 0.8257 - val_loss: 0.5382 - val_accuracy: 0.8339\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.5099 - accuracy: 0.8362 - val_loss: 0.5436 - val_accuracy: 0.8260\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.5171 - accuracy: 0.8342 - val_loss: 0.4832 - val_accuracy: 0.8502\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.4840 - accuracy: 0.8457 - val_loss: 0.4725 - val_accuracy: 0.8514\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.4734 - accuracy: 0.8488 - val_loss: 0.4666 - val_accuracy: 0.8547\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4509 - accuracy: 0.8559 - val_loss: 0.4662 - val_accuracy: 0.8562\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.4702 - accuracy: 0.8496 - val_loss: 0.5351 - val_accuracy: 0.8357\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4668 - accuracy: 0.8487 - val_loss: 0.4699 - val_accuracy: 0.8527\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4526 - accuracy: 0.8527 - val_loss: 0.4407 - val_accuracy: 0.8614\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4283 - accuracy: 0.8622 - val_loss: 0.4156 - val_accuracy: 0.8710\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4010 - accuracy: 0.8708 - val_loss: 0.4208 - val_accuracy: 0.8672\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4352 - accuracy: 0.8584 - val_loss: 0.4586 - val_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.4417 - accuracy: 0.8556 - val_loss: 0.4199 - val_accuracy: 0.8705\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4052 - accuracy: 0.8684 - val_loss: 0.4005 - val_accuracy: 0.8753\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.4527 - accuracy: 0.8534 - val_loss: 0.4173 - val_accuracy: 0.8712\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3919 - accuracy: 0.8739 - val_loss: 0.3908 - val_accuracy: 0.8798\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 112ms/step - loss: 0.3968 - accuracy: 0.8707 - val_loss: 0.3962 - val_accuracy: 0.8781\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.3923 - accuracy: 0.8730 - val_loss: 0.4017 - val_accuracy: 0.8751\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 114ms/step - loss: 0.3900 - accuracy: 0.8729 - val_loss: 0.3726 - val_accuracy: 0.8846\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3573 - accuracy: 0.8842 - val_loss: 0.4127 - val_accuracy: 0.8753\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3588 - accuracy: 0.8831 - val_loss: 0.4204 - val_accuracy: 0.8743\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.3669 - accuracy: 0.8818 - val_loss: 0.3621 - val_accuracy: 0.8906\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.3681 - accuracy: 0.8799 - val_loss: 0.3640 - val_accuracy: 0.8892\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3564 - accuracy: 0.8834 - val_loss: 0.3701 - val_accuracy: 0.8885\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3402 - accuracy: 0.8894 - val_loss: 0.3671 - val_accuracy: 0.8924\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3430 - accuracy: 0.8876 - val_loss: 0.3522 - val_accuracy: 0.8930\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.3599 - accuracy: 0.8828 - val_loss: 0.3512 - val_accuracy: 0.8938\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3618 - accuracy: 0.8829 - val_loss: 0.3617 - val_accuracy: 0.8934\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 0.3561 - accuracy: 0.8838 - val_loss: 0.3483 - val_accuracy: 0.8974\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.3496 - accuracy: 0.8862 - val_loss: 0.3547 - val_accuracy: 0.8932\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.3261 - accuracy: 0.8939 - val_loss: 0.3395 - val_accuracy: 0.8969\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.3453 - accuracy: 0.8877 - val_loss: 0.3435 - val_accuracy: 0.8977\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8977\n",
      "Accuracy on the Validation Data is 0.8976666927337646 and the loss is 0.3435101807117462\n",
      "For Hidden Layer 1 neurons =  675 ,Hidden Layer 2 neurons =  476 & Hidden Layer 3 neurons =  135 ; also Droput of 0.27191972629920436\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intializing empty lists\n",
    "Layer_1_neurons=[]\n",
    "Layer_2_neurons = []\n",
    "Layer_3_neurons = []\n",
    "Dropout = []\n",
    "Loss = []\n",
    "Accuracy = []\n",
    "\n",
    "# Tuning\n",
    "for i in range(10):\n",
    "    print('--------------------------- Loop {0} ---------------------------'.format(i+1))\n",
    "    layer_1 = np.random.randint(500,700)\n",
    "    layer_2 = np.random.randint(350,500)\n",
    "    layer_3 = np.random.randint(75,150)\n",
    "    drop = np.random.uniform(0.2,0.3)\n",
    "    mod = model_arch(X_train,y_train,loops = 100,hidden_layer_1_neurons= layer_1,hidden_layer_2_neurons= layer_2,hidden_layer_3_neurons= layer_3,\n",
    "                     dropout=drop,learningrate = 0.01, regularization = 0,val=True,x_val=X_val,y_val=y_val)\n",
    "    # Performance of model\n",
    "    loss,accuracy = mod.evaluate(X_val,y_val)\n",
    "    print('Accuracy on the Validation Data is {0} and the loss is {1}'.format(accuracy,loss))\n",
    "    print('For Hidden Layer 1 neurons =  {0} ,Hidden Layer 2 neurons =  {1} & Hidden Layer 3 neurons =  {2} ; also Droput of {3}'.format(layer_1,layer_2,layer_3,drop))\n",
    "    print('\\n')\n",
    "    Layer_1_neurons.append(layer_1)\n",
    "    Layer_2_neurons.append(layer_2)\n",
    "    Layer_3_neurons.append(layer_3)\n",
    "    Dropout.append(drop)\n",
    "    Loss.append(loss)\n",
    "    Accuracy.append(accuracy)\n",
    "    \n",
    "# Visualizng the Results\n",
    "data = pd.DataFrame(Layer_1_neurons,columns=['Layer 1 neurons'])\n",
    "data['Layer 2 neurons'] = Layer_2_neurons\n",
    "data['Layer 3 neurons'] = Layer_3_neurons\n",
    "data['Dropout'] = Dropout\n",
    "data['Loss'] = Loss\n",
    "data['Accuracy'] = Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 neurons</th>\n",
       "      <th>Layer 2 neurons</th>\n",
       "      <th>Layer 3 neurons</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>519</td>\n",
       "      <td>424</td>\n",
       "      <td>142</td>\n",
       "      <td>0.222203</td>\n",
       "      <td>0.323804</td>\n",
       "      <td>0.905875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>573</td>\n",
       "      <td>483</td>\n",
       "      <td>102</td>\n",
       "      <td>0.208721</td>\n",
       "      <td>0.380555</td>\n",
       "      <td>0.884250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>581</td>\n",
       "      <td>391</td>\n",
       "      <td>106</td>\n",
       "      <td>0.213650</td>\n",
       "      <td>0.333982</td>\n",
       "      <td>0.902292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>405</td>\n",
       "      <td>145</td>\n",
       "      <td>0.203822</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.905250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>657</td>\n",
       "      <td>465</td>\n",
       "      <td>95</td>\n",
       "      <td>0.273805</td>\n",
       "      <td>0.350440</td>\n",
       "      <td>0.894250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>659</td>\n",
       "      <td>372</td>\n",
       "      <td>146</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.324060</td>\n",
       "      <td>0.901458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>558</td>\n",
       "      <td>360</td>\n",
       "      <td>98</td>\n",
       "      <td>0.213041</td>\n",
       "      <td>0.384480</td>\n",
       "      <td>0.883542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>602</td>\n",
       "      <td>465</td>\n",
       "      <td>98</td>\n",
       "      <td>0.260169</td>\n",
       "      <td>0.336149</td>\n",
       "      <td>0.898875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>684</td>\n",
       "      <td>364</td>\n",
       "      <td>108</td>\n",
       "      <td>0.219705</td>\n",
       "      <td>0.362038</td>\n",
       "      <td>0.892875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>675</td>\n",
       "      <td>476</td>\n",
       "      <td>135</td>\n",
       "      <td>0.271920</td>\n",
       "      <td>0.343510</td>\n",
       "      <td>0.897667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layer 1 neurons  Layer 2 neurons  Layer 3 neurons   Dropout      Loss  \\\n",
       "0              519              424              142  0.222203  0.323804   \n",
       "1              573              483              102  0.208721  0.380555   \n",
       "2              581              391              106  0.213650  0.333982   \n",
       "3              512              405              145  0.203822  0.335400   \n",
       "4              657              465               95  0.273805  0.350440   \n",
       "5              659              372              146  0.272725  0.324060   \n",
       "6              558              360               98  0.213041  0.384480   \n",
       "7              602              465               98  0.260169  0.336149   \n",
       "8              684              364              108  0.219705  0.362038   \n",
       "9              675              476              135  0.271920  0.343510   \n",
       "\n",
       "   Accuracy  \n",
       "0  0.905875  \n",
       "1  0.884250  \n",
       "2  0.902292  \n",
       "3  0.905250  \n",
       "4  0.894250  \n",
       "5  0.901458  \n",
       "6  0.883542  \n",
       "7  0.898875  \n",
       "8  0.892875  \n",
       "9  0.897667  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be choosing following valuesof architectural hyperparameters\n",
    "\n",
    "Number of neurons in Layer 1 = 520\n",
    "\n",
    "Number of neurons in Layer 2 = 420\n",
    " \n",
    "Number of neurons in Layer 3 = 142\n",
    "\n",
    "Dropout = 0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate and regularization tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intializing the NN model function\n",
    "def model(X,Y,loops,learningrate,regularization,val = False,x_val = None,y_val = None,Test = False,x_test= None,y_test =None):\n",
    "    # intializing the model\n",
    "    NN_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(520),\n",
    "        tf.keras.layers.Dropout(0.22),  # Dropouts are generally used after Activation functions but it can be used before for relu\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dense(420),\n",
    "        tf.keras.layers.Dropout(0.22),  # Dropouts are generally used after Activation functions but it can be used before for relu\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dense(142),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dense(10,activation = 'softmax',kernel_regularizer = tf.keras.regularizers.l2(regularization))\n",
    "    ])\n",
    "    \n",
    "    # Adam Optimizer\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= learningrate,beta_1 =0.8 ,beta_2=0.89,decay = 1e-4)\n",
    "    \n",
    "    # Compile\n",
    "    NN_model.compile(optimizer= adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 10 , min_delta = 0.01 )\n",
    "    \n",
    "    if val == True:\n",
    "        NN_model.fit(X,Y,epochs=loops,validation_data=(x_val,y_val),batch_size = int(X.shape[0]/21),callbacks=[callback])\n",
    "    else:\n",
    "         NN_model.fit(X,Y,epochs=loops,batch_size = int(X.shape[0]/21))\n",
    "    \n",
    "    return(NN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Model for Resonability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 89ms/step - loss: 2.4116 - accuracy: 0.1028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x24b8068cd30>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train,y_train,loops = 1,learningrate = 0.01, regularization = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial accuracy of the model is around 10% percent which signifies there is no bias in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Loss (Increasing Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 88ms/step - loss: 5075112.5000 - accuracy: 0.1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x24babd04970>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train,y_train,loops = 1,learningrate = 0.01, regularization = 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loss is shooting up. Verified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the Network is overfitting on small sub set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train[:100,:]\n",
    "y_train_subset = y_train[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.2583 - accuracy: 0.1100\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5154 - accuracy: 0.1300\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5270 - accuracy: 0.1300\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.5656 - accuracy: 0.1200\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.3821 - accuracy: 0.2100\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.4239 - accuracy: 0.2400\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.2423 - accuracy: 0.2300\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.1074 - accuracy: 0.3200\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.8970 - accuracy: 0.3400\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.0163 - accuracy: 0.3200\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.9557 - accuracy: 0.3500\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7802 - accuracy: 0.4100\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7017 - accuracy: 0.4100\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5661 - accuracy: 0.4300\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5226 - accuracy: 0.4800\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5364 - accuracy: 0.4600\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4613 - accuracy: 0.5500\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3454 - accuracy: 0.5700\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.5800\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0619 - accuracy: 0.6900\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1704 - accuracy: 0.5800\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9684 - accuracy: 0.6500\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.1982 - accuracy: 0.61 - 0s 4ms/step - loss: 1.1552 - accuracy: 0.6300\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0364 - accuracy: 0.6300\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.6900\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2170 - accuracy: 0.5800\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0111 - accuracy: 0.6600\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8827 - accuracy: 0.6900\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7712 - accuracy: 0.7600\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9841 - accuracy: 0.6800\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.8200\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8586 - accuracy: 0.7300\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.7600\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.8400\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.8400\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7746 - accuracy: 0.7900\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8342 - accuracy: 0.7600\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7669 - accuracy: 0.7800\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6809 - accuracy: 0.7800\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9542 - accuracy: 0.7800\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8575 - accuracy: 0.7100\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0026 - accuracy: 0.7400\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.7600\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.8100\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.8600\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7762 - accuracy: 0.8100\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.8400\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.8500\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.8300\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8400\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8300\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.8300\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.8200\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.8400\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7482 - accuracy: 0.8200\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.9000\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.8800\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8900\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.8500\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8193 - accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8800\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8700\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8700\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.8500\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8629 - accuracy: 0.7600: 0s - loss: 0.9090 - accuracy: 0.\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8900\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0604 - accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.8800\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.8800\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8500\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.8600\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.8800\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8600\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.8700\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.8600\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.8300\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8800\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8700\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9500\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.9000\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.8400\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9000\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9400\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8900\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.8900\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9100\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8900\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9200\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.9100\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.8400\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9500\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8900\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8700\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8900\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8800\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.9000\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9500\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.9000\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.9100\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.8900\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.8900\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8700\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.9200\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9300\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.9300\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.8600\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2718 - accuracy: 0.9000\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.9100\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.9100\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.9000\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.9100\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.8700\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.9100\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.9200\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7524 - accuracy: 0.8600\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.9300\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8700\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9500\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.8800\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9700\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.9200\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8900\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9400\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9400\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.9000\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.9200\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8900\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.9000\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8900\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.9000\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8900\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9300\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.9300\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.9100\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.9200\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1463 - accuracy: 0.9500\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.9700\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.9500\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9500\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9200\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.9300\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2628 - accuracy: 0.9300\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.9300\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2737 - accuracy: 0.9400\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.9000\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9300\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.9200\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9400\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9800\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 0.9400\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2152 - accuracy: 0.9000\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.9400\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9500\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9200\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.9000\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.9200\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.9300\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2134 - accuracy: 0.9500\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2829 - accuracy: 0.9300\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.9000\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9200\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9200\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.8900\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.9500\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8700\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9300\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.9300\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.9400\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.9400\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9900\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.9100\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.9400\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.9100\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8391 - accuracy: 0.8400\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9700\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.9100\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.9700\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.9200\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.9300\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9800\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.8700\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9800\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9400\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9900\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.9300\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.9300\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.9200\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.9200\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.9300\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9800\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9300\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.9300\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9300\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9700\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.9300\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.9300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5.7068e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0005706765223294497, 1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = model(X_train_subset,y_train_subset,loops = 200,learningrate = 0.01, regularization = 0)\n",
    "mod.evaluate(X_train_subset,y_train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is perfectly overfitting the small dataset.\n",
    "Thus there is no problems in model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Loop 1 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 51.2035 - accuracy: 0.2499 - val_loss: 36.7299 - val_accuracy: 0.5229\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 28.0105 - accuracy: 0.5972 - val_loss: 19.1699 - val_accuracy: 0.6563\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 13.9931 - accuracy: 0.6758 - val_loss: 8.8876 - val_accuracy: 0.7211\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 6.2393 - accuracy: 0.7179 - val_loss: 3.8465 - val_accuracy: 0.7057\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 2.9187 - accuracy: 0.7221 - val_loss: 2.1370 - val_accuracy: 0.6940\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 2.0454 - accuracy: 0.7320 - val_loss: 1.8788 - val_accuracy: 0.7052\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 1.9148 - accuracy: 0.7494 - val_loss: 1.8007 - val_accuracy: 0.7529\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 1.8577 - accuracy: 0.7637 - val_loss: 1.7366 - val_accuracy: 0.7648\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 1.8058 - accuracy: 0.7790 - val_loss: 1.7225 - val_accuracy: 0.7740\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 1.7616 - accuracy: 0.7908 - val_loss: 1.7466 - val_accuracy: 0.7620\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 1.7589 - accuracy: 0.7744 - val_loss: 1.6516 - val_accuracy: 0.7940\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 1.6907 - accuracy: 0.8034 - val_loss: 1.6871 - val_accuracy: 0.7874\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 1.6686 - accuracy: 0.8011 - val_loss: 1.6084 - val_accuracy: 0.8161\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 1.6217 - accuracy: 0.8177 - val_loss: 1.6275 - val_accuracy: 0.8087\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.5814 - accuracy: 0.8266 - val_loss: 1.6319 - val_accuracy: 0.8207\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 1.5609 - accuracy: 0.8281 - val_loss: 1.5777 - val_accuracy: 0.8110\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 1.5339 - accuracy: 0.8299 - val_loss: 1.5989 - val_accuracy: 0.8303\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 1.5103 - accuracy: 0.8339 - val_loss: 1.5256 - val_accuracy: 0.8234\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 1.4767 - accuracy: 0.8406 - val_loss: 1.5447 - val_accuracy: 0.8224\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 1.4930 - accuracy: 0.8228 - val_loss: 1.4701 - val_accuracy: 0.8443\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 1.4247 - accuracy: 0.8479 - val_loss: 1.5110 - val_accuracy: 0.8163\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 1.4920 - accuracy: 0.8069 - val_loss: 1.4131 - val_accuracy: 0.8218\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.4289 - accuracy: 0.8299 - val_loss: 1.4065 - val_accuracy: 0.8322\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.3865 - accuracy: 0.8448 - val_loss: 1.3834 - val_accuracy: 0.8415\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.3483 - accuracy: 0.8546 - val_loss: 1.4632 - val_accuracy: 0.8348\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 1.3521 - accuracy: 0.8463 - val_loss: 1.3510 - val_accuracy: 0.8507\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.3087 - accuracy: 0.8599 - val_loss: 1.3138 - val_accuracy: 0.8583\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2862 - accuracy: 0.8626 - val_loss: 1.3399 - val_accuracy: 0.8423\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 1.2865 - accuracy: 0.8573 - val_loss: 1.3361 - val_accuracy: 0.8543\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.2631 - accuracy: 0.8624 - val_loss: 1.2986 - val_accuracy: 0.8602\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2350 - accuracy: 0.8694 - val_loss: 1.2914 - val_accuracy: 0.8513\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2619 - accuracy: 0.8512 - val_loss: 1.2832 - val_accuracy: 0.8542\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 1.2045 - accuracy: 0.8745 - val_loss: 1.2672 - val_accuracy: 0.8567\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 1.1931 - accuracy: 0.8729 - val_loss: 1.2751 - val_accuracy: 0.8557\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1770 - accuracy: 0.8737 - val_loss: 1.2408 - val_accuracy: 0.8612\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 1.1715 - accuracy: 0.8728 - val_loss: 1.2793 - val_accuracy: 0.8610\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 1.1766 - accuracy: 0.8656 - val_loss: 1.1907 - val_accuracy: 0.8645\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 1.1907 - accuracy: 0.8645\n",
      "Accuracy on the Validation Data is 0.8644583225250244 and the loss is 1.1907172203063965\n",
      "For Learning Rate of 0.0015965558284139433 and Regularization of 3.343622516011404\n",
      "\n",
      "\n",
      "--------------------------- Loop 2 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 2.1203 - accuracy: 0.2709 - val_loss: 1.4323 - val_accuracy: 0.5420\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.2779 - accuracy: 0.5991 - val_loss: 1.1366 - val_accuracy: 0.6527\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1283 - accuracy: 0.6493 - val_loss: 0.9992 - val_accuracy: 0.6898\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.9840 - accuracy: 0.6963 - val_loss: 0.8942 - val_accuracy: 0.7324\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.9054 - accuracy: 0.7230 - val_loss: 0.8523 - val_accuracy: 0.7438\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.8731 - accuracy: 0.7347 - val_loss: 0.7933 - val_accuracy: 0.7567\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7760 - accuracy: 0.7650 - val_loss: 0.7875 - val_accuracy: 0.7645\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7440 - accuracy: 0.7749 - val_loss: 0.6963 - val_accuracy: 0.7920\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.6693 - accuracy: 0.7981 - val_loss: 0.6950 - val_accuracy: 0.7931\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.7037 - accuracy: 0.7870 - val_loss: 0.6226 - val_accuracy: 0.8148\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6349 - accuracy: 0.8095 - val_loss: 0.6698 - val_accuracy: 0.8003\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6414 - accuracy: 0.8084 - val_loss: 0.6200 - val_accuracy: 0.8188\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6292 - accuracy: 0.8106 - val_loss: 0.5873 - val_accuracy: 0.8266\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6315 - accuracy: 0.8087 - val_loss: 0.5806 - val_accuracy: 0.82826551 - accu\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5786 - accuracy: 0.8261 - val_loss: 0.6161 - val_accuracy: 0.8204\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5938 - accuracy: 0.8211 - val_loss: 0.6010 - val_accuracy: 0.8211\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5827 - accuracy: 0.8253 - val_loss: 0.5737 - val_accuracy: 0.8321\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5743 - accuracy: 0.8258 - val_loss: 0.5342 - val_accuracy: 0.8398\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5509 - accuracy: 0.8357 - val_loss: 0.5110 - val_accuracy: 0.8510\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5139 - accuracy: 0.8477 - val_loss: 0.4809 - val_accuracy: 0.8614\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4915 - accuracy: 0.8556 - val_loss: 0.5255 - val_accuracy: 0.8462\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4878 - accuracy: 0.8554 - val_loss: 0.5381 - val_accuracy: 0.8455\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5017 - accuracy: 0.8500 - val_loss: 0.4735 - val_accuracy: 0.8628\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5052 - accuracy: 0.8501 - val_loss: 0.4803 - val_accuracy: 0.8603\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4958 - accuracy: 0.8531 - val_loss: 0.4960 - val_accuracy: 0.8547\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5277 - accuracy: 0.8410 - val_loss: 0.4565 - val_accuracy: 0.8685\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4387 - accuracy: 0.8708 - val_loss: 0.4687 - val_accuracy: 0.8651\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4634 - accuracy: 0.8616 - val_loss: 0.4596 - val_accuracy: 0.8678\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4245 - accuracy: 0.8764 - val_loss: 0.4586 - val_accuracy: 0.8694\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4078 - accuracy: 0.8815 - val_loss: 0.4592 - val_accuracy: 0.8711\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4592 - accuracy: 0.8711\n",
      "Accuracy on the Validation Data is 0.8710833191871643 and the loss is 0.4592267572879791\n",
      "For Learning Rate of 0.0015298833459884997 and Regularization of 0.001214492985103269\n",
      "\n",
      "\n",
      "--------------------------- Loop 3 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 2.3960 - accuracy: 0.1108 - val_loss: 2.9903 - val_accuracy: 0.1280\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 2.1401 - accuracy: 0.2004 - val_loss: 1.9222 - val_accuracy: 0.2882\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.5237 - accuracy: 0.4706 - val_loss: 1.6739 - val_accuracy: 0.4883\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.1675 - accuracy: 0.6201 - val_loss: 1.4784 - val_accuracy: 0.5946\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.9930 - accuracy: 0.6844 - val_loss: 1.3184 - val_accuracy: 0.6647\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.8617 - accuracy: 0.7277 - val_loss: 1.1420 - val_accuracy: 0.7254\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8060 - accuracy: 0.7428 - val_loss: 1.0540 - val_accuracy: 0.7139\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.8756 - accuracy: 0.7208 - val_loss: 0.9597 - val_accuracy: 0.7125\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7921 - accuracy: 0.7492 - val_loss: 0.7817 - val_accuracy: 0.7773\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7252 - accuracy: 0.7715 - val_loss: 0.7661 - val_accuracy: 0.7739\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.7513 - accuracy: 0.7627 - val_loss: 0.7823 - val_accuracy: 0.7614\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.6556 - accuracy: 0.7949 - val_loss: 0.7059 - val_accuracy: 0.7823\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7147 - accuracy: 0.7745 - val_loss: 0.6134 - val_accuracy: 0.8115\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6082 - accuracy: 0.8092 - val_loss: 0.6019 - val_accuracy: 0.8150\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.5870 - accuracy: 0.8158 - val_loss: 0.6406 - val_accuracy: 0.8013\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5939 - accuracy: 0.8142 - val_loss: 0.6182 - val_accuracy: 0.8083\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5828 - accuracy: 0.8171 - val_loss: 0.5712 - val_accuracy: 0.8255\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5589 - accuracy: 0.8260 - val_loss: 0.5443 - val_accuracy: 0.8301\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5381 - accuracy: 0.8323 - val_loss: 0.5351 - val_accuracy: 0.8370\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5131 - accuracy: 0.8413 - val_loss: 0.5666 - val_accuracy: 0.8288\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.5203 - accuracy: 0.8375 - val_loss: 0.5403 - val_accuracy: 0.8363\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.4933 - accuracy: 0.8482 - val_loss: 0.4903 - val_accuracy: 0.8533\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5005 - accuracy: 0.8462 - val_loss: 0.5738 - val_accuracy: 0.8316\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5404 - accuracy: 0.8312 - val_loss: 0.4561 - val_accuracy: 0.8613\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4660 - accuracy: 0.8555 - val_loss: 0.4652 - val_accuracy: 0.8603\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4451 - accuracy: 0.8622 - val_loss: 0.4509 - val_accuracy: 0.8648\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4457 - accuracy: 0.8622 - val_loss: 0.4771 - val_accuracy: 0.8572\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4317 - accuracy: 0.8672 - val_loss: 0.4425 - val_accuracy: 0.8685\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4312 - accuracy: 0.8670 - val_loss: 0.5106 - val_accuracy: 0.8479\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4820 - accuracy: 0.8503 - val_loss: 0.4685 - val_accuracy: 0.8604\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5117 - accuracy: 0.8406 - val_loss: 0.4497 - val_accuracy: 0.8660\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4658 - accuracy: 0.8561 - val_loss: 0.4478 - val_accuracy: 0.8685\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4853 - accuracy: 0.8492 - val_loss: 0.5276 - val_accuracy: 0.8445\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5133 - accuracy: 0.8382 - val_loss: 0.4240 - val_accuracy: 0.8737\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4113 - accuracy: 0.8736 - val_loss: 0.4729 - val_accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5249 - accuracy: 0.8365 - val_loss: 0.4531 - val_accuracy: 0.8634\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4531 - accuracy: 0.8634\n",
      "Accuracy on the Validation Data is 0.8634166717529297 and the loss is 0.4530622959136963\n",
      "For Learning Rate of 0.01081203320225772 and Regularization of 0.00030076397768004045\n",
      "\n",
      "\n",
      "--------------------------- Loop 4 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.3187 - accuracy: 0.2261 - val_loss: 1.8429 - val_accuracy: 0.4790\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.6752 - accuracy: 0.4863 - val_loss: 1.4773 - val_accuracy: 0.6203\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.4012 - accuracy: 0.5963 - val_loss: 1.2938 - val_accuracy: 0.6824\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 88ms/step - loss: 1.2477 - accuracy: 0.6485 - val_loss: 1.1791 - val_accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.1445 - accuracy: 0.6826 - val_loss: 1.0884 - val_accuracy: 0.7361\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.0797 - accuracy: 0.7023 - val_loss: 1.0113 - val_accuracy: 0.7522\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.9844 - accuracy: 0.7318 - val_loss: 0.9423 - val_accuracy: 0.7751\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.9241 - accuracy: 0.7508 - val_loss: 0.8890 - val_accuracy: 0.7845\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.9023 - accuracy: 0.7554 - val_loss: 0.8332 - val_accuracy: 0.7943\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.8393 - accuracy: 0.7769 - val_loss: 0.8026 - val_accuracy: 0.8002\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.8221 - accuracy: 0.7802 - val_loss: 0.7736 - val_accuracy: 0.8060\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.8082 - accuracy: 0.7843 - val_loss: 0.7350 - val_accuracy: 0.8111\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.7896 - accuracy: 0.7876 - val_loss: 0.7044 - val_accuracy: 0.8193\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7391 - accuracy: 0.8041 - val_loss: 0.6788 - val_accuracy: 0.8274\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7170 - accuracy: 0.8120 - val_loss: 0.7043 - val_accuracy: 0.8137\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7230 - accuracy: 0.8070 - val_loss: 0.6364 - val_accuracy: 0.8384\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6825 - accuracy: 0.8205 - val_loss: 0.6440 - val_accuracy: 0.8322\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.6703 - accuracy: 0.8235 - val_loss: 0.6148 - val_accuracy: 0.8414\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6442 - accuracy: 0.8317 - val_loss: 0.6079 - val_accuracy: 0.8457\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6587 - accuracy: 0.8251 - val_loss: 0.6069 - val_accuracy: 0.8451\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6559 - accuracy: 0.8257 - val_loss: 0.5886 - val_accuracy: 0.8495\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.6251 - accuracy: 0.8355 - val_loss: 0.5876 - val_accuracy: 0.8469\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.6174 - accuracy: 0.8367 - val_loss: 0.5794 - val_accuracy: 0.8480\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5978 - accuracy: 0.8434 - val_loss: 0.5893 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6013 - accuracy: 0.8406 - val_loss: 0.5646 - val_accuracy: 0.8530\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5950 - accuracy: 0.8423 - val_loss: 0.5529 - val_accuracy: 0.8555\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5617 - accuracy: 0.8530 - val_loss: 0.5536 - val_accuracy: 0.8540\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5668 - accuracy: 0.8488 - val_loss: 0.5482 - val_accuracy: 0.8567\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.6088 - accuracy: 0.8374 - val_loss: 0.5414 - val_accuracy: 0.8613\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5798 - accuracy: 0.8454 - val_loss: 0.5361 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.5749 - accuracy: 0.8466 - val_loss: 0.5285 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5450 - accuracy: 0.8556 - val_loss: 0.5367 - val_accuracy: 0.8589\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5224 - accuracy: 0.8643 - val_loss: 0.5220 - val_accuracy: 0.8638\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5353 - accuracy: 0.8576 - val_loss: 0.5094 - val_accuracy: 0.8690\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5451 - accuracy: 0.8559 - val_loss: 0.4907 - val_accuracy: 0.8759\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4987 - accuracy: 0.8712 - val_loss: 0.5032 - val_accuracy: 0.8708\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.5034 - accuracy: 0.8697 - val_loss: 0.5046 - val_accuracy: 0.8681\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5302 - accuracy: 0.8593 - val_loss: 0.4854 - val_accuracy: 0.8773\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.4763 - accuracy: 0.8772 - val_loss: 0.4765 - val_accuracy: 0.8797\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.4745 - accuracy: 0.8777 - val_loss: 0.5271 - val_accuracy: 0.8637\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5068 - accuracy: 0.8660 - val_loss: 0.4850 - val_accuracy: 0.8744\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 0.5075 - accuracy: 0.8654 - val_loss: 0.4777 - val_accuracy: 0.8768\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.5041 - accuracy: 0.8654 - val_loss: 0.4826 - val_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 0.4798 - accuracy: 0.8729 - val_loss: 0.4706 - val_accuracy: 0.8796\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4603 - accuracy: 0.8796 - val_loss: 0.4594 - val_accuracy: 0.8852\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4594 - accuracy: 0.8852\n",
      "Accuracy on the Validation Data is 0.8852499723434448 and the loss is 0.4594411253929138\n",
      "For Learning Rate of 0.0003929182506168061 and Regularization of 0.005410898569596944\n",
      "\n",
      "\n",
      "--------------------------- Loop 5 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 3.1144 - accuracy: 0.1269 - val_loss: 2.6351 - val_accuracy: 0.1412\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 2.2021 - accuracy: 0.2572 - val_loss: 1.8804 - val_accuracy: 0.3608\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.6419 - accuracy: 0.4913 - val_loss: 1.6183 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.3608 - accuracy: 0.6089 - val_loss: 1.4333 - val_accuracy: 0.6296\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 1.1507 - accuracy: 0.6881 - val_loss: 1.3234 - val_accuracy: 0.6729\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0605 - accuracy: 0.7157 - val_loss: 1.1476 - val_accuracy: 0.7293\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.9885 - accuracy: 0.7404 - val_loss: 1.2157 - val_accuracy: 0.6697\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.9532 - accuracy: 0.7473 - val_loss: 1.0137 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9076 - accuracy: 0.7583 - val_loss: 1.0272 - val_accuracy: 0.7287\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8676 - accuracy: 0.7732 - val_loss: 0.8700 - val_accuracy: 0.7763\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8172 - accuracy: 0.7879 - val_loss: 0.8321 - val_accuracy: 0.7799\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8509 - accuracy: 0.7723 - val_loss: 0.8184 - val_accuracy: 0.7787\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7869 - accuracy: 0.7937 - val_loss: 0.7475 - val_accuracy: 0.8021\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7441 - accuracy: 0.8080 - val_loss: 0.7517 - val_accuracy: 0.7985\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7317 - accuracy: 0.8079 - val_loss: 0.6952 - val_accuracy: 0.8178\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6817 - accuracy: 0.8255 - val_loss: 0.6804 - val_accuracy: 0.8219\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6885 - accuracy: 0.8201 - val_loss: 0.8413 - val_accuracy: 0.7755\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7971 - accuracy: 0.7822 - val_loss: 0.8182 - val_accuracy: 0.7842\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6969 - accuracy: 0.8152 - val_loss: 0.6456 - val_accuracy: 0.8268\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6873 - accuracy: 0.8181 - val_loss: 0.6194 - val_accuracy: 0.8366\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6338 - accuracy: 0.8355 - val_loss: 0.5939 - val_accuracy: 0.8452\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5963 - accuracy: 0.8470 - val_loss: 0.6241 - val_accuracy: 0.8369\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6010 - accuracy: 0.8434 - val_loss: 0.6193 - val_accuracy: 0.8353\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6190 - accuracy: 0.8368 - val_loss: 0.6237 - val_accuracy: 0.8320\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5890 - accuracy: 0.8453 - val_loss: 0.5466 - val_accuracy: 0.8563\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5447 - accuracy: 0.8584 - val_loss: 0.5622 - val_accuracy: 0.8522\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5466 - accuracy: 0.8592 - val_loss: 0.5729 - val_accuracy: 0.8439\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5560 - accuracy: 0.8540 - val_loss: 0.5682 - val_accuracy: 0.8520\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5685 - accuracy: 0.8476 - val_loss: 0.5831 - val_accuracy: 0.8445\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5688 - accuracy: 0.8484 - val_loss: 0.5936 - val_accuracy: 0.8407\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5478 - accuracy: 0.8563 - val_loss: 0.5401 - val_accuracy: 0.8598\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4895 - accuracy: 0.8744 - val_loss: 0.5090 - val_accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5050 - accuracy: 0.8691 - val_loss: 0.5503 - val_accuracy: 0.8563\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5691 - accuracy: 0.8452 - val_loss: 0.5308 - val_accuracy: 0.8560\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5553 - accuracy: 0.8494 - val_loss: 0.5361 - val_accuracy: 0.8579\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5059 - accuracy: 0.8662 - val_loss: 0.5346 - val_accuracy: 0.8593\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5005 - accuracy: 0.8683 - val_loss: 0.5015 - val_accuracy: 0.8672\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5030 - accuracy: 0.8665 - val_loss: 0.4607 - val_accuracy: 0.8813\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4708 - accuracy: 0.8776 - val_loss: 0.5323 - val_accuracy: 0.8575\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4989 - accuracy: 0.8649 - val_loss: 0.4674 - val_accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4869 - accuracy: 0.8693 - val_loss: 0.4892 - val_accuracy: 0.8688\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4479 - accuracy: 0.8838 - val_loss: 0.4834 - val_accuracy: 0.8751\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4782 - accuracy: 0.8707 - val_loss: 0.5015 - val_accuracy: 0.8668\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4985 - accuracy: 0.8652 - val_loss: 0.4600 - val_accuracy: 0.8785\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4235 - accuracy: 0.8895 - val_loss: 0.4651 - val_accuracy: 0.8795\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4713 - accuracy: 0.8747 - val_loss: 0.4557 - val_accuracy: 0.8845\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4340 - accuracy: 0.8858 - val_loss: 0.4500 - val_accuracy: 0.8833\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4051 - accuracy: 0.8967 - val_loss: 0.4591 - val_accuracy: 0.8806\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.8806\n",
      "Accuracy on the Validation Data is 0.8805833458900452 and the loss is 0.459105521440506\n",
      "For Learning Rate of 0.004612964426229195 and Regularization of 0.07039346778698621\n",
      "\n",
      "\n",
      "--------------------------- Loop 6 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.5232 - accuracy: 0.1024 - val_loss: 3.5338 - val_accuracy: 0.1037\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.3299 - accuracy: 0.1138 - val_loss: 2.4913 - val_accuracy: 0.1240\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.1196 - accuracy: 0.1815 - val_loss: 2.0663 - val_accuracy: 0.1938\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.8261 - accuracy: 0.3139 - val_loss: 1.7607 - val_accuracy: 0.3522\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.4209 - accuracy: 0.5064 - val_loss: 1.7150 - val_accuracy: 0.4272\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.2104 - accuracy: 0.6013 - val_loss: 1.5024 - val_accuracy: 0.5288\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1678 - accuracy: 0.6210 - val_loss: 1.3225 - val_accuracy: 0.6171\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.0130 - accuracy: 0.6781 - val_loss: 1.1539 - val_accuracy: 0.6680\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.9346 - accuracy: 0.7069 - val_loss: 1.0575 - val_accuracy: 0.6950\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8742 - accuracy: 0.7270 - val_loss: 0.9982 - val_accuracy: 0.6914\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8818 - accuracy: 0.7255 - val_loss: 0.9096 - val_accuracy: 0.7248\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8644 - accuracy: 0.7299 - val_loss: 0.9218 - val_accuracy: 0.7228\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7760 - accuracy: 0.7622 - val_loss: 0.7952 - val_accuracy: 0.7539\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7806 - accuracy: 0.7573 - val_loss: 0.7347 - val_accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7925 - accuracy: 0.7506 - val_loss: 0.7708 - val_accuracy: 0.7675\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7472 - accuracy: 0.7684 - val_loss: 0.7142 - val_accuracy: 0.7794\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7233 - accuracy: 0.7771 - val_loss: 0.7493 - val_accuracy: 0.7686\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7358 - accuracy: 0.7731 - val_loss: 0.6882 - val_accuracy: 0.7974\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6592 - accuracy: 0.7980 - val_loss: 0.6352 - val_accuracy: 0.8095\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6716 - accuracy: 0.7945 - val_loss: 0.6453 - val_accuracy: 0.8021\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6722 - accuracy: 0.7925 - val_loss: 0.5991 - val_accuracy: 0.8181\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6106 - accuracy: 0.8122 - val_loss: 0.6033 - val_accuracy: 0.8163\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6107 - accuracy: 0.8125 - val_loss: 0.6574 - val_accuracy: 0.8012\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6065 - accuracy: 0.8138 - val_loss: 0.5838 - val_accuracy: 0.8247\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5833 - accuracy: 0.8206 - val_loss: 0.5549 - val_accuracy: 0.8320\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5792 - accuracy: 0.8236 - val_loss: 0.6529 - val_accuracy: 0.8085\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6168 - accuracy: 0.8098 - val_loss: 0.5408 - val_accuracy: 0.8373\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5437 - accuracy: 0.8345 - val_loss: 0.5634 - val_accuracy: 0.8314\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5705 - accuracy: 0.8248 - val_loss: 0.5363 - val_accuracy: 0.8405\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5756 - accuracy: 0.8225 - val_loss: 0.5221 - val_accuracy: 0.8430\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5187 - accuracy: 0.8404 - val_loss: 0.5172 - val_accuracy: 0.8445\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5569 - accuracy: 0.8277 - val_loss: 0.4831 - val_accuracy: 0.8551\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4973 - accuracy: 0.8483 - val_loss: 0.4826 - val_accuracy: 0.8565\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5046 - accuracy: 0.8453 - val_loss: 0.4914 - val_accuracy: 0.8534\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4947 - accuracy: 0.8485 - val_loss: 0.5568 - val_accuracy: 0.8398\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5146 - accuracy: 0.8426 - val_loss: 0.4796 - val_accuracy: 0.8577\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4447 - accuracy: 0.8649 - val_loss: 0.4844 - val_accuracy: 0.8550\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4987 - accuracy: 0.8468 - val_loss: 0.5110 - val_accuracy: 0.8497\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4979 - accuracy: 0.8471 - val_loss: 0.4396 - val_accuracy: 0.8709\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4067 - accuracy: 0.8764 - val_loss: 0.4334 - val_accuracy: 0.8730\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4333 - accuracy: 0.8672 - val_loss: 0.4407 - val_accuracy: 0.8701\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.86 - 2s 94ms/step - loss: 0.4414 - accuracy: 0.8667 - val_loss: 0.4365 - val_accuracy: 0.8693\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4276 - accuracy: 0.8694 - val_loss: 0.4280 - val_accuracy: 0.8724\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4503 - accuracy: 0.8622 - val_loss: 0.4165 - val_accuracy: 0.8798\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4408 - accuracy: 0.8658 - val_loss: 0.4227 - val_accuracy: 0.8765\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4222 - accuracy: 0.8717 - val_loss: 0.4469 - val_accuracy: 0.8695\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4512 - accuracy: 0.8619 - val_loss: 0.4298 - val_accuracy: 0.8744\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4221 - accuracy: 0.8715 - val_loss: 0.3980 - val_accuracy: 0.8856\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3872 - accuracy: 0.8827 - val_loss: 0.4133 - val_accuracy: 0.8798\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4265 - accuracy: 0.8692 - val_loss: 0.4108 - val_accuracy: 0.8813\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3897 - accuracy: 0.8821 - val_loss: 0.3917 - val_accuracy: 0.8867\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3765 - accuracy: 0.8850 - val_loss: 0.4236 - val_accuracy: 0.8773\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4336 - accuracy: 0.8672 - val_loss: 0.3993 - val_accuracy: 0.8836\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3608 - accuracy: 0.8898 - val_loss: 0.4098 - val_accuracy: 0.8790\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4160 - accuracy: 0.8720 - val_loss: 0.3971 - val_accuracy: 0.8854\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3726 - accuracy: 0.8867 - val_loss: 0.3956 - val_accuracy: 0.8854\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3592 - accuracy: 0.8913 - val_loss: 0.4000 - val_accuracy: 0.8845\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3441 - accuracy: 0.8951 - val_loss: 0.3947 - val_accuracy: 0.8869\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3947 - accuracy: 0.8869\n",
      "Accuracy on the Validation Data is 0.8869166374206543 and the loss is 0.39466768503189087\n",
      "For Learning Rate of 0.03252526996493353 and Regularization of 0.0002573192205289726\n",
      "\n",
      "\n",
      "--------------------------- Loop 7 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 5.6951 - accuracy: 0.1304 - val_loss: 5.3035 - val_accuracy: 0.2467\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 5.3560 - accuracy: 0.1960 - val_loss: 5.0415 - val_accuracy: 0.3435\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 5.0761 - accuracy: 0.2679 - val_loss: 4.7956 - val_accuracy: 0.4307\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 4.8018 - accuracy: 0.3424 - val_loss: 4.5714 - val_accuracy: 0.4977\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 4.5426 - accuracy: 0.4193 - val_loss: 4.3571 - val_accuracy: 0.5514\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 4.3155 - accuracy: 0.4842 - val_loss: 4.1631 - val_accuracy: 0.5952\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 4.1210 - accuracy: 0.5349 - val_loss: 3.9893 - val_accuracy: 0.6306\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 3.9487 - accuracy: 0.5745 - val_loss: 3.8333 - val_accuracy: 0.6520\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 3.7972 - accuracy: 0.6026 - val_loss: 3.6881 - val_accuracy: 0.6706\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 3.6539 - accuracy: 0.6262 - val_loss: 3.5472 - val_accuracy: 0.6873\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 3.5183 - accuracy: 0.6453 - val_loss: 3.4187 - val_accuracy: 0.6993\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 3.3966 - accuracy: 0.6606 - val_loss: 3.2974 - val_accuracy: 0.7112\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 3.2797 - accuracy: 0.6764 - val_loss: 3.1854 - val_accuracy: 0.7200\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 3.1692 - accuracy: 0.6854 - val_loss: 3.0751 - val_accuracy: 0.7305\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 3.0657 - accuracy: 0.6953 - val_loss: 2.9743 - val_accuracy: 0.7385\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.9735 - accuracy: 0.7028 - val_loss: 2.8780 - val_accuracy: 0.7430\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.8836 - accuracy: 0.7115 - val_loss: 2.7852 - val_accuracy: 0.7487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.7960 - accuracy: 0.7176 - val_loss: 2.6991 - val_accuracy: 0.7522\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.7166 - accuracy: 0.7222 - val_loss: 2.6153 - val_accuracy: 0.7577\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.6281 - accuracy: 0.7316 - val_loss: 2.5320 - val_accuracy: 0.7617\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.5516 - accuracy: 0.7368 - val_loss: 2.4560 - val_accuracy: 0.7637\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.4764 - accuracy: 0.7400 - val_loss: 2.3797 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.4068 - accuracy: 0.7451 - val_loss: 2.3086 - val_accuracy: 0.7716\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.3397 - accuracy: 0.7490 - val_loss: 2.2412 - val_accuracy: 0.7744\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.2661 - accuracy: 0.7550 - val_loss: 2.1726 - val_accuracy: 0.7790\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.1994 - accuracy: 0.7595 - val_loss: 2.1089 - val_accuracy: 0.7815\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.1403 - accuracy: 0.7628 - val_loss: 2.0443 - val_accuracy: 0.7850\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.0779 - accuracy: 0.7668 - val_loss: 1.9863 - val_accuracy: 0.7874\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.0265 - accuracy: 0.7695 - val_loss: 1.9316 - val_accuracy: 0.7901\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 1.9745 - accuracy: 0.7712 - val_loss: 1.8791 - val_accuracy: 0.7921\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.9178 - accuracy: 0.7756 - val_loss: 1.8250 - val_accuracy: 0.7979\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.8670 - accuracy: 0.7797 - val_loss: 1.7777 - val_accuracy: 0.7985\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.8222 - accuracy: 0.7807 - val_loss: 1.7292 - val_accuracy: 0.8027\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.7741 - accuracy: 0.7837 - val_loss: 1.6874 - val_accuracy: 0.8023\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 1.7307 - accuracy: 0.7869 - val_loss: 1.6410 - val_accuracy: 0.8051\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.6879 - accuracy: 0.7894 - val_loss: 1.6020 - val_accuracy: 0.8074\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.6566 - accuracy: 0.7890 - val_loss: 1.5631 - val_accuracy: 0.8095\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.6154 - accuracy: 0.7930 - val_loss: 1.5234 - val_accuracy: 0.8119\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.5739 - accuracy: 0.7977 - val_loss: 1.4912 - val_accuracy: 0.8123\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.5379 - accuracy: 0.7996 - val_loss: 1.4587 - val_accuracy: 0.8139\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.5076 - accuracy: 0.8022 - val_loss: 1.4326 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.4810 - accuracy: 0.8023 - val_loss: 1.3960 - val_accuracy: 0.8169\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.4482 - accuracy: 0.8049 - val_loss: 1.3672 - val_accuracy: 0.8188\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.4163 - accuracy: 0.8067 - val_loss: 1.3388 - val_accuracy: 0.8212\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.3887 - accuracy: 0.8086 - val_loss: 1.3124 - val_accuracy: 0.8227\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.3648 - accuracy: 0.8096 - val_loss: 1.2852 - val_accuracy: 0.8246\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3392 - accuracy: 0.8120 - val_loss: 1.2680 - val_accuracy: 0.8229\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3162 - accuracy: 0.8136 - val_loss: 1.2424 - val_accuracy: 0.8258\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.2941 - accuracy: 0.8144 - val_loss: 1.2259 - val_accuracy: 0.8261\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.2777 - accuracy: 0.8146 - val_loss: 1.2033 - val_accuracy: 0.8282\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.2477 - accuracy: 0.8193 - val_loss: 1.1864 - val_accuracy: 0.8285\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.2296 - accuracy: 0.8205 - val_loss: 1.1679 - val_accuracy: 0.8304\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.2141 - accuracy: 0.8217 - val_loss: 1.1490 - val_accuracy: 0.8327\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1961 - accuracy: 0.8224 - val_loss: 1.1378 - val_accuracy: 0.8332\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1815 - accuracy: 0.8223 - val_loss: 1.1201 - val_accuracy: 0.8354\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1654 - accuracy: 0.8238 - val_loss: 1.1058 - val_accuracy: 0.8357\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1505 - accuracy: 0.8265 - val_loss: 1.0912 - val_accuracy: 0.8362\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1362 - accuracy: 0.8265 - val_loss: 1.0771 - val_accuracy: 0.8378\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.1228 - accuracy: 0.8285 - val_loss: 1.0675 - val_accuracy: 0.8375\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.1142 - accuracy: 0.8283 - val_loss: 1.0567 - val_accuracy: 0.8395\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0938 - accuracy: 0.8327 - val_loss: 1.0425 - val_accuracy: 0.8423\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0848 - accuracy: 0.8324 - val_loss: 1.0357 - val_accuracy: 0.8393\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.0757 - accuracy: 0.8323 - val_loss: 1.0230 - val_accuracy: 0.8430\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.0611 - accuracy: 0.8334 - val_loss: 1.0145 - val_accuracy: 0.8434\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.0522 - accuracy: 0.8350 - val_loss: 1.0068 - val_accuracy: 0.8438\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 1.0068 - accuracy: 0.8438\n",
      "Accuracy on the Validation Data is 0.84375 and the loss is 1.0067510604858398\n",
      "For Learning Rate of 0.00010027928127585857 and Regularization of 0.17164682054509056\n",
      "\n",
      "\n",
      "--------------------------- Loop 8 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 2.4004 - accuracy: 0.1173 - val_loss: 2.9384 - val_accuracy: 0.1147\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.0305 - accuracy: 0.2520 - val_loss: 1.8947 - val_accuracy: 0.3295\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.4545 - accuracy: 0.5071 - val_loss: 1.4493 - val_accuracy: 0.5737\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1215 - accuracy: 0.6395 - val_loss: 1.3390 - val_accuracy: 0.6277\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.9879 - accuracy: 0.6874 - val_loss: 1.1721 - val_accuracy: 0.6825\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9380 - accuracy: 0.7046 - val_loss: 1.1034 - val_accuracy: 0.6766\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9177 - accuracy: 0.7111 - val_loss: 0.9495 - val_accuracy: 0.7144\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8269 - accuracy: 0.7409 - val_loss: 0.8195 - val_accuracy: 0.7662\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7740 - accuracy: 0.7615 - val_loss: 0.7604 - val_accuracy: 0.7788\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7646 - accuracy: 0.7610 - val_loss: 0.7609 - val_accuracy: 0.7678\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7301 - accuracy: 0.7732 - val_loss: 0.6653 - val_accuracy: 0.7975\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6595 - accuracy: 0.7965 - val_loss: 0.9508 - val_accuracy: 0.7221\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6519 - accuracy: 0.8003 - val_loss: 0.6117 - val_accuracy: 0.8128\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6082 - accuracy: 0.8142 - val_loss: 0.6909 - val_accuracy: 0.7887\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6604 - accuracy: 0.7956 - val_loss: 0.5682 - val_accuracy: 0.8264\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5886 - accuracy: 0.8208 - val_loss: 0.5616 - val_accuracy: 0.8292\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5760 - accuracy: 0.8231 - val_loss: 0.6958 - val_accuracy: 0.7930\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6678 - accuracy: 0.7946 - val_loss: 0.5608 - val_accuracy: 0.8330\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5797 - accuracy: 0.8221 - val_loss: 0.5699 - val_accuracy: 0.8269\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5647 - accuracy: 0.8284 - val_loss: 0.5214 - val_accuracy: 0.8423\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5205 - accuracy: 0.8417 - val_loss: 0.6467 - val_accuracy: 0.8050\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5584 - accuracy: 0.8291 - val_loss: 0.5348 - val_accuracy: 0.8403\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5566 - accuracy: 0.8287 - val_loss: 0.5408 - val_accuracy: 0.8378\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5370 - accuracy: 0.8373 - val_loss: 0.5217 - val_accuracy: 0.8439\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5784 - accuracy: 0.8208 - val_loss: 0.5398 - val_accuracy: 0.8392\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5417 - accuracy: 0.8340 - val_loss: 0.4637 - val_accuracy: 0.8639\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4626 - accuracy: 0.8608 - val_loss: 0.4663 - val_accuracy: 0.8640\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4668 - accuracy: 0.8578 - val_loss: 0.5886 - val_accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5034 - accuracy: 0.8467 - val_loss: 0.4519 - val_accuracy: 0.8651\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4560 - accuracy: 0.8614 - val_loss: 0.4644 - val_accuracy: 0.8632\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4501 - accuracy: 0.8636 - val_loss: 0.4690 - val_accuracy: 0.8601\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4760 - accuracy: 0.8545 - val_loss: 0.4533 - val_accuracy: 0.8646\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4666 - accuracy: 0.8579 - val_loss: 0.4865 - val_accuracy: 0.8568\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4497 - accuracy: 0.8628 - val_loss: 0.4264 - val_accuracy: 0.8748\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4416 - accuracy: 0.8659 - val_loss: 0.4694 - val_accuracy: 0.8616\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4357 - accuracy: 0.8673 - val_loss: 0.4245 - val_accuracy: 0.8745\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4239 - accuracy: 0.8708 - val_loss: 0.3997 - val_accuracy: 0.8833\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3694 - accuracy: 0.8904 - val_loss: 0.4575 - val_accuracy: 0.8655\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4358 - accuracy: 0.8680 - val_loss: 0.4375 - val_accuracy: 0.8719\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3931 - accuracy: 0.8817 - val_loss: 0.3891 - val_accuracy: 0.8870\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3797 - accuracy: 0.8855 - val_loss: 0.4157 - val_accuracy: 0.8778\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3966 - accuracy: 0.8792 - val_loss: 0.4020 - val_accuracy: 0.8855\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3936 - accuracy: 0.8804 - val_loss: 0.4078 - val_accuracy: 0.8813\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3734 - accuracy: 0.8865 - val_loss: 0.3775 - val_accuracy: 0.8928\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3634 - accuracy: 0.8904 - val_loss: 0.3855 - val_accuracy: 0.8899\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3723 - accuracy: 0.8883 - val_loss: 0.3897 - val_accuracy: 0.8888\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3945 - accuracy: 0.8787 - val_loss: 0.3887 - val_accuracy: 0.8875\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3964 - accuracy: 0.8787 - val_loss: 0.3740 - val_accuracy: 0.8942\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3490 - accuracy: 0.8949 - val_loss: 0.3690 - val_accuracy: 0.8949\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3229 - accuracy: 0.9034 - val_loss: 0.3815 - val_accuracy: 0.8917\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8917\n",
      "Accuracy on the Validation Data is 0.8917083144187927 and the loss is 0.38149791955947876\n",
      "For Learning Rate of 0.009361253281837834 and Regularization of 0.0007843220370791703\n",
      "\n",
      "\n",
      "--------------------------- Loop 9 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 8.6550 - accuracy: 0.2808 - val_loss: 6.3889 - val_accuracy: 0.5648\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 5.3260 - accuracy: 0.5718 - val_loss: 4.0558 - val_accuracy: 0.6494\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 3.3651 - accuracy: 0.6665 - val_loss: 2.6543 - val_accuracy: 0.6909\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.2201 - accuracy: 0.7112 - val_loss: 1.8562 - val_accuracy: 0.7208\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 1.6779 - accuracy: 0.7320 - val_loss: 1.5007 - val_accuracy: 0.7195\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.4622 - accuracy: 0.7433 - val_loss: 1.3517 - val_accuracy: 0.7468\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.3632 - accuracy: 0.7548 - val_loss: 1.3513 - val_accuracy: 0.7131\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.3227 - accuracy: 0.7566 - val_loss: 1.2351 - val_accuracy: 0.7603\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2517 - accuracy: 0.7756 - val_loss: 1.1612 - val_accuracy: 0.7825\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1852 - accuracy: 0.7916 - val_loss: 1.1908 - val_accuracy: 0.7677\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1666 - accuracy: 0.7914 - val_loss: 1.1180 - val_accuracy: 0.7946\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1009 - accuracy: 0.8104 - val_loss: 1.1503 - val_accuracy: 0.7747\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 93ms/step - loss: 1.0956 - accuracy: 0.8043 - val_loss: 1.1130 - val_accuracy: 0.7876\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.0710 - accuracy: 0.8084 - val_loss: 1.0792 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.0980 - accuracy: 0.7944 - val_loss: 0.9587 - val_accuracy: 0.8313\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9851 - accuracy: 0.8319 - val_loss: 1.0980 - val_accuracy: 0.7922\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.0666 - accuracy: 0.7980 - val_loss: 0.9701 - val_accuracy: 0.8108\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9576 - accuracy: 0.8323 - val_loss: 1.0052 - val_accuracy: 0.8057\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9378 - accuracy: 0.8347 - val_loss: 0.9239 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8945 - accuracy: 0.8478 - val_loss: 0.9783 - val_accuracy: 0.8230\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.9199 - accuracy: 0.8355 - val_loss: 0.9492 - val_accuracy: 0.8398\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8665 - accuracy: 0.8507 - val_loss: 0.9210 - val_accuracy: 0.8443\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8639 - accuracy: 0.8486 - val_loss: 0.8724 - val_accuracy: 0.8580\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8377 - accuracy: 0.8551 - val_loss: 0.8458 - val_accuracy: 0.8566\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8218 - accuracy: 0.8582 - val_loss: 0.8406 - val_accuracy: 0.8602\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7984 - accuracy: 0.8650 - val_loss: 0.8158 - val_accuracy: 0.8618\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7765 - accuracy: 0.8695 - val_loss: 0.8588 - val_accuracy: 0.8433\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8102 - accuracy: 0.8543 - val_loss: 0.8434 - val_accuracy: 0.8627\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7906 - accuracy: 0.8605 - val_loss: 0.7776 - val_accuracy: 0.8618\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7351 - accuracy: 0.8762 - val_loss: 0.8120 - val_accuracy: 0.8651\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7430 - accuracy: 0.8736 - val_loss: 0.7603 - val_accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7185 - accuracy: 0.8807 - val_loss: 0.7622 - val_accuracy: 0.8734\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7137 - accuracy: 0.8779 - val_loss: 0.7556 - val_accuracy: 0.8684\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6943 - accuracy: 0.8840 - val_loss: 0.7350 - val_accuracy: 0.8739\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6838 - accuracy: 0.8854 - val_loss: 0.7565 - val_accuracy: 0.8716\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6856 - accuracy: 0.8839 - val_loss: 0.7406 - val_accuracy: 0.8712\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6818 - accuracy: 0.8826 - val_loss: 0.7899 - val_accuracy: 0.8615\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6836 - accuracy: 0.8807 - val_loss: 0.7642 - val_accuracy: 0.8657\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.6857 - accuracy: 0.8797 - val_loss: 0.7292 - val_accuracy: 0.8749\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6977 - accuracy: 0.8726 - val_loss: 0.6966 - val_accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6564 - accuracy: 0.8854 - val_loss: 0.6813 - val_accuracy: 0.8773\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.6813 - accuracy: 0.8773\n",
      "Accuracy on the Validation Data is 0.8772916793823242 and the loss is 0.6812729239463806\n",
      "For Learning Rate of 0.0013921018029706778 and Regularization of 0.4381576815310997\n",
      "\n",
      "\n",
      "--------------------------- Loop 10 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 51.4253 - accuracy: 0.2557 - val_loss: 41.6170 - val_accuracy: 0.5340\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 35.1700 - accuracy: 0.5609 - val_loss: 28.1229 - val_accuracy: 0.6200\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 23.3676 - accuracy: 0.6252 - val_loss: 18.1392 - val_accuracy: 0.6803\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 14.7671 - accuracy: 0.6794 - val_loss: 11.1269 - val_accuracy: 0.7005\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 8.8696 - accuracy: 0.7124 - val_loss: 6.4902 - val_accuracy: 0.7282\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 5.1605 - accuracy: 0.7325 - val_loss: 3.7493 - val_accuracy: 0.7422\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 3.1206 - accuracy: 0.7525 - val_loss: 2.4225 - val_accuracy: 0.7628\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.2259 - accuracy: 0.7621 - val_loss: 1.9702 - val_accuracy: 0.7458\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.9529 - accuracy: 0.7623 - val_loss: 1.8392 - val_accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.8699 - accuracy: 0.7791 - val_loss: 1.8114 - val_accuracy: 0.7652\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.8302 - accuracy: 0.7886 - val_loss: 1.7883 - val_accuracy: 0.7853\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.7892 - accuracy: 0.8001 - val_loss: 1.7753 - val_accuracy: 0.7864\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.7820 - accuracy: 0.7916 - val_loss: 1.7535 - val_accuracy: 0.7922\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.7344 - accuracy: 0.8107 - val_loss: 1.7589 - val_accuracy: 0.7987\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.7406 - accuracy: 0.7921 - val_loss: 1.6715 - val_accuracy: 0.8212\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.6789 - accuracy: 0.8218 - val_loss: 1.6916 - val_accuracy: 0.8087\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.6572 - accuracy: 0.8265 - val_loss: 1.6741 - val_accuracy: 0.8056\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.6509 - accuracy: 0.8188 - val_loss: 1.6552 - val_accuracy: 0.8112\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.6125 - accuracy: 0.8339 - val_loss: 1.6823 - val_accuracy: 0.8152\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.6077 - accuracy: 0.8276 - val_loss: 1.6485 - val_accuracy: 0.8271\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.5835 - accuracy: 0.8327 - val_loss: 1.5911 - val_accuracy: 0.8383\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.5477 - accuracy: 0.8441 - val_loss: 1.6297 - val_accuracy: 0.8067\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.5652 - accuracy: 0.8264 - val_loss: 1.5666 - val_accuracy: 0.8327\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.5108 - accuracy: 0.8486 - val_loss: 1.5648 - val_accuracy: 0.8365\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.4886 - accuracy: 0.8524 - val_loss: 1.5856 - val_accuracy: 0.8281\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.4818 - accuracy: 0.8502 - val_loss: 1.5430 - val_accuracy: 0.8454\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 96ms/step - loss: 1.4551 - accuracy: 0.8569 - val_loss: 1.5249 - val_accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.4388 - accuracy: 0.8597 - val_loss: 1.5367 - val_accuracy: 0.8324\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.4453 - accuracy: 0.8502 - val_loss: 1.5163 - val_accuracy: 0.8517\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.4053 - accuracy: 0.8639 - val_loss: 1.4945 - val_accuracy: 0.8521\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.3978 - accuracy: 0.8626 - val_loss: 1.4560 - val_accuracy: 0.8575\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3844 - accuracy: 0.8625 - val_loss: 1.4255 - val_accuracy: 0.8629\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.3605 - accuracy: 0.8691 - val_loss: 1.4207 - val_accuracy: 0.8574\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3526 - accuracy: 0.8667 - val_loss: 1.4621 - val_accuracy: 0.8490\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3712 - accuracy: 0.8537 - val_loss: 1.4254 - val_accuracy: 0.8547\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.3254 - accuracy: 0.8708 - val_loss: 1.3843 - val_accuracy: 0.8609\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3022 - accuracy: 0.8784 - val_loss: 1.4085 - val_accuracy: 0.8648\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2933 - accuracy: 0.8766 - val_loss: 1.3826 - val_accuracy: 0.8611\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.2833 - accuracy: 0.8774 - val_loss: 1.3625 - val_accuracy: 0.8669\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2690 - accuracy: 0.8790 - val_loss: 1.3715 - val_accuracy: 0.8641\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2711 - accuracy: 0.8743 - val_loss: 1.3392 - val_accuracy: 0.8555\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2501 - accuracy: 0.8801 - val_loss: 1.2993 - val_accuracy: 0.8725\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 1.2993 - accuracy: 0.8725\n",
      "Accuracy on the Validation Data is 0.8724583387374878 and the loss is 1.2993061542510986\n",
      "For Learning Rate of 0.0010270423541440352 and Regularization of 3.2121026871062037\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intializing Lists\n",
    "Learning_rate = []\n",
    "Lamda = []\n",
    "Loss = []\n",
    "Accuracy = []\n",
    "\n",
    "# Tunning\n",
    "for i in range(10):\n",
    "    print('--------------------------- Loop {0} ---------------------------'.format(i+1))\n",
    "    lr = math.pow(10,np.random.uniform(-4,-1))\n",
    "    lamda = math.pow(10,np.random.uniform(-5,1))\n",
    "    mod = model(X_train,y_train,loops= 100, learningrate= lr,regularization=lamda,val=True,x_val=X_val,y_val=y_val)\n",
    "    loss,accuracy = mod.evaluate(X_val,y_val)\n",
    "    \n",
    "    Learning_rate.append(lr)\n",
    "    Lamda.append(lamda)\n",
    "    Loss.append(loss)\n",
    "    Accuracy.append(accuracy)\n",
    "    \n",
    "    print('Accuracy on the Validation Data is {0} and the loss is {1}'.format(accuracy,loss))\n",
    "    print('For Learning Rate of {0} and Regularization of {1}'.format(lr,lamda))\n",
    "    print('\\n')\n",
    "    \n",
    "# Visualizng the Results\n",
    "data = pd.DataFrame(Learning_rate,columns=['Learning Rate'])\n",
    "data['Lamda'] = Lamda\n",
    "data['Loss'] = Loss\n",
    "data['Accuracy'] = Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Lamda</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001597</td>\n",
       "      <td>3.343623</td>\n",
       "      <td>1.190717</td>\n",
       "      <td>0.864458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.871083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.453062</td>\n",
       "      <td>0.863417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.459441</td>\n",
       "      <td>0.885250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.070393</td>\n",
       "      <td>0.459106</td>\n",
       "      <td>0.880583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032525</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.394668</td>\n",
       "      <td>0.886917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171647</td>\n",
       "      <td>1.006751</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.381498</td>\n",
       "      <td>0.891708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.438158</td>\n",
       "      <td>0.681273</td>\n",
       "      <td>0.877292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001027</td>\n",
       "      <td>3.212103</td>\n",
       "      <td>1.299306</td>\n",
       "      <td>0.872458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate     Lamda      Loss  Accuracy\n",
       "0       0.001597  3.343623  1.190717  0.864458\n",
       "1       0.001530  0.001214  0.459227  0.871083\n",
       "2       0.010812  0.000301  0.453062  0.863417\n",
       "3       0.000393  0.005411  0.459441  0.885250\n",
       "4       0.004613  0.070393  0.459106  0.880583\n",
       "5       0.032525  0.000257  0.394668  0.886917\n",
       "6       0.000100  0.171647  1.006751  0.843750\n",
       "7       0.009361  0.000784  0.381498  0.891708\n",
       "8       0.001392  0.438158  0.681273  0.877292\n",
       "9       0.001027  3.212103  1.299306  0.872458"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According the Table above we will set the parameters window as below \n",
    "\n",
    "Learning rate : 1e-4 to 1e-1\n",
    "\n",
    "Lamda         : 1e-7 to 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Loop 1 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 2.4534 - accuracy: 0.1075 - val_loss: 3.0093 - val_accuracy: 0.1033\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.2672 - accuracy: 0.1410 - val_loss: 2.1139 - val_accuracy: 0.1763\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.8019 - accuracy: 0.3422 - val_loss: 1.7447 - val_accuracy: 0.4112\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.4333 - accuracy: 0.5086 - val_loss: 1.5275 - val_accuracy: 0.5177\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.1299 - accuracy: 0.6298 - val_loss: 1.5145 - val_accuracy: 0.5472\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0458 - accuracy: 0.6611 - val_loss: 1.3339 - val_accuracy: 0.6158\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.9743 - accuracy: 0.6847 - val_loss: 1.1888 - val_accuracy: 0.6570\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8832 - accuracy: 0.7179 - val_loss: 1.0385 - val_accuracy: 0.7075\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8389 - accuracy: 0.7335 - val_loss: 1.0162 - val_accuracy: 0.6948\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8443 - accuracy: 0.7287 - val_loss: 0.9224 - val_accuracy: 0.7226\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8208 - accuracy: 0.7385 - val_loss: 0.8071 - val_accuracy: 0.7488\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7366 - accuracy: 0.7657 - val_loss: 0.7440 - val_accuracy: 0.7682\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7313 - accuracy: 0.7680 - val_loss: 0.7030 - val_accuracy: 0.7786\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6908 - accuracy: 0.7807 - val_loss: 0.7113 - val_accuracy: 0.7699\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6489 - accuracy: 0.7931 - val_loss: 0.6418 - val_accuracy: 0.7970\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6053 - accuracy: 0.8068 - val_loss: 0.6087 - val_accuracy: 0.8057\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5723 - accuracy: 0.8178 - val_loss: 0.5700 - val_accuracy: 0.8194\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5761 - accuracy: 0.8164 - val_loss: 0.5769 - val_accuracy: 0.8185\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5956 - accuracy: 0.8104 - val_loss: 0.5229 - val_accuracy: 0.8362\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5384 - accuracy: 0.8275 - val_loss: 0.5910 - val_accuracy: 0.8151\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5564 - accuracy: 0.8211 - val_loss: 0.5562 - val_accuracy: 0.8263\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6027 - accuracy: 0.8060 - val_loss: 0.5941 - val_accuracy: 0.8164\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5700 - accuracy: 0.8173 - val_loss: 0.5429 - val_accuracy: 0.8277\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5028 - accuracy: 0.8392 - val_loss: 0.5140 - val_accuracy: 0.8407\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5100 - accuracy: 0.8363 - val_loss: 0.5506 - val_accuracy: 0.8319\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5275 - accuracy: 0.8330 - val_loss: 0.5083 - val_accuracy: 0.8441\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4581 - accuracy: 0.8535 - val_loss: 0.4826 - val_accuracy: 0.8511\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4807 - accuracy: 0.8452 - val_loss: 0.4538 - val_accuracy: 0.8599\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4343 - accuracy: 0.8597 - val_loss: 0.4561 - val_accuracy: 0.8592\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4328 - accuracy: 0.8600 - val_loss: 0.4483 - val_accuracy: 0.8616\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4428 - accuracy: 0.8580 - val_loss: 0.5131 - val_accuracy: 0.8441\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4806 - accuracy: 0.8455 - val_loss: 0.4522 - val_accuracy: 0.8597\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4576 - accuracy: 0.8540 - val_loss: 0.4148 - val_accuracy: 0.8717\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4002 - accuracy: 0.8711 - val_loss: 0.4340 - val_accuracy: 0.8671\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4084 - accuracy: 0.8690 - val_loss: 0.4221 - val_accuracy: 0.8684\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3901 - accuracy: 0.8753 - val_loss: 0.3920 - val_accuracy: 0.8812\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3898 - accuracy: 0.8737 - val_loss: 0.4350 - val_accuracy: 0.8659\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3712 - accuracy: 0.8812 - val_loss: 0.4020 - val_accuracy: 0.8799\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.4041 - accuracy: 0.8698 - val_loss: 0.3985 - val_accuracy: 0.8782\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4057 - accuracy: 0.8687 - val_loss: 0.4152 - val_accuracy: 0.8728\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3568 - accuracy: 0.8852 - val_loss: 0.4015 - val_accuracy: 0.8785\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4223 - accuracy: 0.8638 - val_loss: 0.4157 - val_accuracy: 0.8760\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4071 - accuracy: 0.8688 - val_loss: 0.3948 - val_accuracy: 0.8788\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8788\n",
      "Accuracy on the Validation Data is 0.8788333535194397 and the loss is 0.3947680592536926\n",
      "For Learning Rate of 0.0159515119547616 and Regularization of 1.239340492292768e-06\n",
      "\n",
      "\n",
      "--------------------------- Loop 2 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 2.4893 - accuracy: 0.1039 - val_loss: 3.1616 - val_accuracy: 0.0963\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 2.3143 - accuracy: 0.1156 - val_loss: 2.4576 - val_accuracy: 0.1257\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.0393 - accuracy: 0.2297 - val_loss: 1.9461 - val_accuracy: 0.2937\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.5935 - accuracy: 0.4325 - val_loss: 1.6914 - val_accuracy: 0.4305\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.2185 - accuracy: 0.5952 - val_loss: 1.5332 - val_accuracy: 0.4919\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0190 - accuracy: 0.6705 - val_loss: 1.5376 - val_accuracy: 0.4812\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.9513 - accuracy: 0.6951 - val_loss: 1.3006 - val_accuracy: 0.6342\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8925 - accuracy: 0.7116 - val_loss: 1.1741 - val_accuracy: 0.6781\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7950 - accuracy: 0.7465 - val_loss: 1.1002 - val_accuracy: 0.6991\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7760 - accuracy: 0.7513 - val_loss: 1.0411 - val_accuracy: 0.6909\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7741 - accuracy: 0.7520 - val_loss: 0.9284 - val_accuracy: 0.7248\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7477 - accuracy: 0.7617 - val_loss: 0.8135 - val_accuracy: 0.7525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7270 - accuracy: 0.7685 - val_loss: 0.7740 - val_accuracy: 0.7620\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7018 - accuracy: 0.7761 - val_loss: 0.7420 - val_accuracy: 0.7668\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6769 - accuracy: 0.7841 - val_loss: 0.6377 - val_accuracy: 0.7993\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6096 - accuracy: 0.8048 - val_loss: 0.6927 - val_accuracy: 0.7810\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6372 - accuracy: 0.7959 - val_loss: 0.6345 - val_accuracy: 0.8032\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6358 - accuracy: 0.7969 - val_loss: 0.5678 - val_accuracy: 0.8225\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5384 - accuracy: 0.8279 - val_loss: 0.5446 - val_accuracy: 0.8282\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5442 - accuracy: 0.8274 - val_loss: 0.5982 - val_accuracy: 0.8139\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5500 - accuracy: 0.8246 - val_loss: 0.5543 - val_accuracy: 0.8301\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5216 - accuracy: 0.8332 - val_loss: 0.6155 - val_accuracy: 0.8110\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5236 - accuracy: 0.8337 - val_loss: 0.4904 - val_accuracy: 0.8462\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5080 - accuracy: 0.8385 - val_loss: 0.4928 - val_accuracy: 0.8450\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5105 - accuracy: 0.8369 - val_loss: 0.5199 - val_accuracy: 0.8366\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5854 - accuracy: 0.8105 - val_loss: 0.6342 - val_accuracy: 0.8054\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5764 - accuracy: 0.8136 - val_loss: 0.4841 - val_accuracy: 0.8495\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4882 - accuracy: 0.8429 - val_loss: 0.4772 - val_accuracy: 0.8517\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5253 - accuracy: 0.8312 - val_loss: 0.4654 - val_accuracy: 0.8552\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4921 - accuracy: 0.8420 - val_loss: 0.4495 - val_accuracy: 0.8629\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4670 - accuracy: 0.8497 - val_loss: 0.4960 - val_accuracy: 0.8519\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4950 - accuracy: 0.8422 - val_loss: 0.4615 - val_accuracy: 0.8563\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4720 - accuracy: 0.8478 - val_loss: 0.4713 - val_accuracy: 0.8540\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5007 - accuracy: 0.8390 - val_loss: 0.4527 - val_accuracy: 0.8618\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4281 - accuracy: 0.8614 - val_loss: 0.4709 - val_accuracy: 0.8578\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4391 - accuracy: 0.8572 - val_loss: 0.4045 - val_accuracy: 0.8768\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3866 - accuracy: 0.8761 - val_loss: 0.4196 - val_accuracy: 0.8721\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4499 - accuracy: 0.8537 - val_loss: 0.4635 - val_accuracy: 0.8583\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4586 - accuracy: 0.8530 - val_loss: 0.4623 - val_accuracy: 0.8614\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4935 - accuracy: 0.8393 - val_loss: 0.4385 - val_accuracy: 0.8641\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4232 - accuracy: 0.8624 - val_loss: 0.3998 - val_accuracy: 0.8779\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4194 - accuracy: 0.8640 - val_loss: 0.4454 - val_accuracy: 0.8660\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4217 - accuracy: 0.8636 - val_loss: 0.3981 - val_accuracy: 0.8785\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4082 - accuracy: 0.8678 - val_loss: 0.4067 - val_accuracy: 0.8769\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4064 - accuracy: 0.8685 - val_loss: 0.3924 - val_accuracy: 0.8798\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3658 - accuracy: 0.8833 - val_loss: 0.4605 - val_accuracy: 0.8657\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4605 - accuracy: 0.8657\n",
      "Accuracy on the Validation Data is 0.8656666874885559 and the loss is 0.4605454206466675\n",
      "For Learning Rate of 0.02412189575577678 and Regularization of 3.592824433681157e-07\n",
      "\n",
      "\n",
      "--------------------------- Loop 3 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 2.5177 - accuracy: 0.1012 - val_loss: 3.8732 - val_accuracy: 0.1151\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.3279 - accuracy: 0.1190 - val_loss: 2.5799 - val_accuracy: 0.1402\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.0101 - accuracy: 0.2374 - val_loss: 1.8911 - val_accuracy: 0.2934\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.5826 - accuracy: 0.4378 - val_loss: 1.7425 - val_accuracy: 0.3929\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.3482 - accuracy: 0.5425 - val_loss: 1.5493 - val_accuracy: 0.4958\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.1157 - accuracy: 0.6318 - val_loss: 1.4251 - val_accuracy: 0.5574\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9921 - accuracy: 0.6805 - val_loss: 1.2650 - val_accuracy: 0.6177\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.9468 - accuracy: 0.6979 - val_loss: 1.1117 - val_accuracy: 0.6940\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.8995 - accuracy: 0.7109 - val_loss: 1.0309 - val_accuracy: 0.6867\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8205 - accuracy: 0.7394 - val_loss: 0.9246 - val_accuracy: 0.7340\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7593 - accuracy: 0.7612 - val_loss: 0.9010 - val_accuracy: 0.7308\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8693 - accuracy: 0.7235 - val_loss: 0.7934 - val_accuracy: 0.7557\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7356 - accuracy: 0.7687 - val_loss: 0.7315 - val_accuracy: 0.7777\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6900 - accuracy: 0.7826 - val_loss: 0.7882 - val_accuracy: 0.7577\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7033 - accuracy: 0.7788 - val_loss: 0.7333 - val_accuracy: 0.7728\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.6401 - accuracy: 0.8000 - val_loss: 0.6429 - val_accuracy: 0.7999\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6341 - accuracy: 0.8032 - val_loss: 0.6013 - val_accuracy: 0.8142\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.6057 - accuracy: 0.8109 - val_loss: 0.7043 - val_accuracy: 0.7807\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6613 - accuracy: 0.7919 - val_loss: 0.5813 - val_accuracy: 0.8183\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6017 - accuracy: 0.8109 - val_loss: 0.5990 - val_accuracy: 0.8164\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6271 - accuracy: 0.8030 - val_loss: 0.5725 - val_accuracy: 0.8248\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5813 - accuracy: 0.8183 - val_loss: 0.5471 - val_accuracy: 0.8342\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5201 - accuracy: 0.8388 - val_loss: 0.5536 - val_accuracy: 0.8322\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5285 - accuracy: 0.8367 - val_loss: 0.5871 - val_accuracy: 0.8237\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6189 - accuracy: 0.8059 - val_loss: 0.5419 - val_accuracy: 0.8410\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5255 - accuracy: 0.8371 - val_loss: 0.5362 - val_accuracy: 0.8335\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5528 - accuracy: 0.8264 - val_loss: 0.4971 - val_accuracy: 0.8485\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5150 - accuracy: 0.8415 - val_loss: 0.5310 - val_accuracy: 0.8410\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5034 - accuracy: 0.8432 - val_loss: 0.5038 - val_accuracy: 0.8504\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5244 - accuracy: 0.8358 - val_loss: 0.4852 - val_accuracy: 0.8562\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5508 - accuracy: 0.8279 - val_loss: 0.4880 - val_accuracy: 0.8522\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4815 - accuracy: 0.8514 - val_loss: 0.4944 - val_accuracy: 0.8531\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4645 - accuracy: 0.8578 - val_loss: 0.4908 - val_accuracy: 0.8515\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4804 - accuracy: 0.8526 - val_loss: 0.4558 - val_accuracy: 0.8614\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4556 - accuracy: 0.8601 - val_loss: 0.4519 - val_accuracy: 0.8661\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4434 - accuracy: 0.8637 - val_loss: 0.4532 - val_accuracy: 0.8643\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4392 - accuracy: 0.8649 - val_loss: 0.4388 - val_accuracy: 0.8689\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4261 - accuracy: 0.8680 - val_loss: 0.4480 - val_accuracy: 0.8654\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4361 - accuracy: 0.8650 - val_loss: 0.4485 - val_accuracy: 0.8671\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4078 - accuracy: 0.8740 - val_loss: 0.5109 - val_accuracy: 0.8515\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4902 - accuracy: 0.8465 - val_loss: 0.4981 - val_accuracy: 0.8522\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5159 - accuracy: 0.8384 - val_loss: 0.4316 - val_accuracy: 0.8722\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4230 - accuracy: 0.8690 - val_loss: 0.4059 - val_accuracy: 0.8801\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3785 - accuracy: 0.8842 - val_loss: 0.4266 - val_accuracy: 0.8737\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4341 - accuracy: 0.8659 - val_loss: 0.4010 - val_accuracy: 0.8820\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3830 - accuracy: 0.8820 - val_loss: 0.4060 - val_accuracy: 0.8818\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3808 - accuracy: 0.8824 - val_loss: 0.3913 - val_accuracy: 0.8852\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3874 - accuracy: 0.8808 - val_loss: 0.4116 - val_accuracy: 0.8787\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4155 - accuracy: 0.8718 - val_loss: 0.3906 - val_accuracy: 0.8861\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3662 - accuracy: 0.8865 - val_loss: 0.4272 - val_accuracy: 0.8755\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4560 - accuracy: 0.8575 - val_loss: 0.4291 - val_accuracy: 0.8762\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3930 - accuracy: 0.8779 - val_loss: 0.3735 - val_accuracy: 0.8920\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3488 - accuracy: 0.8927 - val_loss: 0.4083 - val_accuracy: 0.8809\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4172 - accuracy: 0.8698 - val_loss: 0.3890 - val_accuracy: 0.8884\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4093 - accuracy: 0.8731 - val_loss: 0.3901 - val_accuracy: 0.8862\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3646 - accuracy: 0.8871 - val_loss: 0.3897 - val_accuracy: 0.8877\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4030 - accuracy: 0.8761 - val_loss: 0.3892 - val_accuracy: 0.8895\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3662 - accuracy: 0.8878 - val_loss: 0.3578 - val_accuracy: 0.8975\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3217 - accuracy: 0.9007 - val_loss: 0.3671 - val_accuracy: 0.8949\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3307 - accuracy: 0.8988 - val_loss: 0.3932 - val_accuracy: 0.8875\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3788 - accuracy: 0.8817 - val_loss: 0.4270 - val_accuracy: 0.8810\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4210 - accuracy: 0.8690 - val_loss: 0.3764 - val_accuracy: 0.8913\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3764 - accuracy: 0.8913\n",
      "Accuracy on the Validation Data is 0.8912916779518127 and the loss is 0.3763681948184967\n",
      "For Learning Rate of 0.029484325695772882 and Regularization of 9.377866716889338e-05\n",
      "\n",
      "\n",
      "--------------------------- Loop 4 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 2.3485 - accuracy: 0.1657 - val_loss: 2.0518 - val_accuracy: 0.2969\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 1.9746 - accuracy: 0.3261 - val_loss: 1.7536 - val_accuracy: 0.4937\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.6557 - accuracy: 0.4656 - val_loss: 1.5097 - val_accuracy: 0.6058\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.4307 - accuracy: 0.5565 - val_loss: 1.3478 - val_accuracy: 0.6603\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.2800 - accuracy: 0.6113 - val_loss: 1.2371 - val_accuracy: 0.6884\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.1838 - accuracy: 0.6448 - val_loss: 1.1519 - val_accuracy: 0.7045\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1132 - accuracy: 0.6646 - val_loss: 1.0825 - val_accuracy: 0.7210\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.0516 - accuracy: 0.6837 - val_loss: 1.0175 - val_accuracy: 0.7350\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.9882 - accuracy: 0.7027 - val_loss: 0.9590 - val_accuracy: 0.7485\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9339 - accuracy: 0.7192 - val_loss: 0.9026 - val_accuracy: 0.7614\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8985 - accuracy: 0.7271 - val_loss: 0.8466 - val_accuracy: 0.7707\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8667 - accuracy: 0.7384 - val_loss: 0.8130 - val_accuracy: 0.7770\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8353 - accuracy: 0.7463 - val_loss: 0.7781 - val_accuracy: 0.7833\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8109 - accuracy: 0.7539 - val_loss: 0.7452 - val_accuracy: 0.7894\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7897 - accuracy: 0.7602 - val_loss: 0.7169 - val_accuracy: 0.7923\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7640 - accuracy: 0.7671 - val_loss: 0.6971 - val_accuracy: 0.7980\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7598 - accuracy: 0.7687 - val_loss: 0.6775 - val_accuracy: 0.8033\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7216 - accuracy: 0.7797 - val_loss: 0.6643 - val_accuracy: 0.8060\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7209 - accuracy: 0.7807 - val_loss: 0.6417 - val_accuracy: 0.8108\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7097 - accuracy: 0.7811 - val_loss: 0.6268 - val_accuracy: 0.8127\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6784 - accuracy: 0.7914 - val_loss: 0.6080 - val_accuracy: 0.8210\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6653 - accuracy: 0.7966 - val_loss: 0.6002 - val_accuracy: 0.8198\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6712 - accuracy: 0.7942 - val_loss: 0.5872 - val_accuracy: 0.8243\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6496 - accuracy: 0.8008 - val_loss: 0.5760 - val_accuracy: 0.8267\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6317 - accuracy: 0.8070 - val_loss: 0.5650 - val_accuracy: 0.8321\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6192 - accuracy: 0.8096 - val_loss: 0.5652 - val_accuracy: 0.8285\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6156 - accuracy: 0.8107 - val_loss: 0.5462 - val_accuracy: 0.8362\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5989 - accuracy: 0.8165 - val_loss: 0.5360 - val_accuracy: 0.8397\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6133 - accuracy: 0.8102 - val_loss: 0.5346 - val_accuracy: 0.8406\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5837 - accuracy: 0.8209 - val_loss: 0.5221 - val_accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5820 - accuracy: 0.8207 - val_loss: 0.5168 - val_accuracy: 0.8448\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5712 - accuracy: 0.8247 - val_loss: 0.5135 - val_accuracy: 0.8453\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5605 - accuracy: 0.8275 - val_loss: 0.5079 - val_accuracy: 0.8470\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5487 - accuracy: 0.8302 - val_loss: 0.4998 - val_accuracy: 0.8496\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5492 - accuracy: 0.8304 - val_loss: 0.4924 - val_accuracy: 0.8523\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5251 - accuracy: 0.8375 - val_loss: 0.4904 - val_accuracy: 0.8528\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5299 - accuracy: 0.8349 - val_loss: 0.4892 - val_accuracy: 0.8522\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5294 - accuracy: 0.8360 - val_loss: 0.4759 - val_accuracy: 0.8569\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5102 - accuracy: 0.8434 - val_loss: 0.4693 - val_accuracy: 0.8594\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5038 - accuracy: 0.8449 - val_loss: 0.4676 - val_accuracy: 0.8585\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5005 - accuracy: 0.8463 - val_loss: 0.4607 - val_accuracy: 0.8620\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4926 - accuracy: 0.8481 - val_loss: 0.4574 - val_accuracy: 0.8637\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4830 - accuracy: 0.8522 - val_loss: 0.4559 - val_accuracy: 0.8623\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4867 - accuracy: 0.8505 - val_loss: 0.4466 - val_accuracy: 0.8654\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4700 - accuracy: 0.8553 - val_loss: 0.4450 - val_accuracy: 0.8671\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4810 - accuracy: 0.8505 - val_loss: 0.4408 - val_accuracy: 0.8693\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4713 - accuracy: 0.8530 - val_loss: 0.4416 - val_accuracy: 0.8688\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4717 - accuracy: 0.8530 - val_loss: 0.4344 - val_accuracy: 0.8696\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4656 - accuracy: 0.8551 - val_loss: 0.4381 - val_accuracy: 0.8690\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4779 - accuracy: 0.8522 - val_loss: 0.4409 - val_accuracy: 0.8670\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4576 - accuracy: 0.8579 - val_loss: 0.4270 - val_accuracy: 0.8723\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4509 - accuracy: 0.8596 - val_loss: 0.4258 - val_accuracy: 0.8726\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4445 - accuracy: 0.8629 - val_loss: 0.4200 - val_accuracy: 0.8746\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4400 - accuracy: 0.8648 - val_loss: 0.4219 - val_accuracy: 0.8742\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4291 - accuracy: 0.8684 - val_loss: 0.4149 - val_accuracy: 0.8770\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4149 - accuracy: 0.8770\n",
      "Accuracy on the Validation Data is 0.8769583106040955 and the loss is 0.4148671329021454\n",
      "For Learning Rate of 0.00018562853048454924 and Regularization of 8.783137056474455e-05\n",
      "\n",
      "\n",
      "--------------------------- Loop 5 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.4734 - accuracy: 0.1032 - val_loss: 2.7795 - val_accuracy: 0.0987\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.2732 - accuracy: 0.1379 - val_loss: 2.1104 - val_accuracy: 0.1837\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.8792 - accuracy: 0.3004 - val_loss: 1.7030 - val_accuracy: 0.4018\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3834 - accuracy: 0.5267 - val_loss: 1.5490 - val_accuracy: 0.4846\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.1199 - accuracy: 0.6354 - val_loss: 1.4544 - val_accuracy: 0.5341\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.9946 - accuracy: 0.6851 - val_loss: 1.1995 - val_accuracy: 0.6798\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8971 - accuracy: 0.7193 - val_loss: 1.1712 - val_accuracy: 0.6540\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8779 - accuracy: 0.7253 - val_loss: 1.0377 - val_accuracy: 0.6840\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8161 - accuracy: 0.7468 - val_loss: 0.8609 - val_accuracy: 0.7468\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.7537 - accuracy: 0.7667 - val_loss: 0.7939 - val_accuracy: 0.7652\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6958 - accuracy: 0.7860 - val_loss: 0.7689 - val_accuracy: 0.7671\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.7412 - accuracy: 0.7716 - val_loss: 0.7860 - val_accuracy: 0.7619\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6867 - accuracy: 0.7891 - val_loss: 0.7673 - val_accuracy: 0.7633\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.6300 - accuracy: 0.8084 - val_loss: 0.7134 - val_accuracy: 0.7832\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6707 - accuracy: 0.7926 - val_loss: 0.6715 - val_accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6406 - accuracy: 0.8028 - val_loss: 0.6317 - val_accuracy: 0.8096\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6315 - accuracy: 0.8056 - val_loss: 0.5660 - val_accuracy: 0.8298\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5932 - accuracy: 0.8191 - val_loss: 0.5888 - val_accuracy: 0.8255\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5941 - accuracy: 0.8175 - val_loss: 0.5919 - val_accuracy: 0.8192\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5966 - accuracy: 0.8186 - val_loss: 0.5565 - val_accuracy: 0.8315\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5862 - accuracy: 0.8211 - val_loss: 0.5315 - val_accuracy: 0.8428\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5567 - accuracy: 0.8306 - val_loss: 0.5539 - val_accuracy: 0.8327\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5685 - accuracy: 0.8254 - val_loss: 0.5666 - val_accuracy: 0.8309\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5752 - accuracy: 0.8245 - val_loss: 0.5266 - val_accuracy: 0.8409\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5483 - accuracy: 0.8340 - val_loss: 0.5357 - val_accuracy: 0.8426\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5389 - accuracy: 0.8367 - val_loss: 0.5097 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5409 - accuracy: 0.8361 - val_loss: 0.4757 - val_accuracy: 0.8587\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4931 - accuracy: 0.8506 - val_loss: 0.5147 - val_accuracy: 0.8462\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5163 - accuracy: 0.8437 - val_loss: 0.4686 - val_accuracy: 0.8620\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4985 - accuracy: 0.8493 - val_loss: 0.4841 - val_accuracy: 0.8562\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4922 - accuracy: 0.8499 - val_loss: 0.4574 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4380 - accuracy: 0.8690 - val_loss: 0.5404 - val_accuracy: 0.8469\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5028 - accuracy: 0.8478 - val_loss: 0.4459 - val_accuracy: 0.8692\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4407 - accuracy: 0.8688 - val_loss: 0.4452 - val_accuracy: 0.8705\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4359 - accuracy: 0.8696 - val_loss: 0.4495 - val_accuracy: 0.8658\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4256 - accuracy: 0.8721 - val_loss: 0.4540 - val_accuracy: 0.8668\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4262 - accuracy: 0.8715 - val_loss: 0.4634 - val_accuracy: 0.8684\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4288 - accuracy: 0.8713 - val_loss: 0.4193 - val_accuracy: 0.8763\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4203 - accuracy: 0.8724 - val_loss: 0.4574 - val_accuracy: 0.8675\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4658 - accuracy: 0.8574 - val_loss: 0.4587 - val_accuracy: 0.8641\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4491 - accuracy: 0.8639 - val_loss: 0.4080 - val_accuracy: 0.8813\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4246 - accuracy: 0.8715 - val_loss: 0.4181 - val_accuracy: 0.8774\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4187 - accuracy: 0.8720 - val_loss: 0.4936 - val_accuracy: 0.8582\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4127 - accuracy: 0.8753 - val_loss: 0.4320 - val_accuracy: 0.8726\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4337 - accuracy: 0.8670 - val_loss: 0.4227 - val_accuracy: 0.8792\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4073 - accuracy: 0.8773 - val_loss: 0.3955 - val_accuracy: 0.8855\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3916 - accuracy: 0.8808 - val_loss: 0.3970 - val_accuracy: 0.8842\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3746 - accuracy: 0.8869 - val_loss: 0.3849 - val_accuracy: 0.8880\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3598 - accuracy: 0.8912 - val_loss: 0.4108 - val_accuracy: 0.8810\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4029 - accuracy: 0.8774 - val_loss: 0.4016 - val_accuracy: 0.8840\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4029 - accuracy: 0.8770 - val_loss: 0.3879 - val_accuracy: 0.8878\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3879 - accuracy: 0.8878\n",
      "Accuracy on the Validation Data is 0.8878333568572998 and the loss is 0.38790440559387207\n",
      "For Learning Rate of 0.014445780125548317 and Regularization of 0.0009925973122165658\n",
      "\n",
      "\n",
      "--------------------------- Loop 6 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 2.3840 - accuracy: 0.1118 - val_loss: 2.6183 - val_accuracy: 0.1155\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 2.1305 - accuracy: 0.2072 - val_loss: 1.8640 - val_accuracy: 0.3343\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.4525 - accuracy: 0.5049 - val_loss: 1.5625 - val_accuracy: 0.5708\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.1627 - accuracy: 0.6222 - val_loss: 1.3406 - val_accuracy: 0.6644\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9765 - accuracy: 0.6865 - val_loss: 1.3390 - val_accuracy: 0.6200\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.9815 - accuracy: 0.6853 - val_loss: 1.1022 - val_accuracy: 0.6981\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8231 - accuracy: 0.7372 - val_loss: 0.9704 - val_accuracy: 0.7397\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7841 - accuracy: 0.7503 - val_loss: 0.9578 - val_accuracy: 0.7192\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8340 - accuracy: 0.7332 - val_loss: 0.8314 - val_accuracy: 0.7393\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7509 - accuracy: 0.7600 - val_loss: 0.7029 - val_accuracy: 0.7913\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6726 - accuracy: 0.7863 - val_loss: 0.7365 - val_accuracy: 0.7761\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6821 - accuracy: 0.7825 - val_loss: 0.6160 - val_accuracy: 0.8138\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5935 - accuracy: 0.8123 - val_loss: 0.6277 - val_accuracy: 0.8010\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 0.6249 - accuracy: 0.7999 - val_loss: 0.5890 - val_accuracy: 0.8181\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5688 - accuracy: 0.8188 - val_loss: 0.5544 - val_accuracy: 0.8283\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6287 - accuracy: 0.8000 - val_loss: 0.6478 - val_accuracy: 0.7995\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5749 - accuracy: 0.8166 - val_loss: 0.5245 - val_accuracy: 0.8351\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5078 - accuracy: 0.8379 - val_loss: 0.5113 - val_accuracy: 0.8369\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4951 - accuracy: 0.8424 - val_loss: 0.4913 - val_accuracy: 0.8471\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4594 - accuracy: 0.8540 - val_loss: 0.5809 - val_accuracy: 0.8196\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5513 - accuracy: 0.8225 - val_loss: 0.4718 - val_accuracy: 0.8535\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4455 - accuracy: 0.8576 - val_loss: 0.5203 - val_accuracy: 0.8384\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5604 - accuracy: 0.8206 - val_loss: 0.5171 - val_accuracy: 0.8427\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4712 - accuracy: 0.8477 - val_loss: 0.4788 - val_accuracy: 0.8530\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4560 - accuracy: 0.8530 - val_loss: 0.4890 - val_accuracy: 0.8503\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5352 - accuracy: 0.8288 - val_loss: 0.4576 - val_accuracy: 0.8570\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4773 - accuracy: 0.8462 - val_loss: 0.4400 - val_accuracy: 0.8660\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4257 - accuracy: 0.8643 - val_loss: 0.4188 - val_accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3920 - accuracy: 0.8743 - val_loss: 0.4403 - val_accuracy: 0.8635\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4230 - accuracy: 0.8640 - val_loss: 0.4168 - val_accuracy: 0.8719\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4496 - accuracy: 0.8537 - val_loss: 0.4262 - val_accuracy: 0.8680\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4184 - accuracy: 0.8657 - val_loss: 0.4113 - val_accuracy: 0.8740\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3755 - accuracy: 0.8797 - val_loss: 0.4372 - val_accuracy: 0.8634\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4551 - accuracy: 0.8529 - val_loss: 0.4073 - val_accuracy: 0.8722\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4310 - accuracy: 0.8607 - val_loss: 0.4050 - val_accuracy: 0.8772\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3787 - accuracy: 0.8770 - val_loss: 0.4201 - val_accuracy: 0.8715\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4097 - accuracy: 0.8671 - val_loss: 0.3839 - val_accuracy: 0.8821\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3502 - accuracy: 0.8879 - val_loss: 0.3761 - val_accuracy: 0.8860\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3595 - accuracy: 0.8841 - val_loss: 0.3782 - val_accuracy: 0.8836\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3296 - accuracy: 0.8933 - val_loss: 0.3889 - val_accuracy: 0.8819\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3824 - accuracy: 0.8763 - val_loss: 0.3811 - val_accuracy: 0.8859\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4124 - accuracy: 0.8648 - val_loss: 0.4000 - val_accuracy: 0.8797\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3375 - accuracy: 0.8919 - val_loss: 0.3553 - val_accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3217 - accuracy: 0.8942 - val_loss: 0.3659 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3824 - accuracy: 0.8754 - val_loss: 0.3783 - val_accuracy: 0.8851\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3826 - accuracy: 0.8752 - val_loss: 0.3745 - val_accuracy: 0.8862\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3327 - accuracy: 0.8921 - val_loss: 0.3550 - val_accuracy: 0.8928\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3485 - accuracy: 0.8854 - val_loss: 0.3583 - val_accuracy: 0.8918\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3074 - accuracy: 0.9007 - val_loss: 0.3375 - val_accuracy: 0.8993\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3012 - accuracy: 0.9023 - val_loss: 0.3646 - val_accuracy: 0.8907\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3980 - accuracy: 0.8691 - val_loss: 0.3836 - val_accuracy: 0.8859\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3628 - accuracy: 0.8813 - val_loss: 0.3492 - val_accuracy: 0.8957\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3424 - accuracy: 0.8883 - val_loss: 0.3408 - val_accuracy: 0.8989\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8989\n",
      "Accuracy on the Validation Data is 0.8989166617393494 and the loss is 0.3407614827156067\n",
      "For Learning Rate of 0.006050433806556671 and Regularization of 6.933747064715579e-07\n",
      "\n",
      "\n",
      "--------------------------- Loop 7 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 2.6312 - accuracy: 0.1024 - val_loss: 3.7647 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 2.3212 - accuracy: 0.1039 - val_loss: 2.5072 - val_accuracy: 0.0973\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.2926 - accuracy: 0.1136 - val_loss: 2.3095 - val_accuracy: 0.1175\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 2.1358 - accuracy: 0.1773 - val_loss: 2.0273 - val_accuracy: 0.2146\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.7176 - accuracy: 0.3674 - val_loss: 1.8476 - val_accuracy: 0.3292\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 1.4456 - accuracy: 0.5030 - val_loss: 1.7162 - val_accuracy: 0.3844\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.1852 - accuracy: 0.6137 - val_loss: 1.4534 - val_accuracy: 0.5145\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0528 - accuracy: 0.6589 - val_loss: 1.3551 - val_accuracy: 0.5694\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.9374 - accuracy: 0.7018 - val_loss: 1.2486 - val_accuracy: 0.6174\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8725 - accuracy: 0.7212 - val_loss: 1.1336 - val_accuracy: 0.6628\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8350 - accuracy: 0.7326 - val_loss: 0.9721 - val_accuracy: 0.7179\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7785 - accuracy: 0.7529 - val_loss: 0.9698 - val_accuracy: 0.7085\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8055 - accuracy: 0.7433 - val_loss: 0.8174 - val_accuracy: 0.7579\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7818 - accuracy: 0.7498 - val_loss: 0.7903 - val_accuracy: 0.7596\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7382 - accuracy: 0.7668 - val_loss: 0.6864 - val_accuracy: 0.7890\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7124 - accuracy: 0.7739 - val_loss: 0.7296 - val_accuracy: 0.7720\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7482 - accuracy: 0.7600 - val_loss: 0.7418 - val_accuracy: 0.7751\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6425 - accuracy: 0.7977 - val_loss: 0.6163 - val_accuracy: 0.8087\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.6292 - accuracy: 0.8002 - val_loss: 0.5957 - val_accuracy: 0.8134\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5806 - accuracy: 0.8164 - val_loss: 0.6103 - val_accuracy: 0.8108\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 97ms/step - loss: 0.5613 - accuracy: 0.8215 - val_loss: 0.5768 - val_accuracy: 0.8207\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5975 - accuracy: 0.8113 - val_loss: 0.5699 - val_accuracy: 0.8268\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6172 - accuracy: 0.8034 - val_loss: 0.6733 - val_accuracy: 0.8002\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6274 - accuracy: 0.8007 - val_loss: 0.5780 - val_accuracy: 0.8248\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5748 - accuracy: 0.8167 - val_loss: 0.5917 - val_accuracy: 0.8210\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5746 - accuracy: 0.8187 - val_loss: 0.5446 - val_accuracy: 0.8317\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5589 - accuracy: 0.8211 - val_loss: 0.5734 - val_accuracy: 0.8227\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6081 - accuracy: 0.8049 - val_loss: 0.5729 - val_accuracy: 0.8293\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5026 - accuracy: 0.8409 - val_loss: 0.5048 - val_accuracy: 0.8435\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5148 - accuracy: 0.8363 - val_loss: 0.4897 - val_accuracy: 0.8507\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5136 - accuracy: 0.8384 - val_loss: 0.5454 - val_accuracy: 0.8311\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.5967 - accuracy: 0.8097 - val_loss: 0.5228 - val_accuracy: 0.8406\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5679 - accuracy: 0.8202 - val_loss: 0.4854 - val_accuracy: 0.8526\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.5210 - accuracy: 0.8339 - val_loss: 0.5287 - val_accuracy: 0.8375\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.5326 - accuracy: 0.8301 - val_loss: 0.4797 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4568 - accuracy: 0.8549 - val_loss: 0.4508 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5009 - accuracy: 0.8414 - val_loss: 0.4579 - val_accuracy: 0.8606\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4841 - accuracy: 0.8469 - val_loss: 0.4994 - val_accuracy: 0.8504\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5174 - accuracy: 0.8360 - val_loss: 0.4578 - val_accuracy: 0.8647\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.4419 - accuracy: 0.8601 - val_loss: 0.4531 - val_accuracy: 0.8637\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.5153 - accuracy: 0.8372 - val_loss: 0.4699 - val_accuracy: 0.8581\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.4942 - accuracy: 0.8442 - val_loss: 0.4620 - val_accuracy: 0.8587\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.4714 - accuracy: 0.8503 - val_loss: 0.4528 - val_accuracy: 0.8622\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 0.4656 - accuracy: 0.8519 - val_loss: 0.4280 - val_accuracy: 0.8697\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.4179 - accuracy: 0.8673 - val_loss: 0.4584 - val_accuracy: 0.8624\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.4453 - accuracy: 0.8583 - val_loss: 0.4380 - val_accuracy: 0.8684\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.4176 - accuracy: 0.8672 - val_loss: 0.4359 - val_accuracy: 0.8651\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4353 - accuracy: 0.8608 - val_loss: 0.4226 - val_accuracy: 0.8727\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4298 - accuracy: 0.8624 - val_loss: 0.4089 - val_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 0.4476 - accuracy: 0.8557 - val_loss: 0.4108 - val_accuracy: 0.8775\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4287 - accuracy: 0.8640 - val_loss: 0.4250 - val_accuracy: 0.8733\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.4439 - accuracy: 0.8591 - val_loss: 0.4062 - val_accuracy: 0.8785\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 0.4657 - accuracy: 0.8518 - val_loss: 0.4217 - val_accuracy: 0.8724\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 0.4305 - accuracy: 0.8637 - val_loss: 0.4027 - val_accuracy: 0.8791\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.4240 - accuracy: 0.8658 - val_loss: 0.4187 - val_accuracy: 0.8759\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 2s 111ms/step - loss: 0.4546 - accuracy: 0.8567 - val_loss: 0.4409 - val_accuracy: 0.8692\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.4226 - accuracy: 0.8662 - val_loss: 0.3922 - val_accuracy: 0.8827\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.3542 - accuracy: 0.8881 - val_loss: 0.3917 - val_accuracy: 0.8847\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.4338 - accuracy: 0.8620 - val_loss: 0.3976 - val_accuracy: 0.8811\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.8811\n",
      "Accuracy on the Validation Data is 0.8810833096504211 and the loss is 0.3976162075996399\n",
      "For Learning Rate of 0.04171864794043507 and Regularization of 5.356941160985779e-06\n",
      "\n",
      "\n",
      "--------------------------- Loop 8 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 2.6404 - accuracy: 0.1016 - val_loss: 2.4612 - val_accuracy: 0.1005\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.3073 - accuracy: 0.1019 - val_loss: 2.3220 - val_accuracy: 0.1026\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 2.3034 - accuracy: 0.1063 - val_loss: 2.3220 - val_accuracy: 0.1023\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 2.2165 - accuracy: 0.1424 - val_loss: 2.4365 - val_accuracy: 0.1487\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 2.0296 - accuracy: 0.2151 - val_loss: 2.0024 - val_accuracy: 0.2210\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 1.7113 - accuracy: 0.3703 - val_loss: 1.8363 - val_accuracy: 0.3475\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.4662 - accuracy: 0.4957 - val_loss: 1.4518 - val_accuracy: 0.4920\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.1610 - accuracy: 0.6100 - val_loss: 1.3574 - val_accuracy: 0.5520\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 1.1284 - accuracy: 0.6299 - val_loss: 1.1459 - val_accuracy: 0.6527\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 100ms/step - loss: 0.9711 - accuracy: 0.6888 - val_loss: 1.1627 - val_accuracy: 0.6164\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.9384 - accuracy: 0.6984 - val_loss: 1.0465 - val_accuracy: 0.6751\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.8732 - accuracy: 0.7236 - val_loss: 0.9418 - val_accuracy: 0.7078\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.8194 - accuracy: 0.7417 - val_loss: 0.9276 - val_accuracy: 0.7056\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8039 - accuracy: 0.7450 - val_loss: 0.8148 - val_accuracy: 0.7451\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.7717 - accuracy: 0.7559 - val_loss: 0.8227 - val_accuracy: 0.7428\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.7687 - accuracy: 0.7591 - val_loss: 0.7016 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.7179 - accuracy: 0.7750 - val_loss: 0.7053 - val_accuracy: 0.7812\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.7413 - accuracy: 0.7677 - val_loss: 0.7335 - val_accuracy: 0.7715\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7041 - accuracy: 0.7803 - val_loss: 0.6551 - val_accuracy: 0.7974\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7382 - accuracy: 0.7672 - val_loss: 0.6927 - val_accuracy: 0.7903\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6476 - accuracy: 0.7970 - val_loss: 0.7020 - val_accuracy: 0.7855\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6696 - accuracy: 0.7888 - val_loss: 0.6165 - val_accuracy: 0.8110\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6321 - accuracy: 0.8030 - val_loss: 0.6115 - val_accuracy: 0.8110\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5902 - accuracy: 0.8136 - val_loss: 0.5921 - val_accuracy: 0.8172\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5744 - accuracy: 0.8209 - val_loss: 0.5375 - val_accuracy: 0.8351\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5488 - accuracy: 0.8298 - val_loss: 0.5672 - val_accuracy: 0.8280\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6213 - accuracy: 0.8044 - val_loss: 0.5435 - val_accuracy: 0.8303\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5635 - accuracy: 0.8244 - val_loss: 0.5470 - val_accuracy: 0.8336\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6094 - accuracy: 0.8077 - val_loss: 0.5153 - val_accuracy: 0.8408\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4951 - accuracy: 0.8460 - val_loss: 0.5086 - val_accuracy: 0.8431\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 0.5175 - accuracy: 0.8391 - val_loss: 0.4973 - val_accuracy: 0.8474\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5064 - accuracy: 0.8412 - val_loss: 0.5285 - val_accuracy: 0.8411\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5047 - accuracy: 0.8424 - val_loss: 0.4882 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.5690 - accuracy: 0.8217 - val_loss: 0.5855 - val_accuracy: 0.8274\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5228 - accuracy: 0.8367 - val_loss: 0.4883 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4847 - accuracy: 0.8489 - val_loss: 0.4667 - val_accuracy: 0.8593\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.5086 - accuracy: 0.8414 - val_loss: 0.4856 - val_accuracy: 0.8541\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5231 - accuracy: 0.8368 - val_loss: 0.5062 - val_accuracy: 0.8456\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4404 - accuracy: 0.8629 - val_loss: 0.4696 - val_accuracy: 0.8577\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5035 - accuracy: 0.8421 - val_loss: 0.4460 - val_accuracy: 0.8655\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4602 - accuracy: 0.8560 - val_loss: 0.4482 - val_accuracy: 0.8635\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4402 - accuracy: 0.8638 - val_loss: 0.4443 - val_accuracy: 0.8650\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4807 - accuracy: 0.8476 - val_loss: 0.5124 - val_accuracy: 0.8494\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.5008 - accuracy: 0.8435 - val_loss: 0.4757 - val_accuracy: 0.8568\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4549 - accuracy: 0.8582 - val_loss: 0.4272 - val_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4224 - accuracy: 0.8684 - val_loss: 0.4574 - val_accuracy: 0.8618\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4270 - accuracy: 0.8668 - val_loss: 0.4324 - val_accuracy: 0.8683\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4459 - accuracy: 0.8602 - val_loss: 0.4294 - val_accuracy: 0.8713\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4197 - accuracy: 0.8692 - val_loss: 0.4434 - val_accuracy: 0.8660\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4075 - accuracy: 0.8720 - val_loss: 0.4415 - val_accuracy: 0.8664\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4390 - accuracy: 0.8625 - val_loss: 0.4080 - val_accuracy: 0.8771\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4011 - accuracy: 0.8746 - val_loss: 0.4235 - val_accuracy: 0.8731\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4127 - accuracy: 0.8723 - val_loss: 0.4118 - val_accuracy: 0.8761\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3918 - accuracy: 0.8780 - val_loss: 0.3906 - val_accuracy: 0.8816\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4063 - accuracy: 0.8727 - val_loss: 0.4036 - val_accuracy: 0.8766\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4036 - accuracy: 0.8766\n",
      "Accuracy on the Validation Data is 0.8765833377838135 and the loss is 0.4035967290401459\n",
      "For Learning Rate of 0.0572848204268836 and Regularization of 5.2321418084970306e-05\n",
      "\n",
      "\n",
      "--------------------------- Loop 9 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 2.4139 - accuracy: 0.1086 - val_loss: 2.5472 - val_accuracy: 0.1207\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.2246 - accuracy: 0.1643 - val_loss: 2.0333 - val_accuracy: 0.2302\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.6461 - accuracy: 0.4166 - val_loss: 1.6628 - val_accuracy: 0.4594\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 1.1543 - accuracy: 0.6217 - val_loss: 1.5463 - val_accuracy: 0.5673\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.0062 - accuracy: 0.6754 - val_loss: 1.3920 - val_accuracy: 0.6109\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.9282 - accuracy: 0.7026 - val_loss: 1.1550 - val_accuracy: 0.6986\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8239 - accuracy: 0.7369 - val_loss: 1.0733 - val_accuracy: 0.7264\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7753 - accuracy: 0.7508 - val_loss: 0.9469 - val_accuracy: 0.7470\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7391 - accuracy: 0.7646 - val_loss: 0.9038 - val_accuracy: 0.7366\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6813 - accuracy: 0.7828 - val_loss: 0.7314 - val_accuracy: 0.7969\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6269 - accuracy: 0.8012 - val_loss: 0.8091 - val_accuracy: 0.7596\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6438 - accuracy: 0.7958 - val_loss: 0.6124 - val_accuracy: 0.8177\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5625 - accuracy: 0.8221 - val_loss: 0.6942 - val_accuracy: 0.7882\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6016 - accuracy: 0.8074 - val_loss: 0.6710 - val_accuracy: 0.7943\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5491 - accuracy: 0.8246 - val_loss: 0.7469 - val_accuracy: 0.7721\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5694 - accuracy: 0.8186 - val_loss: 0.5746 - val_accuracy: 0.8188\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5386 - accuracy: 0.8290 - val_loss: 0.5677 - val_accuracy: 0.8260\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5764 - accuracy: 0.8164 - val_loss: 0.4933 - val_accuracy: 0.8448\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4851 - accuracy: 0.8450 - val_loss: 0.5374 - val_accuracy: 0.8297\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5346 - accuracy: 0.8294 - val_loss: 0.5406 - val_accuracy: 0.8369\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4736 - accuracy: 0.8496 - val_loss: 0.5128 - val_accuracy: 0.8410\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4807 - accuracy: 0.8465 - val_loss: 0.4666 - val_accuracy: 0.8580\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4496 - accuracy: 0.8577 - val_loss: 0.4830 - val_accuracy: 0.8496\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.4852 - accuracy: 0.8436 - val_loss: 0.4841 - val_accuracy: 0.8505\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5082 - accuracy: 0.8372 - val_loss: 0.5102 - val_accuracy: 0.8458\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5312 - accuracy: 0.8281 - val_loss: 0.4462 - val_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4440 - accuracy: 0.8583 - val_loss: 0.4554 - val_accuracy: 0.8623\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4135 - accuracy: 0.8669 - val_loss: 0.4869 - val_accuracy: 0.8471\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4604 - accuracy: 0.8512 - val_loss: 0.4336 - val_accuracy: 0.8672\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4212 - accuracy: 0.8651 - val_loss: 0.3940 - val_accuracy: 0.8794\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3807 - accuracy: 0.8775 - val_loss: 0.4360 - val_accuracy: 0.8655\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4432 - accuracy: 0.8560 - val_loss: 0.4036 - val_accuracy: 0.8775\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3887 - accuracy: 0.8750 - val_loss: 0.3921 - val_accuracy: 0.8816\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4333 - accuracy: 0.8623 - val_loss: 0.3842 - val_accuracy: 0.8820\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3639 - accuracy: 0.8840 - val_loss: 0.3986 - val_accuracy: 0.8807\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3681 - accuracy: 0.8826 - val_loss: 0.3955 - val_accuracy: 0.8762\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.3695 - accuracy: 0.8825 - val_loss: 0.3921 - val_accuracy: 0.8809\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.3630 - accuracy: 0.8830 - val_loss: 0.4326 - val_accuracy: 0.8687\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3944 - accuracy: 0.8729 - val_loss: 0.3973 - val_accuracy: 0.8817\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3618 - accuracy: 0.8842 - val_loss: 0.4138 - val_accuracy: 0.8790\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4138 - accuracy: 0.8790\n",
      "Accuracy on the Validation Data is 0.8790416717529297 and the loss is 0.4138079285621643\n",
      "For Learning Rate of 0.00634345023342687 and Regularization of 1.1194850655586318e-05\n",
      "\n",
      "\n",
      "--------------------------- Loop 10 ---------------------------\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 2.6367 - accuracy: 0.0998 - val_loss: 3.1668 - val_accuracy: 0.0994\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 2.3115 - accuracy: 0.1019 - val_loss: 2.3215 - val_accuracy: 0.0973\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 2.3034 - accuracy: 0.1050 - val_loss: 2.3102 - val_accuracy: 0.1080\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 2.2215 - accuracy: 0.1399 - val_loss: 2.4234 - val_accuracy: 0.1518\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.9250 - accuracy: 0.2646 - val_loss: 2.2301 - val_accuracy: 0.2280\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1.6215 - accuracy: 0.4185 - val_loss: 1.6495 - val_accuracy: 0.3833\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3257 - accuracy: 0.5479 - val_loss: 1.4944 - val_accuracy: 0.4703\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 1.1659 - accuracy: 0.6137 - val_loss: 1.3709 - val_accuracy: 0.5357\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 1.0292 - accuracy: 0.6686 - val_loss: 1.0470 - val_accuracy: 0.6640\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.9613 - accuracy: 0.6931 - val_loss: 1.0218 - val_accuracy: 0.6718\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8432 - accuracy: 0.7321 - val_loss: 0.9320 - val_accuracy: 0.7122\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.8052 - accuracy: 0.7471 - val_loss: 0.8624 - val_accuracy: 0.7278\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7773 - accuracy: 0.7549 - val_loss: 0.8037 - val_accuracy: 0.7550\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7800 - accuracy: 0.7530 - val_loss: 0.7754 - val_accuracy: 0.7562\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7637 - accuracy: 0.7581 - val_loss: 0.7426 - val_accuracy: 0.7684\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.7479 - accuracy: 0.7626 - val_loss: 0.7454 - val_accuracy: 0.7667 1s - - ETA: 0s - loss: 0.7480 - accuracy: 0.76\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6409 - accuracy: 0.7993 - val_loss: 0.7066 - val_accuracy: 0.7791\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 0.6736 - accuracy: 0.7868 - val_loss: 0.6879 - val_accuracy: 0.7845\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6938 - accuracy: 0.7798 - val_loss: 0.7052 - val_accuracy: 0.7781\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6718 - accuracy: 0.7882 - val_loss: 0.6335 - val_accuracy: 0.7999\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.6235 - accuracy: 0.8022 - val_loss: 0.6047 - val_accuracy: 0.8077\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.6653 - accuracy: 0.7906 - val_loss: 0.5859 - val_accuracy: 0.8172\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5841 - accuracy: 0.8167 - val_loss: 0.6144 - val_accuracy: 0.8095\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.6068 - accuracy: 0.8079 - val_loss: 0.5958 - val_accuracy: 0.8153\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6029 - accuracy: 0.8087 - val_loss: 0.5943 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5867 - accuracy: 0.8139 - val_loss: 0.5944 - val_accuracy: 0.8153\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5861 - accuracy: 0.8144 - val_loss: 0.5865 - val_accuracy: 0.8202\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5767 - accuracy: 0.8194 - val_loss: 0.5482 - val_accuracy: 0.8322\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5538 - accuracy: 0.8242 - val_loss: 0.5363 - val_accuracy: 0.8367\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5165 - accuracy: 0.8366 - val_loss: 0.5327 - val_accuracy: 0.8350\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5178 - accuracy: 0.8375 - val_loss: 0.4868 - val_accuracy: 0.8503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4859 - accuracy: 0.8465 - val_loss: 0.4728 - val_accuracy: 0.8535\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4851 - accuracy: 0.8480 - val_loss: 0.5022 - val_accuracy: 0.8466\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4986 - accuracy: 0.8427 - val_loss: 0.4921 - val_accuracy: 0.8523\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4899 - accuracy: 0.8460 - val_loss: 0.4884 - val_accuracy: 0.8455\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4866 - accuracy: 0.8454 - val_loss: 0.4741 - val_accuracy: 0.8545\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4744 - accuracy: 0.8498 - val_loss: 0.4581 - val_accuracy: 0.8598\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4501 - accuracy: 0.8573 - val_loss: 0.4517 - val_accuracy: 0.8620\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4546 - accuracy: 0.8555 - val_loss: 0.4424 - val_accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4221 - accuracy: 0.8670 - val_loss: 0.4594 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4638 - accuracy: 0.8522 - val_loss: 0.4573 - val_accuracy: 0.8622\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4399 - accuracy: 0.8612 - val_loss: 0.4538 - val_accuracy: 0.8608\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5089 - accuracy: 0.8382 - val_loss: 0.4379 - val_accuracy: 0.8649\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4389 - accuracy: 0.8598 - val_loss: 0.4321 - val_accuracy: 0.8665\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.4217 - accuracy: 0.8653 - val_loss: 0.4804 - val_accuracy: 0.8561\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 0.4575 - accuracy: 0.8534 - val_loss: 0.4297 - val_accuracy: 0.8702\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.86 - 2s 94ms/step - loss: 0.4400 - accuracy: 0.8601 - val_loss: 0.4216 - val_accuracy: 0.8719\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4456 - accuracy: 0.8575 - val_loss: 0.4229 - val_accuracy: 0.8710\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.4229 - accuracy: 0.8710\n",
      "Accuracy on the Validation Data is 0.8709583282470703 and the loss is 0.422930508852005\n",
      "For Learning Rate of 0.06094681868428785 and Regularization of 3.1159340145095234e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intializing Lists\n",
    "Learning_rate = []\n",
    "Lamda = []\n",
    "Loss = []\n",
    "Accuracy = []\n",
    "\n",
    "for i in range(10):\n",
    "    print('--------------------------- Loop {0} ---------------------------'.format(i+1))\n",
    "    lr = math.pow(10,np.random.uniform(-4,-1))\n",
    "    lamda = math.pow(10,np.random.uniform(-7,-3))\n",
    "    mod = model(X_train,y_train,loops= 100, learningrate= lr,regularization=lamda,val=True,x_val=X_val,y_val=y_val)\n",
    "    loss,accuracy = mod.evaluate(X_val,y_val)\n",
    "    \n",
    "    Learning_rate.append(lr)\n",
    "    Lamda.append(lamda)\n",
    "    Loss.append(loss)\n",
    "    Accuracy.append(accuracy)\n",
    "    \n",
    "    print('Accuracy on the Validation Data is {0} and the loss is {1}'.format(accuracy,loss))\n",
    "    print('For Learning Rate of {0} and Regularization of {1}'.format(lr,lamda))\n",
    "    print('\\n')\n",
    "    \n",
    "# Visualizng the Results\n",
    "data = pd.DataFrame(Learning_rate,columns=['Learning Rate'])\n",
    "data['Lamda'] = Lamda\n",
    "data['Loss'] = Loss\n",
    "data['Accuracy'] = Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Lamda</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015952</td>\n",
       "      <td>1.239340e-06</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.878833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024122</td>\n",
       "      <td>3.592824e-07</td>\n",
       "      <td>0.460545</td>\n",
       "      <td>0.865667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029484</td>\n",
       "      <td>9.377867e-05</td>\n",
       "      <td>0.376368</td>\n",
       "      <td>0.891292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000186</td>\n",
       "      <td>8.783137e-05</td>\n",
       "      <td>0.414867</td>\n",
       "      <td>0.876958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014446</td>\n",
       "      <td>9.925973e-04</td>\n",
       "      <td>0.387904</td>\n",
       "      <td>0.887833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006050</td>\n",
       "      <td>6.933747e-07</td>\n",
       "      <td>0.340761</td>\n",
       "      <td>0.898917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.041719</td>\n",
       "      <td>5.356941e-06</td>\n",
       "      <td>0.397616</td>\n",
       "      <td>0.881083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057285</td>\n",
       "      <td>5.232142e-05</td>\n",
       "      <td>0.403597</td>\n",
       "      <td>0.876583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006343</td>\n",
       "      <td>1.119485e-05</td>\n",
       "      <td>0.413808</td>\n",
       "      <td>0.879042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.060947</td>\n",
       "      <td>3.115934e-06</td>\n",
       "      <td>0.422931</td>\n",
       "      <td>0.870958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate         Lamda      Loss  Accuracy\n",
       "0       0.015952  1.239340e-06  0.394768  0.878833\n",
       "1       0.024122  3.592824e-07  0.460545  0.865667\n",
       "2       0.029484  9.377867e-05  0.376368  0.891292\n",
       "3       0.000186  8.783137e-05  0.414867  0.876958\n",
       "4       0.014446  9.925973e-04  0.387904  0.887833\n",
       "5       0.006050  6.933747e-07  0.340761  0.898917\n",
       "6       0.041719  5.356941e-06  0.397616  0.881083\n",
       "7       0.057285  5.232142e-05  0.403597  0.876583\n",
       "8       0.006343  1.119485e-05  0.413808  0.879042\n",
       "9       0.060947  3.115934e-06  0.422931  0.870958"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we see that the values of\n",
    "\n",
    "<b>Learning rate = 0.003\n",
    "Lamda         = 6.933747e-07</b>\n",
    "\n",
    "Would provide the maximum efficiency or accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 2.2343 - accuracy: 0.2018 - val_loss: 1.8381 - val_accuracy: 0.3588\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.4272 - accuracy: 0.5246 - val_loss: 1.2332 - val_accuracy: 0.6091\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.0508 - accuracy: 0.6647 - val_loss: 1.0433 - val_accuracy: 0.6780\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.9359 - accuracy: 0.7033 - val_loss: 0.9122 - val_accuracy: 0.7273\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.8430 - accuracy: 0.7324 - val_loss: 0.8489 - val_accuracy: 0.7328\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.7648 - accuracy: 0.7572 - val_loss: 0.7415 - val_accuracy: 0.7700\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6960 - accuracy: 0.7786 - val_loss: 0.7537 - val_accuracy: 0.7624\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.6977 - accuracy: 0.7802 - val_loss: 0.6471 - val_accuracy: 0.7965\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.80 - 2s 94ms/step - loss: 0.6170 - accuracy: 0.8059 - val_loss: 0.9156 - val_accuracy: 0.7246\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6887 - accuracy: 0.7810 - val_loss: 0.5832 - val_accuracy: 0.8186\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.5624 - accuracy: 0.8234 - val_loss: 0.5827 - val_accuracy: 0.8162\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5704 - accuracy: 0.8179 - val_loss: 0.6398 - val_accuracy: 0.8055\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 0.5536 - accuracy: 0.8238 - val_loss: 0.5953 - val_accuracy: 0.8163\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.6381 - accuracy: 0.7965 - val_loss: 0.5460 - val_accuracy: 0.8313\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5185 - accuracy: 0.8330 - val_loss: 0.6044 - val_accuracy: 0.8113\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.5229 - accuracy: 0.8348 - val_loss: 0.4959 - val_accuracy: 0.8456\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.5175 - accuracy: 0.8364 - val_loss: 0.5252 - val_accuracy: 0.8378\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4695 - accuracy: 0.8508 - val_loss: 0.4692 - val_accuracy: 0.8548\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4648 - accuracy: 0.8512 - val_loss: 0.5230 - val_accuracy: 0.8379\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4550 - accuracy: 0.8546 - val_loss: 0.4992 - val_accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4504 - accuracy: 0.8560 - val_loss: 0.5091 - val_accuracy: 0.8415\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4952 - accuracy: 0.8400 - val_loss: 0.4950 - val_accuracy: 0.8480\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4518 - accuracy: 0.8551 - val_loss: 0.4687 - val_accuracy: 0.8537\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4704 - accuracy: 0.8477 - val_loss: 0.4547 - val_accuracy: 0.8588\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4142 - accuracy: 0.8676 - val_loss: 0.4943 - val_accuracy: 0.8494\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4470 - accuracy: 0.8572 - val_loss: 0.4337 - val_accuracy: 0.8681\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4148 - accuracy: 0.8680 - val_loss: 0.4186 - val_accuracy: 0.8720\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3966 - accuracy: 0.8727 - val_loss: 0.4011 - val_accuracy: 0.8773\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3756 - accuracy: 0.8794 - val_loss: 0.4292 - val_accuracy: 0.8658\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.4092 - accuracy: 0.8677 - val_loss: 0.4258 - val_accuracy: 0.8680\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3586 - accuracy: 0.8848 - val_loss: 0.4225 - val_accuracy: 0.8679\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.4208 - accuracy: 0.8627 - val_loss: 0.4157 - val_accuracy: 0.8736\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3998 - accuracy: 0.8705 - val_loss: 0.4014 - val_accuracy: 0.8774\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.4192 - accuracy: 0.8637 - val_loss: 0.3825 - val_accuracy: 0.8838\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3406 - accuracy: 0.8897 - val_loss: 0.3682 - val_accuracy: 0.8860\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3660 - accuracy: 0.8821 - val_loss: 0.3940 - val_accuracy: 0.8792\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3452 - accuracy: 0.8880 - val_loss: 0.3745 - val_accuracy: 0.8880\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3392 - accuracy: 0.8905 - val_loss: 0.3608 - val_accuracy: 0.8915\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3335 - accuracy: 0.8914 - val_loss: 0.3716 - val_accuracy: 0.8875\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.3348 - accuracy: 0.8910 - val_loss: 0.3577 - val_accuracy: 0.8922\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.3157 - accuracy: 0.8974 - val_loss: 0.3636 - val_accuracy: 0.8915\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3496 - accuracy: 0.8860 - val_loss: 0.3922 - val_accuracy: 0.8800\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.3172 - accuracy: 0.8970 - val_loss: 0.3300 - val_accuracy: 0.9019\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.2716 - accuracy: 0.9125 - val_loss: 0.3724 - val_accuracy: 0.8877\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3225 - accuracy: 0.8948 - val_loss: 0.3483 - val_accuracy: 0.8976\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.3056 - accuracy: 0.8999 - val_loss: 0.3308 - val_accuracy: 0.9031\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 0.2607 - accuracy: 0.9162 - val_loss: 0.3453 - val_accuracy: 0.8976\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.2686 - accuracy: 0.9126 - val_loss: 0.3600 - val_accuracy: 0.8960\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.2629 - accuracy: 0.9136 - val_loss: 0.3370 - val_accuracy: 0.9002\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 0.2597 - accuracy: 0.9150 - val_loss: 0.3379 - val_accuracy: 0.9004\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 0.2672 - accuracy: 0.9129 - val_loss: 0.3628 - val_accuracy: 0.8954\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.2964 - accuracy: 0.9037 - val_loss: 0.3309 - val_accuracy: 0.9038\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 0.2935 - accuracy: 0.9034 - val_loss: 0.3277 - val_accuracy: 0.9053\n"
     ]
    }
   ],
   "source": [
    "# Putting the values of Learning rate and Regularization\n",
    "mod = model(X_train,y_train,loops= 100, learningrate= 0.003,regularization= 6.933747e-07,val=True,x_val=X_val,y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3277 - accuracy: 0.9053\n",
      "--------------------------------------------------------------\n",
      "Accuracy on the Validation Data is 0.9052500128746033 and the loss is 0.3277164697647095\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.9059\n",
      "--------------------------------------------------------------\n",
      "Accuracy on the Test Data is 0.905916690826416 and the loss is 0.3321121335029602\n"
     ]
    }
   ],
   "source": [
    "# Performance of model on Validation and Test set\n",
    "loss,accuracy = mod.evaluate(X_val,y_val)\n",
    "print('--------------------------------------------------------------')\n",
    "print('Accuracy on the Validation Data is {0} and the loss is {1}'.format(accuracy,loss))\n",
    "loss,accuracy = mod.evaluate(X_test,y_test)\n",
    "print('--------------------------------------------------------------')\n",
    "print('Accuracy on the Test Data is {0} and the loss is {1}'.format(accuracy,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We see for the Trained Neural Network Model following are the attributes -\n",
    "\n",
    "Validation Data : Acc - 90.5%  Loss - 0.327\n",
    "Test Data       : Acc - 90.5%  Loss - 0.332</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
